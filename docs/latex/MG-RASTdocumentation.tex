%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
\edef\sphinxdqmaybe{\ifdefined\DeclareUnicodeCharacterAsOptional\string"\fi}
  \DeclareUnicodeCharacter{\sphinxdqmaybe00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}
\addto\captionsenglish{\renewcommand{\contentsname}{Contents:}}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.\@ }}
\makeatletter
\def\fnum@figure{\figurename\thefigure{}}
\makeatother
\addto\captionsenglish{\renewcommand{\tablename}{Table }}
\makeatletter
\def\fnum@table{\tablename\thetable{}}
\makeatother
\addto\captionsenglish{\renewcommand{\literalblockname}{Listing}}

\addto\captionsenglish{\renewcommand{\literalblockcontinuedname}{continued from previous page}}
\addto\captionsenglish{\renewcommand{\literalblockcontinuesname}{continues on next page}}
\addto\captionsenglish{\renewcommand{\sphinxnonalphabeticalgroupname}{Non-alphabetical}}
\addto\captionsenglish{\renewcommand{\sphinxsymbolsname}{Symbols}}
\addto\captionsenglish{\renewcommand{\sphinxnumbersname}{Numbers}}

\addto\extrasenglish{\def\pageautorefname{page}}

\setcounter{tocdepth}{1}



\title{MG-RAST documentation Documentation}
\date{Mar 22, 2019}
\release{}
\author{Folker Meyer and the MG-RAST team}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}



\chapter{MG-RAST user manual}
\label{\detokenize{user_manual:mg-rast-user-manual}}\label{\detokenize{user_manual::doc}}

\section{Motivation}
\label{\detokenize{user_manual:motivation}}
MG-RAST provides Science as a Service for environmental DNA
(“metagenomic sequences”) at \sphinxurl{https://mg-rast.org}.

The National Human Genome Research Institute (NHGRI), a division of the
National Institutes of Health, publishes information (see Figure
{\hyperref[\detokenize{user_manual:fig:cost_per_megabase}]{\emph{{[}fig:cost\_per\_megabase{]}}}}) describing the
development of computing costs and DNA sequencing costs over time
(Institute 2012). The dramatic gap between the shrinking costs of
sequencing and the more or less stable costs of computing is a major
challenge for biomedical researchers trying to use next-generation DNA
sequencing platforms to obtain information on microbial communities.
Wilkening \sphinxstyleemphasis{et al.} (Wilkening et al. 2009) provide a real currency cost
for the analysis of 100 gigabasepairs of DNA sequence data using BLASTX
on Amazon’s EC2 service: \$300,000. %
\begin{footnote}[1]\sphinxAtStartFootnote
This includes only the computation cost, no data transfer cost, and
was computed using 2009 prices.
%
\end{footnote} A more recent study by
University of Maryland researchers (Angiuoli et al. 2011) estimates the
computation for a terabase of DNA shotgun data using their CLOVR
metagenome analysis pipeline at over \$5 million per terabase.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=4in]{{cost_per_megabase}.png}
\caption{Chart showing shrinking cost for DNA sequencing. This comparison with
Moore’s law roughly describing the development of computing costs
highlights the growing gap between sequence data and the available
analysis resources. Source: NHGRI (Institute 2012)}\label{\detokenize{user_manual:id12}}\end{figure}

Nevertheless, the growth in data enabled by next-generation sequencing
platforms also provides an exciting opportunity for studying microbial
communities:  99\% of the microbes in which have not yet been cultured
(Riesenfeld, Schloss, and Handelsman 2004). Cultivation-free methods
(often summarized as metagenomics) offer novel insights into the biology
of the vast majority of life on Earth (Thomas, Gilbert, and Meyer 2012).

Several types of studies use DNA for environmental analyses:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Environmental clone libraries (functional metagenomics): use of
Sanger sequencing (frequently) instead of more cost-efficient
next-generation sequencing

\item {} 
Amplicon metagenomics (single gene studies, 16s rDNA):
next-generation sequencing of PCR amplified ribosomal genes providing
a single reference gene\textendash{}based view of microbial community ecology

\item {} 
Shotgun metagenomics: use of next-generation technology applied
directly to environmental samples

\item {} 
Metatranscriptomics: use of cDNA transcribed from mRNA

\end{enumerate}

Each of these methods has strengths and weaknesses (see (Thomas,
Gilbert, and Meyer 2012)), as do the various sequencing technologies
(see (Loman et al. 2012)).

\begin{DUlineblock}{0em}
\item[] To support user-driven analysis of all types of metagenomic data, we
have provided MG-RAST (Meyer et al. 2008) to enable researchers to
study the function and composition of microbial communities. The
MG-RAST portal offers automated quality control, annotation,
comparative analysis, and archiving services. At the time of writing
MG-RAST has completed the analysis of over 100 terabasepairs of DNA
data in over 250,000 datasets contributed by thousands of researchers
worldwide.
\item[] The MG-RAST system provides answers to the following scientific
questions:
\end{DUlineblock}
\begin{itemize}
\item {} 
Who is out there? Identifying the composition of a microbial
community either by using amplicon data for single genes or by
deriving community composition from shotgun metagenomic data using
sequence similarities.

\item {} 
What are they doing? Using shotgun data (or metatranscriptomic data)
to derive the functional complement of a microbial community using
similarity searches against a number of databases.

\item {} 
Who is doing what? Based on sequence similarity searches, identifying
the organisms encoding specific functions.

\end{itemize}

The system supports the analysis of the prokaryotic content of samples,
analysis of viruses and eukaryotic sequences is not currently supported,
due to software limitations.

MG-RAST users can upload raw sequence data in fastq, fasta and sff
format; the sequences will be normalized (quality controlled) and
processed and summaries automatically generated. The server provides
several methods to access the different data types, including
phylogenetic and metabolic reconstructions, and the ability to compare
the metabolism and annotations of one or more metagenomes, individually
or in groups. Access to the data is password protected unless the owner
has made it public, and all data generated by the automated pipeline is
available for download in variety of common formats.


\section{Brief description}
\label{\detokenize{user_manual:brief-description}}\label{\detokenize{user_manual:section-brief-description}}
The MG-RAST pipeline performs quality control, protein prediction,
clustering and similarity-based annotation on nucleic acid sequence
datasets using a number of bioinformatics tools (see Section
{\hyperref[\detokenize{user_manual:section:bioinformatics-codes}]{\emph{13.2.1}}}. MG-RAST was built to analyze
large shotgun metagenomic data sets ranging in size from megabases to
terabases. We also support amplicon (16S, 18S, and ITS) sequence
datasets and metatranscriptome (RNA-seq) sequence datasets. The current
MG-RAST pipeline is not capable of predicting coding regions from
eukaryotes and thus will be of limited use for eukaryotic shotgun
metagenomes and/or the eukaryotic subsets of shotgun metagenomes.

Data on MG-RAST is private to the submitting user unless shared with
other users or made public by the user. We strongly encourage the
eventual release of data and require metadata (“data describing data”)
for data sharing or publication. Data submitted with metadata will be
given priority for the computational queue.

You need to provide (raw or assembled) nucleotide sequence data and
sample descriptions (“metadata”). The system accepts sequence data in
FASTA, FASTQ and SFF format and metadata in the form or GSC (
\sphinxurl{http://gensc.org/}
) standard compliant checklists (see Yilmaz et al, Nature Biotech,
2011). Uploads can be put in the system via either the web interface or
a command line tool. Data and metadata are validated after upload.

You must choose quality control filtering options at the time you submit
your job. MG-RAST provides several options for quality control (QC)
filtering for nucleotide sequence data, including removal of artificial
duplicate reads, quality-based read trimming, length-based read
trimming, and screening for DNA of model organisms (or humans). These
filters are applied before the data are submitted for annotation.

The MG-RAST pipeline assigns an accession number and puts the data in a
queue for computation. The similarity search step is computationally
expensive. Small jobs can complete as fast as hours, while large jobs
can spend a week waiting in line for computational resources.

MG-RAST performs a protein similarity search between predicted proteins
and database proteins (for shotgun) and a nucleic-acid similarity search
(for reads similar to 16S and 18S sequences).

MG-RAST presents the annotations via the tools on the analysis page
which prepare, compare, display, and export the results on the website.
The download page offers the input data, data at intermediate stages of
filtering, the similarity search output, and summary tables of functions
and organisms detected.

MG-RAST can compare thousands of data sets run through a consistent
annotation pipeline. We also provide a means to view annotations in
multiple different namespaces (e.g. SEED functions, K.O. Terms, Cog
Classes, EGGnoggs) via the M5Nr.

The publication “Metagenomics-a guide from sampling to data analysis”
(PMID 22587947) in Microbial Informatics and Experimentation, 2012 is a
good review of best practices for experiment design for further reading.


\section{URL}
\label{\detokenize{user_manual:url}}\label{\detokenize{user_manual:section-mg-rast-url}}
\sphinxurl{https://mg-rast.org/} \sphinxurl{http://metagenomics.anl.gov/}


\section{License}
\label{\detokenize{user_manual:license}}\label{\detokenize{user_manual:section-license}}

\section{Citing MG-RAST}
\label{\detokenize{user_manual:citing-mg-rast}}\label{\detokenize{user_manual:section-mg-rast-citation}}
\begin{DUlineblock}{0em}
\item[] A significant number of papers have been published about MG-RAST
itself and the supporting platform, however we ask that if you use the
system please cite:
\item[] The Metagenomics RAST server — A public resource for the automatic
phylogenetic and functional analysis of metagenomes
\item[] F. Meyer, D. Paarmann, M. D’Souza, R. Olson , E. M. Glass, M. Kubal,
T. Paczian, A. Rodriguez, R. Stevens, A. Wilke, J. Wilkening, and R.
A. Edwards
\item[] BMC Bioinformatics 2008, 9:386
\end{DUlineblock}

\sphinxhref{http://www.biomedcentral.com/1471-2105/9/386}{http://www.biomedcentral.com/1471-2105/ 9/386}

.

\begin{DUlineblock}{0em}
\item[] In addition if you also use the API please cite:
\item[] A RESTful API for Accessing Microbial Community Data for MG-RAST
\item[] A. Wilke, J. Bischof, T. Harrison, T. Brettin, M. D’Souza, W. Gerlach,
H. Matthews, T. Paczian, J. Wilkening, E. M. Glass, N. Desai, F. Meyer
\item[] PLOS Comp Biology 2015, DOI: 10.1371/journal.pcbi.1004008
\end{DUlineblock}

\sphinxurl{http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004008}

.


\section{Version history}
\label{\detokenize{user_manual:version-history}}

\subsection{Version 1}
\label{\detokenize{user_manual:version-1}}
The original version of MG-RAST was developed in 2007 by Folker Meyer,
Andreas Wilke, Daniel Paarman, Bob Olson, and Rob Edwards. It relied
heavily on the SEED(Overbeek et al. 2005) environment and allowed upload
of preprocessed 454 and Sanger data.


\subsection{Version 2}
\label{\detokenize{user_manual:version-2}}
Version 2, released in 2008, had numerous improvements. It was optimized
to handle full-sized 454 datasets and was the first version of MG-RAST
that was not fully SEED based. Version 2.0 used BLASTX analysis for both
gene prediction and functional classification(Meyer et al. 2008).


\subsection{Version 3}
\label{\detokenize{user_manual:version-3}}
While version 2 of MG-RAST was widely used, it was limited to datasets
smaller than a few hundred megabases, and comparison of samples was
limited to pairwise comparisons. Version 3 is not based on SEED
technology; instead, it uses the SEED subsystems as a preferred data
source. Starting with version 3, MG-RAST moved to github.


\subsubsection{Version 3.6}
\label{\detokenize{user_manual:version-3-6}}
With version 3.6 MG-RAST was containerized, moving from a bare metal
infrastructure to a set of docker containers running in a
Fleet/SystemD/etcD environment.


\subsubsection{Version 4}
\label{\detokenize{user_manual:version-4}}
Version 4.0 brings a new web interface, fully relying on the API for
data access and moves the bulk of the data stored from Postgres to
Cassandra. The new web interface moves the data visualization burden
from the web server to the clients machine, using Javascript and HTML5
heavily.

In version 4.0 we have moved the changed the backend store for profiles.
While previous version stored a pre-computed mapping of observed
abundances to functional or taxonomic categories, this is now computed
on the fly. The number of profiles stored is reduced to the MD5 and LCA
profiles. The API has been augmented to allow dynamic mapping to
categories, to provide the required bandwidth we have migrated the
profile store from Postgres to Cassandra.

The web interface of the previous version predated the API, the user
interface for version 4.0 now uses the API. The web interface has been
re-written in JavaScript/HTML5. Unlike previous version the web
interface now is executed on the client (inside the browser) and now
soupports any recent browser.

With version 4.04 we are switching the main web site to be mg-rast.org
and are also turning on https by default. For a limited time, the
unencrypted access protocols will remain available. We encourage all
users to upgrade their bookmarks and also install upgraded versions of
the CRAN package and/or the python tool suite. We also switched the
similarity tool to Diamond(Buchfink, Xie, and Huson 2015).


\subsection{Comparison of versions 2 and 3}
\label{\detokenize{user_manual:comparison-of-versions-2-and-3}}
Version 3 added the ability to analyze massive amounts of Illumina reads
by introducing a significant number of changes to the pipeline and the
underlying platform technology. In version 3 we introduced the notion of
the API as the central component of the system.

In the 3.0 version, datasets of tens of gigabases can be annotated, and
comparison of taxa or functions that differ between samples is now
limited only by the available screen real estate. Figure
{\hyperref[\detokenize{user_manual:fig:mgrastv2VSv3}]{\emph{1.1}}} shows a comparison of the analytical and
computational approaches used in MG-RAST v2 and v3. The major changes
are the inclusion of a dedicated gene-calling stage using FragGenescan
(Rho, Tang, and Ye 2010), clustering of predicted proteins at 90\%
identified by using uclust (Edgar 2010), and the use of BLAT (Kent 2002)
for the computation of similarities. Together with changes in the
underlying infrastructure, this version has allowed dramatic scaling of
the analysis with the limited hardware available.

Similar to version 2.0, the new version of MG-RAST does not pretend to
know the correct parameters for the transfer of annotations. Instead,
users are empowered to choose the best parameters for their datasets.


\subsection{Comparison of versions 3 and 4}
\label{\detokenize{user_manual:comparison-of-versions-3-and-4}}
The roadmap for version 4 has a number of key elements that will be
implemented step-by-step, currently the following features are
implemented:
\begin{itemize}
\item {} 
New JavaScript web interface using the API

\item {} 
Cassandra instead of Postgres as main data store for profiles

\end{itemize}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{mgrastv2VSv3}.png}
\caption{Overview of processing pipeline in (left) MG-RAST v2 and (right)
MG-RAST v3. In the old pipeline, metadata was rudimentary, compute
steps were performed on individual reads on a 40-node cluster that
was tightly coupled to the system, and similarities were computed by
BLAST to yield abundance profiles that could then be compared on a
per sample or per pair basis. In the new pipeline, rich metadata can
be uploaded, normalization and feature prediction are performed,
faster methods such as BLAT are used to compute similarities, and the
resulting abundance profiles are fed into downstream pipelines on the
cloud to perform community and metabolic reconstruction and to allow
queries according to rich sample and functional metadata.}\label{\detokenize{user_manual:fig-mgrastv2vsv3}}\end{figure}

The new version of MG-RAST represents a rethinking of core processes and
data products, as well as new user interface metaphors and a redesigned
computational infrastructure. MG-RAST supports a variety of user-driven
analyses, including comparisons of many samples, previously too
computationally intensive to support for an open user community.

Scaling to the new workload required changes in two areas: the
underlying infrastructure needed to be rethought, and the analysis
pipeline needed to be adapted to address the properties of the newest
sequencing technologies.


\section{The MG-RAST team}
\label{\detokenize{user_manual:the-mg-rast-team}}
MG-RAST was started by Rob Edwards and Folker Meyer in 2007. The MG-RAST
team has significantly expanded in the past few years. The team is
listed below.
\begin{itemize}
\item {} 
Andreas Wilke

\item {} 
Wolfgang Gerlach

\item {} 
Travis Harrison

\item {} 
William L. Trimble

\item {} 
Folker Meyer

\end{itemize}


\subsection{MG-RAST alumni}
\label{\detokenize{user_manual:mg-rast-alumni}}
The following people were associated with MG-RAST in the past:
\begin{itemize}
\item {} 
Daniel Paarmann, 2007-2008

\item {} 
Rob Edwards, 2007-2008

\item {} 
Mike Kubal, 2007-2008

\item {} 
Alex Rodriguez, 2007-2008

\item {} 
Bob Olson, 2007-2009

\item {} 
Daniela Bartels, 2007-2011

\item {} 
Yekaterina Dribinsky, 2011

\item {} 
Jared Wilkening, 2007-2013

\item {} 
Mark D’Souza, 2007-2014

\item {} 
Hunter Matthews 2009-2014

\item {} 
Narayan Desai, 2011-2014

\item {} 
Wei Tang, 2012-2015

\item {} 
Daniel Braithwaite, 2012-2015

\item {} 
Elizabeth M. Glass, 2008-2016

\item {} 
Jared Bischof, 2010-2016

\item {} 
Kevin Keegan, 2009-2016

\item {} 
Tobias Paczian 2007 - 2018

\end{itemize}


\chapter{Under the hood: The MG-RAST technology platform}
\label{\detokenize{user_manual:under-the-hood-the-mg-rast-technology-platform}}

\section{The backend}
\label{\detokenize{user_manual:the-backend}}
While originally MG-RAST data was stored in a shared filesystem and a
MySQL database, the backend store evolved with growing popularity and
demand.

Currently a number of data stores are used to provide the underpinning
for various parts of the MG-RAST API.

An approximate mapping of stores to functions in version 4.0 is provided
in table {\hyperref[\detokenize{user_manual:xtab:v4-stores-to-API}]{\emph{{[}xtab:v4-stores-to-API{]}}}}.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Mapping of API functions to data stores}\label{\detokenize{user_manual:id13}}
\sphinxaftertopcaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
Function
&\sphinxstyletheadfamily 
data store
&\sphinxstyletheadfamily 
comment
\\
\hline
Search
&
Apache, SOLR and elastic search
&\\
\hline
Profiles
&
Cassandra and SHOCK
&\\
\hline
M5NR
&
Cassandra
&\\
\hline
Authentication
&
MySQL
&\\
\hline
Project
&
MySQL
&\\
\hline
Access control
&
MySQL
&\\
\hline
Metadata
&
MySQL
&\\
\hline
Files
&
SHOCK
&\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The backend infrastructure and the overall system layout is shown in
figure {\hyperref[\detokenize{user_manual:fig:2016-production}]{\emph{2.1}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{2016-production-overview}.png}
\caption{Overview of the production system in mid 2016. Fleet is used to
manage a number of containerized services (shown with dashed lines).
Two services are provisioned outside the Fleet system: SHOCK
(providing 0.7 Petabyte of storage) and a Postgres clusters. We note
the significant number of different databases used to serve data
required for the API.}\label{\detokenize{user_manual:fig-2016-production}}\end{figure}

As of version 3.6 the majority of the services are provisioned as
containers, provisioned as a set of Fleet units described in
\sphinxurl{https://github.com/MG-RAST/MG-RAST-infrastructure/tree/master/fleet-units}.


\section{The supporting technologies: Skyport, AWE and SHOCK}
\label{\detokenize{user_manual:the-supporting-technologies-skyport-awe-and-shock}}
One key aspect of scaling MG-RAST to large numbers of modern NGS
datasets is the use of cloud computing %
\begin{footnote}[2]\sphinxAtStartFootnote
We use the term \sphinxstyleemphasis{cloud} as a shortcut for Infrastructure as a Service
(IaaS).
%
\end{footnote}, which decouples MG-RAST
from its previous dedicated hardware resources.

We use AWE (Wilke et al. 2011) an efficient, open source resource
manager to execute the MG-RAST workflow. We expanded AWE to work with
Linux containers forming the Skyport system (Gerlach et al. 2014). AWE
and Skyport use RESTful interfaces thus allowing the addition of clients
without the need to add firewall exceptions and/or massive system
reconfiguration.

The main MG-RAST data store is the the SHOCK data management system
(Wilke et al. 2015) developed alongside AWE. SHOCK like AWE relies on a
RESTful interface instead of a more traditional shared file system.

When we introduced the technologies described above to replace a shared
file system (Sun NFS mounted on several hundred nodes), we saw a speed
up of a factor of 750x on identical hardware.


\section{Data model}
\label{\detokenize{user_manual:data-model}}
The MG-RAST data model (see Figure {\hyperref[\detokenize{user_manual:fig:data-model}]{\emph{2.2}}}) has
changed dramatically in order to handle the size of modern
next-generation sequencing datasets. In particular, we have made a
number of choices that reduce the computational and storage burden.

We note that the size of the derived data products for a next-generation
dataset in MG-RAST is typically about 10x the size of the actual
dataset. Individual datasets now may be as large as a terabase %
\begin{footnote}[3]\sphinxAtStartFootnote
This would be for several metagenomes that are part of the JGI
Prairie pilot.
%
\end{footnote},
with the on-disk footprint significantly larger than the basepair count
because of the inefficient nature of FASTQ files, which basically double
the on-disk size for FASTQ representations.
\begin{itemize}
\item {} 
Abundance profiles. Using abundance profiles, where we count the
number of occurrences of function or taxon per metagenomic dataset,
is one important factor that keeps the datasets manageable. Instead
of growing the dataset sizes (often with several hundred million
individual sequences per dataset), the data products now are more or
less static in size.

\item {} 
Single similarity computing step per feature type. By running exactly
one similarity computation for proteins and another one for rRNA
features, we have limited the computational requirements.

\item {} 
Clustering of features. By clustering features at 90\% identity, we
reduce the number of times we compute on similar proteins. Abundant
features will be even more efficiently clustered, leading to more
compression for abundant species.

\end{itemize}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{data-model}.png}
\caption{MG-RAST v3 data model.}\label{\detokenize{user_manual:fig-data-model}}\end{figure}

As shown in Figure {\hyperref[\detokenize{user_manual:fig:data-model}]{\emph{2.2}}}, MG-RAST relies on
abundance profiles to capture information for each metagenome. The
following abundance profiles are calculated for every metagenome.
\begin{itemize}
\item {} 
MD5s \textendash{} number of sequences (clusters) per database entry in the M5nr.

\item {} 
functions \textendash{} summary of all the MD5s that match a given function.

\item {} 
ontologies \textendash{} summary of all the MD5s that match a given hierarchy
entry.

\item {} 
organisms \textendash{} summary of all MD5s that match a given taxon entry.

\item {} 
lowest common ancestors

\end{itemize}

The static helper tables (show in blue in Figure
{\hyperref[\detokenize{user_manual:fig:mgrast_analysis-schema}]{\emph{{[}fig:mgrast\_analysis-schema{]}}}}) help
keep the main tables smaller, by normalizing and providing integer
representations for the entities in the abundance profiles.

THIS NEEDS TO BE REDONE!!!!!!

{[}fig:mgrast\_analysis-schema{]}


\chapter{The MG-RAST pipeline}
\label{\detokenize{user_manual:the-mg-rast-pipeline}}\label{\detokenize{user_manual:section-mgrast-pipeline-details}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{mgrastv3pipeline}.png}
\caption{Details of the analysis pipeline for MG-RAST version 3}\label{\detokenize{user_manual:fig-mgrast-v3-pipeline}}\end{figure}

MG-RAST provides automated processing of environmental DNA sequences via
a pipeline. The pipeline has multiple steps that can be grouped into
five stages:

We restrict the pipeline annotations to protein coding genes and
ribosomal RNA (rRNA) genes.
\begin{itemize}
\item {} 
\begin{DUlineblock}{0em}
\item[] Data hygiene:
\item[] Quality control and removal of artifacts.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] Feature extraction:
\item[] Identification of protein coding and rRNA features (aka “genes”)
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] Feature annotation:
\item[] Identification of putative functions and taxonomic origins for each
of the features
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] Profile generation:
\item[] Creation of multiple on disk representations of the information
obtained above.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] Data loading:
\item[] Loading the representations into the appropriate databases.
\end{DUlineblock}

\end{itemize}

The pipeline shown in Figure {\hyperref[\detokenize{user_manual:fig:mgrast-v3-pipeline}]{\emph{3.1}}} contains
a significant number of improvements over previous versions and is
optimized for accuracy and computational cost.

Using the M5nr (Wilke et al. 2012) (an MD5 nonredundant database), the
new pipeline computes results against many reference databases instead
of only SEED. Several key algorithmic improvements were needed to
support the flood of user-generated data (see Figure
{\hyperref[\detokenize{user_manual:fig:mgrast-job-sizes}]{\emph{{[}fig:mgrast-job-sizes{]}}}}). Using dedicated
software to perform gene prediction instead of using a similarity-based
approach reduces runtime requirements. The additional clustering of
proteins at 90\% identity reduces data while preserving biological
signals.

Below we describe each step of the pipeline in some detail. All datasets
generated by the individual stages of the processing pipeline are made
available as downloads. Appendix {\hyperref[\detokenize{user_manual:chapter:downloads}]{\emph{11}}} lists the
available files for each dataset.


\section{Data hygiene}
\label{\detokenize{user_manual:data-hygiene}}

\subsection{Preprocessing}
\label{\detokenize{user_manual:preprocessing}}
After upload, data is preprocessed by using SolexaQA (Cox, Peterson, and
Biggs 2010) to trim low-quality regions from FASTQ data.
Platform-specific approaches are used for 454 data submitted in FASTA
format: reads more than than two standard deviations away from the mean
read length are discarded following (Huse et al. 2007). All sequences
submitted to the system are available, but discarded reads will not be
analyzed further.


\subsection{Dereplication}
\label{\detokenize{user_manual:dereplication}}
For shotgun metagenome and shotgun metatranscriptome datasets we perform
a dereplication step. We use a simple k-mer approach to rapidly identify
all 20 character prefix identical sequences. This step is required in
order to remove Artificial Duplicate Reads (ADRs) (Gomez-Alvarez, Teal,
and Schmidt 2009). Instead of simply discarding the ADRs, we set them
aside and use them later for error estimation.

We note that dereplication is not suitable for amplicon datasets that
are likely to share common prefixes.


\subsection{DRISEE}
\label{\detokenize{user_manual:drisee}}\label{\detokenize{user_manual:section-drisee}}
MG-RAST v3 uses DRISEE (Duplicate Read Inferred Sequencing Error
Estimation) (Keegan et al. 2012) to analyze the sets of Artificial
Duplicate Reads (ADRs) (Gomez-Alvarez, Teal, and Schmidt 2009) and
determine the degree of variation among prefix-identical sequences
derived from the same template. See Section {\hyperref[\detokenize{user_manual:DRISEEDETAIL}]{\emph{4.2}}} for
details.


\subsection{Screening}
\label{\detokenize{user_manual:screening}}
The pipeline provides the option of removing reads that are near-exact
matches to the genomes of a handful of model organisms, including fly,
mouse, cow, and human. The screening stage uses Bowtie (Langmead et al.
2009) (a fast, memory-efficient, short read aligner), and only reads
that do not match the model organisms pass into the next stage of the
annotation pipeline.

Note that this option will remove all reads similar to the human genome
and render them inaccessible. This decision was made in order to avoid
storing any human DNA on MG-RAST.


\section{Feature identification}
\label{\detokenize{user_manual:feature-identification}}

\subsection{Protein coding gene calling}
\label{\detokenize{user_manual:protein-coding-gene-calling}}
The previous version of MG-RAST used similarity-based gene predictions,
an approach that is significantly more expensive computationally than de
novo gene prediction. After an in-depth investigation of tool
performance (Trimble et al. 2012), we have moved to a machine learning
approach: FragGeneScan (Rho, Tang, and Ye 2010). Using this approach, we
can now predict coding regions in DNA sequences of 75 bp and longer. Our
novel approach also enables the analysis of user-provided assembled
contigs.

We note that FragGeneScan is trained for prokaryotes only. While it will
identify proteins for eukaryotic sequences, the results should be viewed
as more or less random.


\subsection{rRNA detection}
\label{\detokenize{user_manual:rrna-detection}}
An initial search using vsearch (???) against a reduced RNA database
efficiently identifies ribosomal RNA. The reduced database is a 90\%
identity clustered version of the SILVA, Greengenes and RDP databases
and is used to rapidly identify sequences with similarities to ribosomal
RNA.


\section{Feature annotation}
\label{\detokenize{user_manual:feature-annotation}}

\subsection{Protein filtering}
\label{\detokenize{user_manual:protein-filtering}}
We indentify possibly protein coding regions overlapping ribosomal RNAs
and exclude them from further processing.


\subsection{AA clustering}
\label{\detokenize{user_manual:aa-clustering}}
MG-RAST builds clusters of proteins at the 90\% identity level using the
cd-hit (???) preserving the relative abundances. These clusters greatly
reduce the computational burden of comparing all pairs of short reads,
while clustering at 90\% identity preserves sufficient biological
signals.


\subsection{Protein identification}
\label{\detokenize{user_manual:protein-identification}}
Once created, a representative (the longest sequence) for each cluster
is subjected to similarity analysis.

For rRNA similarities, instead of BLAST we use sBLAT, an implementation
of the BLAT algorithm (Kent 2002), which we parallelized using OpenMP
(Board 2011) for this work.

As of version 4.04 we have migrated to DIAMOND(Buchfink, Xie, and Huson
2015) to compute protein similarities against M5nr (Wilke et al. 2012).
During computation protein and rRNA sequences are represented only via a
sequenced derived identifier (an MD5 checksum). Once the computation
completes, we generate a number of representations of the observed
similarities for various purposes.

Once the similarities are computed, we present reconstructions of the
species content of the sample based on the similarity results. We
reconstruct the putative species composition of the sample by looking at
the phylogenetic origin of the database sequences hit by the similarity
searches.

Sequence similarity searches are computed against a protein database
derived from the M5nr (Wilke et al. 2012), which provides nonredundant
integration of many databases: GenBank,(Benson et al. 2013), SEED
(Overbeek et al. 2005), IMG (Markowitz et al. 2008), UniProt (Magrane
and Consortium 2011), KEGG (Kanehisa 2002), and eggNOGs (Jensen et al.
2008).


\subsection{rRNA clustering}
\label{\detokenize{user_manual:rrna-clustering}}
The rRNA-similar reads are then clustered at 97\% identity using cd-hit,
and the longest sequence is picked as the cluster representative.


\subsection{rRNA identification}
\label{\detokenize{user_manual:rrna-identification}}
A BLAT similarity search for the longest cluster representative is
performed against the M5rna database which integrates SILVA(Pruesse et
al. 2007), Greengenes(DeSantis et al. 2006), and RDP(Cole et al. 2003).


\section{Profile generation}
\label{\detokenize{user_manual:profile-generation}}
In the final stage, the data computed so far is integrated into a number
of data products. The most important one are the abundance profiles.

Abundance profiles represent a pivoted and aggregated version of the
similarity files. We compute best hit, representative hit and LCA
abundance profiles (see {\hyperref[\detokenize{user_manual:section:hit-types}]{\emph{4.5}}}).


\section{Database loading}
\label{\detokenize{user_manual:database-loading}}
In the final step the profiles are loaded into the respective databases.


\chapter{MG-RAST data products}
\label{\detokenize{user_manual:mg-rast-data-products}}
MG-RAST provices a number of data products in a variety of formats.
\begin{itemize}
\item {} 
\begin{DUlineblock}{0em}
\item[] Fasta and FastQ
\item[] Sequence data can be downloaded via the API and web interface as
Fasta (or FastQ) files
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] JSON
\item[] Metadata and Tables and other structured data can be downloaded via
the APi or the web site in JSON format.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] Spreadsheet
\item[] Metadata and Tables can be downloaded as spreadsheets via the web
interface.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] SVG and PNG
\item[] Images can be downloaded via the web site interface in SVG and PNG
formast.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] BIOM v1
\item[] BIOM (McDonald et al. 2012) files can be downloaded via the web
interface for use with e.g., QIIME (Caporaso et al. 2010).
\end{DUlineblock}

\end{itemize}
\begin{itemize}
\item {} 
\begin{DUlineblock}{0em}
\item[] Sequence data
\item[] The originally submitted sequence data as well as the various
subsets resulting from processing can be downloaded.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] Metadata
\item[] data describing data in GSC-compliant format.
\end{DUlineblock}

\item {} 
Analysis results \textendash{} results of running the MG-RAST pipeline. The list
includes all intermediate data products and is intended to serve as a
basis for further analysis outside the MG-RAST pipeline.

Details on the individual files are in Appendix
{\hyperref[\detokenize{user_manual:chapter:downloads}]{\emph{11}}}.

\end{itemize}


\section{Abundance profiles}
\label{\detokenize{user_manual:abundance-profiles}}
Abundance profiles are the primary data product that MG-RAST’s user
interface uses to display information on the datasets.

Using the abundance profiles, the MG-RAST system defers making a
decision on when to transfer annotations. Since there is no well-defined
threshold that is acceptable for all use cases, the abundance profiles
contain all similarities and require their users to set cut-off values.

The threshold for annotation transfer can be set by using the following
parameters: e-value, percent identity, and minimal alignment length.

The taxonomic profiles use the NCBI taxonomy. All taxonomic information
is projected against this data. The functional profiles are available
for data sources that provide hierarchical information. These currently
comprise the following.
\begin{itemize}
\item {} 
SEED Subsystems

The SEED subsystems(Overbeek et al. 2005) represent an independent
reannotation effort that powers, for example, the RAST(Aziz et al.
2008) effort. Manual curation of subsystems makes them an extremely
valuable data source.

Subsystems represent a four-level hierarchy:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Subsystem level 1 \textendash{} highest level

\item {} 
Subsystem level 2 \textendash{}

\item {} 
Subsystem level 3 \textendash{} similar to a KEGG pathway

\item {} 
Subsystem level 4 \textendash{} actual functional assignment to the feature in
question

\end{enumerate}

The page at \sphinxurl{http://pubseed.theseed.org/SubsysEditor.cgi} allows
browsing the subsystems.

\item {} 
KEGG Orthologs

We use the KEGG(Kanehisa 2002) enzyme number hierarchy to implement a
four-level hierarchy.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
KEGG level 1 \textendash{} first digit of the EC number (EC:X.*.*.*)

\item {} 
KEGG level 2 \textendash{} first two digits of the EC number (EC:X.Y.*.*)

\item {} 
KEGG level 3 \textendash{} first three digits of the EC number (EC:X:Y:Z:.*)

\item {} 
KEGG level 4 \textendash{} entire four digits EC number

\end{enumerate}

We note that KEGG data is no longer available for free download. We
thus have to rely on using the latest freely downloadable version of
the data.

The high-level KEGG categories are as follows.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Cellular Processes

\item {} 
Environmental Information Processing

\item {} 
Genetic Information Processing

\item {} 
Human Diseases

\item {} 
Metabolism

\item {} 
Organizational Systems

\end{enumerate}

\item {} 
COG and EGGNOG Categories

The high-level COG and EGGNOG categories are as follows.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Cellular Processes

\item {} 
Information Storage and Processing

\item {} 
Metabolism

\item {} 
Poorly Characterized

\end{enumerate}

We note that for most metagenomes the coverage of each of the four
namespaces is quite different. The “source hits distribution” (see
Section
{\hyperref[\detokenize{user_manual:section:source-hits-distribution}]{\emph{{[}section:source-hits-distribution{]}}}})
provides information on how many sequences per dataset were found for
each database.

\end{itemize}


\section{DRISEE profile}
\label{\detokenize{user_manual:drisee-profile}}\label{\detokenize{user_manual:driseedetail}}
DRISEE (Keegan et al. 2012) is a method for measuring sequencing error
in whole-genome shotgun metagenomic sequence data that is independent of
sequencing technology and overcomes many of the shortcomings of Phred.
It utilizes artificial duplicate reads (ADRs) to generate internal
sequence standards from which an overall assessment of sequencing error
in a sample is derived. The current implementation of DRISEE is not
suitable for amplicon sequencing data or other samples that may contain
natural duplicated sequences (e.g., eukaryotic DNA where gene
duplication and other forms of highly repetitive sequences are common)
in high abundance.   DRISEE results are presented on the Overview page
for each MG-RAST sample for which a DRISEE profile can be determined.
Total DRISEE error presents the overall DRISEE-based assessment of the
sample as a percent error:
\begin{equation*}
\begin{split}Total \,\, DRISEE \,\, Error = \frac{base\_errors}{total\_bases} * 100\end{split}
\end{equation*}
where \({base\_errors}\) refers to the sum of DRISEE-detected errors
and \({total\_bases}\) refers to the sum of all bases considered by
DRISEE. Beneath the Total DRISEE Error, a barchart indicates the error
for the sample (the red vertical bar) as well as the minimum (barchart
initial value), maximum (barchart final value), mean \((\mu)\), mean
+/- one standard deviation (\(\sigma\)), and mean +/- two standard
deviations (\(2\sigma\)) Total DRISEE Errors observed among all
samples in MG-RAST for which a DRISEE profile has been computed.

The DRISEE plot presents a more detailed view of the DRISEE profile; the
DRISEE percent error is displayed per base. Individual errors (A,T,C,G,
and N substitution rates as well as the InDel rate) are presented as
well as a cumulative total.

Users can download DRISEE values as a tab-separated file. The first line
of the file contains headers for the values in the second line. The
second line contains DRISEE percent error values for A substitutions
(A\_err), T substitutions (T\_err), C substitutions (C\_err), G
substitutions (G\_err), N substitutions (N\_err), insertions and deletions
(InDel\_err), and the Total DRISEE Error. The third line indicates
headers for all remaining lines. Rows 4 and 4+ present the DRISEE counts
for the indexed position across all considered bins of ADRs. Column
values represent the number of reads that match an A,T,C,G,N, or InDel
at the indicated position relative to the appropriate consensus sequence
followed by the number of reads that do not match an A,T,C,G,N, or
InDel.


\section{Kmer profiles}
\label{\detokenize{user_manual:kmer-profiles}}
kmer digests are an annotation-independent method for describing
sequence datasets that can support inferences about genome size and
coverage. Here the Overview page presents several visualizations,
evaluated at k=15: the kmer spectrum, kmer rank abundance, and ranked
kmer consumed. All three graphs represent the same spectrum, but in
different ways. The kmer spectrum plots the number of distinct kmers
against kmer coverage; the kmer coverage is equivalent to number of
observations of each kmer. The kmer rank abundance plots the
relationship between kmer coverage and the kmer rank—answering the
question “What is the coverage of the nth most-abundant kmer?”. Ranked
kmer consumed plots the largest fraction of the data explained by the
nth most-abundant kmers only.


\section{Nucleotide histograms}
\label{\detokenize{user_manual:nucleotide-histograms}}
Nucleotide histograms are graphs showing the fraction of base pairs of
each type (A, C, G, T, or ambiguous base “N”) at each position starting
from the beginning of each read.

Amplicon datasets (see Figure {\hyperref[\detokenize{user_manual:fig:nucleotide-hist-amplicon}]{\emph{4.1}}})
should show biased distributions of bases at each position, reflecting
both conservation and variability in the recovered sequences:

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=4in]{{nucleotide-hist-amplicon}.png}
\caption{Nucleotide histogram with biased distributions typical for an
amplicon dataset.}\label{\detokenize{user_manual:fig-nucleotide-hist-amplicon}}\end{figure}

Shotgun datasets should have roughly equal proportions of A, T, G and C
basecalls, independent of position in the read as shown in Figure
{\hyperref[\detokenize{user_manual:fig:nucleotide-hist-ok}]{\emph{4.2}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=4in]{{nucleotide-hist-ok}.png}
\caption{Nucleotide histogram showing ideal distributions typical for a
shotgun metagenome.}\label{\detokenize{user_manual:fig-nucleotide-hist-ok}}\end{figure}

Vertical bars at the beginning of the read indicate untrimmed (see
Figure {\hyperref[\detokenize{user_manual:fig:nucleotide-hist-barcodes}]{\emph{4.3}}}), contiguous barcodes.
Gene calling via FragGeneScan (Rho, Tang, and Ye 2010) and RNA
similarity searches are not impacted by the presence of barcodes.
However, if a significant fraction of the reads is consumed by barcodes,
it reduces the biological information contained in the reads.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=4in]{{nucleotide-hist-barcodes}.png}
\caption{Nucleotide histogram with untrimmed barcodes.}\label{\detokenize{user_manual:fig-nucleotide-hist-barcodes}}\end{figure}

If a shotgun dataset has clear patterns in the data, these indicate
likely contamination with artificial sequences. The dataset shown in see
Figure {\hyperref[\detokenize{user_manual:fig:nucleotide-with-contamination}]{\emph{4.4}}} had a large fraction
of adapter dimers.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=4in]{{nucleotide-with-contamination}.png}
\caption{Nucleotide histogram with contamination.}\label{\detokenize{user_manual:fig-nucleotide-with-contamination}}\end{figure}


\section{Best hit, representative hit, and lowest common ancestor profiles}
\label{\detokenize{user_manual:best-hit-representative-hit-and-lowest-common-ancestor-profiles}}\label{\detokenize{user_manual:section-hit-types}}
Mapping the similarities between the predicted protein coding and rRNA
sequences to the databases results in files that map the predicted
sequences against database entries (“SIM files”). In some cases
sequences are identical between different database records, e.g. version
of E. coli might share identical proteins and it becomes impossible to
determine the “correct” organism name.

In those cases, the translation of those SIMS (that are against an
anonymous database, with merely MD5 hashes used as identifiers; see
M5NR) can be done in several different ways.
\begin{itemize}
\item {} 
best hit \textendash{} using one organisms

\item {} 
represenative hit \textendash{} we pick a random member of the group of idential
sequences, the strain you know to be in the sample might not be the
representative, the counts are correct, no inflation. (this will
ensure that your favorite strain is also listed, but leads to an
inflation in the counts)

\end{itemize}

Figures {\hyperref[\detokenize{user_manual:fig:UI-analysis-representative-hit}]{\emph{4.5}}} and
{\hyperref[\detokenize{user_manual:fig:UI-analysis-best-hit}]{\emph{4.6}}} show the effects of using the best
and representative hit strategies.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=4in]{{v402-UI-Analysis-best-hit-selected}.png}
\caption{Selecting best hit for mapping data from study mgp128 against
Subsystems.}\label{\detokenize{user_manual:fig-ui-analysis-representative-hit}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=4in]{{v402-UI-Analysis-representative-hit-selected}.png}
\caption{Selecting representative hit for mapping data from study mgp128
against Subsystems leads to inflated numbers.}\label{\detokenize{user_manual:fig-ui-analysis-best-hit}}\end{figure}

MG-RAST searches the nonredundant M5nr and M5rna databases in which each
sequence is unique. These two databases are built from multiple sequence
database sources, and the individual sequences may occur multiple times
in different strains and species (and sometimes genera) with 100\%
identity. In these circumstances, choosing the “right” taxonomic
information is not a straightforward process.

To optimally serve a number of different use cases, we have implemented
three methods\textendash{}best hit, representative hit, and lowest common
ancestor—for end users to determine the number of hits (occurrences of
the input sequence in the database) reported for a given sequence in
their dataset.


\subsection{Best hit}
\label{\detokenize{user_manual:best-hit}}
The best hit classification reports the functional and taxonomic
annotation of the best hit in the M5nr for each feature. In those cases
where the similarity search yields multiple same-scoring hits for a
feature, we do not choose any single “correct” label. For this reason we
have decided to double count all annotations with identical match
properties and leave determination of truth to our users. While this
approach aims to inform about the functional and taxonomic potential of
a microbial community by preserving all information, subsequent analysis
can be biased because of a single feature having multiple annotations,
leading to inflated hit counts. For users looking for a specific species
or function in their results, the best hit classification is likely what
is wanted.


\subsection{Representative hit}
\label{\detokenize{user_manual:representative-hit}}
The representative hit classification selects a single, unambiguous
annotation for each feature. The annotation is based on the first hit in
the homology search and the first annotation for that hit in our
database. This approach makes counts additive across functional and
taxonomic levels and thus allows, for example, the comparison of
functional and taxonomic profiles of different metagenomes.


\subsection{Lowest Common Ancestor (LCA)}
\label{\detokenize{user_manual:lowest-common-ancestor-lca}}\label{\detokenize{user_manual:section-lca}}
To avoid the problem of multiple taxonomic annotations for a single
feature, we provide taxonomic annotations based on the widely used LCA
method introduced by MEGAN (Huson et al. 2007). In this method all hits
are collected that have a bit score close to the bit score of the best
hit. The taxonomic annotation of the feature is then determined by
computing the LCA of all species in this set. This replaces all
taxonomic annotations from ambiguous hits with a single higher-level
annotation in the NCBI taxonomy tree.


\subsection{Comparison of methods}
\label{\detokenize{user_manual:comparison-of-methods}}
Users should be aware that the number of hits might be inflated if the
best hit filter is used or that a favorite species might be missing
despite a similar sequence similarity result if the representative hit
filter is used (in fact, even if a 100\% identical match to a favorite
species exists).

One way to consider both the best hit and representative hit is that
they overinterpret the available evidence. With the LCA classifier
function, on the other hand, any input sequence is classified only down
to a trustworthy taxonomic level. While naively this seems to be the
best function to choose in all cases because it classifies sequences to
varying depths, the approach causes problems for downstream analysis
tools that might rely on everything being classified to the same level.


\section{Numbers of annotations vs. number of reads}
\label{\detokenize{user_manual:numbers-of-annotations-vs-number-of-reads}}\label{\detokenize{user_manual:section-annotation-numbers}}
The MG-RAST v3 annotation pipeline does not usually provide a single
annotation for each submitted fragment of DNA. Steps in the pipeline map
one read to multiple annotations and one annotation to multiple reads.
These steps are a consequence of genome structure, pipeline engineering,
and the character of the sequence databases that MG-RAST uses for
annotation.

The first step that is not one-to-one is gene prediction. Long reads
(\(>\) \(400\)bp) and contigs can contain pieces of two or
more microbial genes; when the gene caller makes this prediction, the
multiple predicted protein sequences (called fragments) are annotated
separately.

An intermediate clustering step identifies sequences at 90\% amino acid
identity and performs one search for each cluster. Sequences that do not
fall into clusters are searched separately. The “abundance” column in
the MG-RAST tables presents the estimate of the number of sequences that
contain a given annotation, found by multiplying each selected database
match (hit) by the number of representatives in each cluster. The final
step that is not one-to-one is the annotation process itself. Sequences
can exist in the underlying data sources many times with different
labels. When those sequence are the best hit similarity, we do not have
a principled way to choosing the “correct” label. For this reason we
have decided to double count these annotations and leave determination
of truth to our users. Note: Even when considering a single data source,
double-counting can occur depending on the consistency of annotations.
Also note: Hits refer to the number of unique database sequences that
were found in the similarity search, not the number of reads. The hit
count can be smaller than the number of reads because of clustering or
larger due to double counting.


\section{Metadata}
\label{\detokenize{user_manual:metadata}}\label{\detokenize{user_manual:section-metadata}}
MG-RAST is both an analytical platform and a data integration system. To
enable data reuse, for example for meta-analyses, we require that all
data being made publicly available to third parties contain at least
minimal metadata. The MG-RAST team has decided to follow the minimal
checklist approach used by the Genomics Standards Consortium (GSC)(Field
et al. 2011).

While the GSC provides a GCDML (R. et al. 2008) encoding, this XML-based
format is more useful to programmers than to end users submitting data.
We have therefore elected to use spreadsheets to transport metadata.
Specifically we use MIxS (Minimum information about any (x) sequence
(MIxS) and MIMARKS (Minimum Information about a MARKer gene Survey) to
encode minimal metadata (Yilmaz et al. 2010).

The metadata describe the origins of samples and provide details on the
generation of the sequence data. While the GSC checklist aims at
capturing a minimum of information, MG-RAST can handle additional
metadata if supplied by the user. The metadata is stored in a simple key
value format and is displayed on the Metagenome Overview page.

Once uploaded, the metadata spreadsheets are validated automatically,
and users are informed of any problems.

The presence of metadata enables discovery by end users using contextual
metadata. Users can perform searches such as “retrieve soil samples from
the continental U.S.A.” If the users have added additional metadata
(domain specific extension), additional queries are enabled: for
example, “restrict the results to soils with a specific pH”.


\chapter{The version 4.0 web interface}
\label{\detokenize{user_manual:the-version-4-0-web-interface}}
\begin{DUlineblock}{0em}
\item[] The MG-RAST system provides a rich web user interface that covers all
aspects of the metagenome analysis, from data upload to ordination
analysis. The web interface can also be used for data discovery.
\sphinxstylestrong{Metadata} enables data discovery MG-RAST supports the widely used
MIxS and MIMARKS Standards (Yilmaz, 2011) (as well as domain-specific
plug-ins for specialized environments extending the minimal GSC
standards).
\item[] One key aspect of the MG-RAST approach is the creation of \sphinxstylestrong{smart data
products} enabling the user at the time of analysis to determine the
best parameters for, for example, a comparison between samples. This
is done without the need for recomputation of results.
\item[] We note that if you want to create links to the MG-RAST web site, you
should use the \sphinxstyleemphasis{linkin} mechanism instead of linking to any web page
directly. All pages intended for users to create external links
provide the linkin feature, See Section
{\hyperref[\detokenize{user_manual:section:linkin}]{\emph{{[}section:linkin{]}}}}.
\end{DUlineblock}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{quad-chart-analysis-example}.png}
\caption{(a) Using the web interface for a search of metagenomes for microbial
mats in hotsprings (GSC-MIMS-Keywords Biome=“hotspring; microbial
mat”), we find 6 metagenomes (refs: 4443745.3, 4443746.3, 4443747.3,
4443749.3, 4443750.3, 4443762.3). (b) Initial comparison reveals some
differences in protein functional class abundance (using SEED
subsystens level 1). (c) From the PCoA plot using normalized counts
of functional SEED Subsystem\textendash{}based functional annotations (level 2)
and Bray-Curtis as metric, we attempt to find differences between two
similar datasets (MG-RAST-IDs: 444749.3, 4443762.3). (d) Using
exported tables with functional annotations and taxonomic mapping, we
analyze the distribution of organisms observed to contain
beta-lactamase and plot the abundance per species for two distinct
samples.}\label{\detokenize{user_manual:fig-quad-chart-analysis-example}}\end{figure}

\begin{DUlineblock}{0em}
\item[] Starting with version 4.0 MG-RAST supports an HTML5/JavaScript based
web user interface. It supports any recent browser but is tested
primarily with Firefox.
\item[] Below we are iterating through the various pages in MG-RAST version 4.
\end{DUlineblock}

Figure {\hyperref[\detokenize{user_manual:fig:quad-chart-analysis-example}]{\emph{5.1}}} shows a sample
analysis with MG-RAST.


\section{The “My Data” page}
\label{\detokenize{user_manual:the-my-data-page}}
After login the user is directed to their personal “My Data” page (see
figure {\hyperref[\detokenize{user_manual:fig:v4-mydata}]{\emph{5.2}}}), their personal MG-RAST homepage.

This page is provides information on data sets currently being
processed, data sets owned by the user as well as any upcoming tasks for
the users (i.e. release data to the public after the expiration of the
quarantine period).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=7in]{{v4-my-data}.png}
\caption{The page shows currently running jobs, the tasks the user needs to
perform in the system, a list of their studies and more.}\label{\detokenize{user_manual:fig-v4-mydata}}\end{figure}

In addition to the data items mentioned above, the page also contains a
list of the collections (see {\hyperref[\detokenize{user_manual:Collections}]{\emph{{[}Collections{]}}}}) owned by
the user.


\section{Browsing, searching and viewing studies}
\label{\detokenize{user_manual:browsing-searching-and-viewing-studies}}

\subsection{The search page}
\label{\detokenize{user_manual:the-search-page}}\label{\detokenize{user_manual:section-search-page}}
The search page lists all available metagenomic data sets and allows
filtering. The looking glass symbol provides access to the search page,
there are also shortcuts to the search function on multiple pages.

The basic function of the Search page is to find data sets that (1)
contain a search string in the metadata (dataset name, project name,
project description, GSC metadata), (2) contain specific functions
(e.g., SEED functional roles, SEED subsystems, or GenBank annotations),
or (3) contain specific organisms. The default search uses all three
kinds of data.

In addition to a Google-like search that searches all data fields, we
provide specialized searches in one of the three data types.

We note that due to data visibility (see
{\hyperref[\detokenize{user_manual:section:data-visibility}]{\emph{{[}section:data-visibility{]}}}}) not all data
sets are visible to all users.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=7in]{{v4-search-page}.png}
\caption{The search page.}\label{\detokenize{user_manual:fig-v4-search}}\end{figure}

The search page has two components, the output widget (see figure
{\hyperref[\detokenize{user_manual:fig:v4-search}]{\emph{5.3}}}) and the refinement widget.

The refinement widget allows filtering, the creation of saved searches
and the creation of collections.


\subsection{The study page}
\label{\detokenize{user_manual:the-study-page}}
Data in MG-RAST is organized in studies (formerly known as Projects),
each study has an automatically generated page.

The study page displays a project title, project description and other
study specific information such as funding information. Users are
encouraged to provide information on the project in addition to the
metadata. The study page also includes the ability to display analysis
results generated with the MG-RAST user interface.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=7in]{{v4-study-page}.png}
\caption{A study page.}\label{\detokenize{user_manual:fig-v4-study}}\end{figure}

The study page provides a number of tools to the data set owner:
\begin{itemize}
\item {} 
\begin{DUlineblock}{0em}
\item[] Sharing
\item[] Studies in MG-RAST while initially private (see
{\hyperref[\detokenize{user_manual:section:data-visibility}]{\emph{{[}section:data-visibility{]}}}}) can be
shared with others. Simply provide any email address for an
individual and they will be send a token that allows data access.
Sharing is intended to allow pre-publication data sharing.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] Reviewer access
\item[] Reviewer access tokens can be embedded in Manuscripts (or their
cover letters) to allow reviewers and editors access to the data
sets.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] Data Publication
\item[] Data can be made public. This option will generate the only kind of
identifiers that should be used in publications.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] Metadata editor
\item[] Complete or correct the metadata.
\end{DUlineblock}

\end{itemize}


\section{Information about specific data sets (Overview page)}
\label{\detokenize{user_manual:information-about-specific-data-sets-overview-page}}
MG-RAST automatically creates an individual summary page for each
dataset. This metagenome overview page provides a summary of the
annotations for a single dataset. The page is made available by the
automated pipeline once the computation is finished. The page is
generated using default values for annotation transfer parameters (e.g.
e-values) and thus likely does not represent good biological
information, for that please use the Analysis page (see below).

However the Overview page is a good starting point for looking at a
particular dataset. It provides a significant amount of information on
technical details and biological content.

\begin{DUlineblock}{0em}
\item[] The page is intended as a single point of reference for metadata,
quality, and data. It also provides an initial overview of the
analysis results for individual datasets with default parameters.
Further analyses are available on the Analysis page.
\item[] There are four different types of Overview pages that are displayed as
required by the data:
\end{DUlineblock}
\begin{itemize}
\item {} 
Amplicon metagenome overview page

\item {} 
Shotgun metagenome overview page

\item {} 
Assembled shotgun metagenome overview page

\item {} 
Metatranscriptome overview page

\end{itemize}

While the different types of overview pages are mostly identical, some
visualizations are not relevant or even possible for certain data types.
The decision which type of page to display is made based on the data,
not the metadata provided by the user.

Previous version of MG-RAST provided almost complete \sphinxstylestrong{download} access
to the underlying data, with version 4.0 we have expanded that to all
tables and figures. The symbol shown in Figure
{\hyperref[\detokenize{user_manual:fig:download-symbol}]{\emph{5.5}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=1in]{{download-symbol}.png}
\caption{The download symbol, providing access to the API call and the data in
a variety of formats. The (i) displays the API call used to generate
the respective data and the pull down menu provides access in variety
of formats.}\label{\detokenize{user_manual:fig-download-symbol}}\end{figure}

The Overview page provides the MG-RAST ID for a data set, a unique
identifier that is usable as accession number for publications.
Additional information such as the name of the submitting PI and
organization and a user-provided metagenome name are displayed at the
top of the page as well. A static URL for linking to the system that
will be stable across changes to the MG-RAST web interface is provided
as additional information (Figure {\hyperref[\detokenize{user_manual:fig:metagenome-overview}]{\emph{5.7}}}).

\sphinxstylestrong{Please note:} Until the data is released to the public, temporary
identifiers are made available that will be replaced by permanent valid
IDs at the time of data release. The temporary identifiers are long
numbers used to represent the data sets until they are public. Do not
use temporary identifiers in publications as they are designed to change
over time. An example for a temporary ID is
\sphinxcode{\sphinxupquote{4fbfe5d4216d676d343733343339372e33}}. A valid MG-RAST identifier is
\sphinxcode{\sphinxupquote{mgm4447101.3}}. Both the API and the web site work with temporary IDs
and MG-RAST IDs.

The results on the Overview page (e.g. link) represent a quick summary
of the biological and technical content of each data set. In the past we
use a relatively simple approach (best-hit) to compute the biological
information. Our reasoning was based on the fact that the “real”
meaningful data was presented via the Analysis Page.

With version 4.04 we are now presenting an updated Overview page,
results on this page are based on the lowest common ancestor (LCA)
algorithm (see Figure {\hyperref[\detokenize{user_manual:fig:lca}]{\emph{5.6}}}). The LCA (or most recent
common ancestor) for a given DNA sequence is computed by evaluating the
set of similarities observed when matching the sequence against a number
of databases.

To put this in very simple language, when faced with uncertainty about
which species to choose (e.g. when faced with a protein shared by many
E. coli species), the MG-RAST Overview page will display a genus level
result Escherichia (one level up from species). Likewise if no decision
can be made between Escherichia and Shigella (both genera), the LCA will
be set to Enterobacteriaceae.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=3in]{{lca-figure}.png}
\caption{Determining the LCA.}\label{\detokenize{user_manual:fig-lca}}\end{figure}

Faced with a decision between multiple strain level hits (purple and
orange) for different species, the LCA algorithm will pick higher
(genus) level entity.

We note that this will change results for some data sets and cause the
analysis pages to look differently, the underlying sequence analysis
however is not affected, we merely set a new default value for the
generation of overview graphs on this page.

Repeat: The scientific results (presented via the Analysis page) for
download or comparison are not affected.

Additional reading:
\sphinxurl{https://en.wikipedia.org/wiki/Most\_recent\_common\_ancestor} .

We point the readers attention to the download symbols next to each
figure and or table, providing access to the data and API calls
underlying each display item.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=7in]{{v4-metagenome-overview-page}.png}
\caption{Top of the metagenome Overview page.}\label{\detokenize{user_manual:fig-metagenome-overview}}\end{figure}

We provide an automatically generated paragraph of text describing the
submitted data and the results computed by the pipeline. By means of the
project information we display additional information provided by the
data submitters at the time of submission or later.


\subsection{Sequence and feature breakdown}
\label{\detokenize{user_manual:sequence-and-feature-breakdown}}
One of the first places to look at for each data set are the function
and feature breakdown at the top of each overview page.

The pie charts at the top of the overview page (Figure
{\hyperref[\detokenize{user_manual:fig:classification-pie-chart}]{\emph{5.8}}}) classify the submitted
sequences submitted into several categories according to their QC
results, sequences are classified as having failed QC (grey), containing
at least one feature (purple) and unknown if they do not contain any
recognized feature (red). In addition the predicted features are broken
up into unknown protein (yellow), annotated protein (green) and
ribosomal RNA (blue) in a second pie chart.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{v4-overviewpage-quality-pie-charts}.png}
\caption{The first pie charts classifies the sequences submitted in this data
set according to their QC results, the 2nd breaks down the detected
features in to several categories.}\label{\detokenize{user_manual:fig-classification-pie-chart}}\end{figure}


\subsubsection{What about other feature types?}
\label{\detokenize{user_manual:what-about-other-feature-types}}
We note that for performance reasons no other sequence features are
annotated by the default pipeline. Other feature types such as small
RNAs or regulatory motifs (e.g., CRISPRs (Bolotin et al. 2005)) not only
will require significantly higher computational resources but also are
frequently not supported by the unassembled short reads that constitute
the vast majority of todays metagenomic data in MG-RAST. The quality of
the sequence data coming from next-generation instruments requires
careful design of experiments, lest the sensitivity of the methods is
greater than the signal-to-noise ratio the data supports.


\subsection{Metadata}
\label{\detokenize{user_manual:id4}}
The overview page also provides metadata for each dataset to the extent
that such information has been made available. Metadata enables other
researchers to discover datasets and compare annotations. MG-RAST
requires standard metadata for data sharing and data publication. This
is implemented using the standards developed by the Genomics Standards
Consortium. Figure {\hyperref[\detokenize{user_manual:fig:GSC-MIxS-checklist-information}]{\emph{5.9}}} shows
the metadata summary for a dataset.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=3.5in]{{GSC-MIxS-checklist-information}.png}
\caption{Information from the GSC MIxS checklist providing minimal metadata on
the sample.}\label{\detokenize{user_manual:fig-gsc-mixs-checklist-information}}\end{figure}

All metadata stored for a specific dataset is available in MG-RAST; we
merely display a standardized subset in this table. A link at the bottom
of the table (“More Metadata”) provides access to a table with the
complete metadata. This enables users to provide extended metadata going
beyond the GSC minimal standards. A mechanism to provide community
consensus extensions to the minimal checklists and the environmental
packages are explicitly encouraged but not required when using MG-RAST.


\subsubsection{Functional and taxonomic breakdowns}
\label{\detokenize{user_manual:functional-and-taxonomic-breakdowns}}
A number of pie charts are computed, represening a breakdown of the data
into different taxonomic ranks (domain, phylum, class, order, family,
genus) an the top levels of the four supported controlled annotation
namespaces (Subsystems, Kegg Orthologues (KOGS), COGs and Eggnogs
(NOGS)).


\subsubsection{Rank abundance}
\label{\detokenize{user_manual:rank-abundance}}
The rank abundance plot (Figure {\hyperref[\detokenize{user_manual:fig:rank-abundance}]{\emph{5.10}}}) provides
a rank-ordered list of taxonomic units at a user-defined taxonomic
level, ordered by their abundance in the annotations.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=3in]{{rank-abundance}.png}
\caption{Sample rank abundance plot by phylum.}\label{\detokenize{user_manual:fig-rank-abundance}}\end{figure}


\subsubsection{Rarefaction}
\label{\detokenize{user_manual:rarefaction}}
The rarefaction curve of annotated species richness is a plot (see
Figure {\hyperref[\detokenize{user_manual:fig:rarefaction}]{\emph{5.11}}} of the total number of distinct
species annotations as a function of the number of sequences sampled.
The slope of the right-hand part of the curve is related to the fraction
of sampled species that are rare. On the left, a steep slope indicates
that a large fraction of the species diversity remains to be discovered.
If the curve becomes flatter to the right, a reasonable number of
individuals is sampled: more intensive sampling is likely to yield only
few additional species. Sampling curves generally rise quickly at first
and then level off toward an asymptote as fewer new species are found
per unit of individuals collected.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{rarefaction}.png}
\caption{Rarefaction plot showing a curve of annotated species richness. This
curve is a plot of the total number of distinct species annotations
as a function of the number of sequences sampled.}\label{\detokenize{user_manual:fig-rarefaction}}\end{figure}

The rarefaction curve is derived from the protein taxonomic annotations
and is subject to problems stemming from technical artifacts. These
artifacts can be similar to the ones affecting amplicon sequencing
(Reeder and Knight 2009), but the process of inferring species from
protein similarities may introduce additional uncertainty.


\subsubsection{Alpha diversity}
\label{\detokenize{user_manual:alpha-diversity}}
In this section we display an estimate of the alpha diversity based on
the taxonomic annotations for the predicted proteins. The alpha
diversity is presented in context of other metagenomes in the same
project (see Figure {\hyperref[\detokenize{user_manual:fig:alpha-diversity}]{\emph{5.12}}}).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{alpha-diversity}.png}
\caption{Alpha diversity plot showing the range of \(\alpha\)-diversity
values in the project the data set belongs to. The min, max, and mean
values are shown, with the standard deviation ranges (\(\sigma\)
and \(2\sigma\)) in different shades. The
\(\alpha\)-diversity of this metagenome is shown in red.}\label{\detokenize{user_manual:fig-alpha-diversity}}\end{figure}

The alpha diversity estimate is a single number that summarizes the
distribution of species-level annotations in a dataset. The Shannon
diversity index is an abundance-weighted average of the logarithm of the
relative abundances of annotated species.

We compute the species richness as the antilog of the Shannon diversity:
\begin{equation*}
\begin{split}\textrm{Richness} = 10^{-\sum_i  p_i \log(p_i) }\end{split}
\end{equation*}
where \(p_i\) are the proportions of annotations in each of the
species categories. Shannon species richness has units of the “effective
number of species”. Each \(p\) is a ratio of the number of
annotations for each species to the total number of annotations. The
species-level annotations are from all the annotation source databases
used by MG-RAST. The table of species and number of observations used to
calculate this diversity estimate can be downloaded under “download
source data” on the Overview page.


\subsubsection{Functional categories}
\label{\detokenize{user_manual:functional-categories}}
This section contains four pie charts providing a breakdown of the
functional categories for KEGG (Kanehisa 2002), COG (Tatusov et al.
2003), SEED Subsystems (Overbeek et al. 2005), and eggNOGs (Jensen et
al. 2008). The relative abundance of sequences per functional category
can be downloaded as a spreadsheet, and users can browse the functional
breakdowns via the Krona tool (Ondov, Bergman, and Phillippy 2011)
integrated in the page.

A more detailed functional analysis, allowing the user to manipulate
parameters for sequence similarity matches, is available from the
Analysis page.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=4in]{{subsystems-functions-piechart}.png}
\caption{The Subsystems function piechart, showing reads classified into SEED
subsystem level-one functions. In contrast to the COG, eggNOG, and
KEGG classification schemes, there are over 20 top-level subsystem
categories, creating a more highly resolved “fingerprint” for the
metagenome.}\label{\detokenize{user_manual:fig-subsystems-functions-piechart}}\end{figure}


\subsubsection{The sample page}
\label{\detokenize{user_manual:the-sample-page}}
For each sample MG-RAST displays a sample page shown in figure
{\hyperref[\detokenize{user_manual:fig:v4-sample-page}]{\emph{5.14}}}, the page displays all sample specific
information. The information on this page is derived from the metadata.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{v4-sample-page}.png}
\caption{A sample page.}\label{\detokenize{user_manual:fig-v4-sample-page}}\end{figure}


\subsubsection{The library page}
\label{\detokenize{user_manual:the-library-page}}
For each set of sequences underlying a data set (“a library”) MG-RAST
provides a specific page with information extracted from the metadata.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{v4-library-page}.png}
\caption{A library page.}\label{\detokenize{user_manual:fig-v4-library-page}}\end{figure}


\section{The analysis page \textendash{} Comparing data, extracting and downloading data}
\label{\detokenize{user_manual:the-analysis-page-comparing-data-extracting-and-downloading-data}}\label{\detokenize{user_manual:section-analysis-page}}
The Analysis page is the core of the MG-RAST system, it consumes the
various profiles and allows adjusting of parameters.

. It provides a number of tools to compare data sets with different
parameters as well as the ability to drill down into the data (e.g.
selecting Actinobacteria or features related to a specific functional
gene group (e.g. the Lysine Biosynthesis Subsystem).

Compared to previous version of MG-RAST the Analysis page has seen
significant improvements, here we provide a step-by-step guide to using
the page


\subsection{Download profiles to local machine for analysis}
\label{\detokenize{user_manual:download-profiles-to-local-machine-for-analysis}}
Profiles to be compared, analyzed or visualized need to be downloaded.
Figure {\hyperref[\detokenize{user_manual:fig:v4-analysis-profile-load}]{\emph{5.16}}} shows an example
download of 8 profiles.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{v4-analysis-page-profile-load}.png}
\caption{After selecting a project (“mgp128”) the Refseq and Subsystem
profiles for the respective data sets are loaded. Blue progress bars
indicated profiles being uploaded, green bars indicate the download
has completed.}\label{\detokenize{user_manual:fig-v4-analysis-profile-load}}\end{figure}

After the profiles have been downloaded, the analysis is no longer
dependent on the MG-RAST server resources, instead using the computer
the browser is running on. This is achieved via the JavaScript
functionality in your browser (please make sure its enabled). Also data
is stored in memory, providing you with a good reason to maximize the
memory (RAM) of the machine you are running the analysis on.


\subsection{Normalization}
\label{\detokenize{user_manual:normalization}}
Normalization refers to a transformation that attempts to reshape an
underlying distribution. MG-RAST now uses DEseq, which is an R package
to analyse count data from high-throughput sequencing assays. DESeq, as
it has been shown to outperform other methods of normalization - in
particular, those that use any sort of linear scaling.

Standardization is a transformation applied to each distribution in a
group of distributions so that all distributions exhibit the same mean
and the same standard deviation. This removes some aspects of
intersample variability and can make data more comparable. This sort of
procedure is analogous to commonly practiced scaling procedures but is
more robust in that it controls for both scale and location.

The Analysis page calculates the ordination visualizations with either
raw or normalized counts, at the user’s option. The normalization
procedure is as follows.

\(normalized\_value\_i = log2(raw\_counts\_i + 1)\)

The standardized values then are calculated from the normalized values
by subtracting the mean of each sample’s normalized values and dividing
by the standard deviation of each sample’s normalized values.

\(standardized\_i = (normalized\_i - mean(normalized\_i)) / stddev(normalized\_i)\)

More about these procedures is available in a number of texts. We
recommend Terry Speed’s “Statistical Analysis of Gene Expression in
Microarray Data” (Speed 2003).

When data exhibit a nonnormal, normal, or unknown distribution,
nonparametric tests (e.g., Man-Whitney or Kurskal-Wallis) should be
used. Boxplots are easy to use, and the MG-RAST analysis page provides
boxplots of the standardized abundance values for checking the
comparability of samples (Figure {\hyperref[\detokenize{user_manual:fig:boxplots}]{\emph{5.17}}}).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=3in]{{boxplots}.png}
\caption{Boxplots of the abundance data for raw values (top) as well as values
that have undergone the normalization and standardization procedures
(bottom) described in the text. After normalization and
standardization, samples exhibit value distributions that are much
more comparable and that have a normal distribution; the normalized
and standardized data are suitable for analysis with parametric
tests; the raw data are not.}\label{\detokenize{user_manual:fig-boxplots}}\end{figure}


\subsection{Rarefaction}
\label{\detokenize{user_manual:section-analysis-page-rarefaction}}\label{\detokenize{user_manual:id5}}
The rarefaction view is available only for taxonomic data. The
rarefaction curve of annotated species richness is a plot (see Figure
{\hyperref[\detokenize{user_manual:fig:analysis-page-rarefaction-example}]{\emph{5.18}}}) of the total number
of distinct species annotations as a function of the number of sequences
sampled. As shown in Figure
{\hyperref[\detokenize{user_manual:fig:analysis-page-rarefaction-example}]{\emph{5.18}}}, multiple data sets
can be included.

The slope of the right-hand part of the curve is related to the fraction
of sampled species that are rare. When the rarefaction curve is flat,
more intensive sampling is likely to yield only a few additional
species. The rarefaction curve is derived from the protein taxonomic
annotations and is subject to problems stemming from technical
artifacts. These artifacts can be similar to the ones affecting amplicon
sequencing (Reeder and Knight 2009), but the process of inferring
species from protein similarities may introduce additional uncertainty.

On the Analysis page the rarefaction plot serves as a means of comparing
species richness between samples in a way independent of the sampling
depth.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{analysis-page-rarefaction-example}.png}
\caption{Rarefaction plot showing a curve of annotated species richness. This
curve is a plot of the total number of distinct species annotations
as a function of the number of sequences sampled.}\label{\detokenize{user_manual:fig-analysis-page-rarefaction-example}}\end{figure}

On the left, a steep slope indicates that a large fraction of the
species diversity remains to be discovered. If the curve becomes flatter
to the right, a reasonable number of individuals is sampled: more
intensive sampling is likely to yield only a few additional species.

Sampling curves generally rise very quickly at first and then level off
toward an asymptote as fewer new species are found per unit of
individuals collected. These rarefaction curves are calculated from the
table of species abundance. The curves represent the average number of
different species annotations for subsamples of the the complete
dataset.


\subsection{KEGG mapper}
\label{\detokenize{user_manual:kegg-mapper}}\label{\detokenize{user_manual:section-kegg-mapper}}
The KEGG map tool allows the visual comparison of predicted metabolic
pathways in metagenomic samples. It maps the abundance of identified
enzymes onto a KEGG (Kanehisa 2002) map of functional pathways; note
that the mapper is available only for functional data). Users can select
from any available KEGG pathway map. Different colors indicate different
metagenomic datasets.

The KEGG mapper works by providing two buffers that users can assign
datasets to. After loading the buffers with the intended datasets, the
KEGG mapper can highlight parts of the KEGG map that are present in the
dataset. Several combinations of the two datasets can be displayed, as
shown in Figure {\hyperref[\detokenize{user_manual:fig:analysis-page-kegg-mapper-options}]{\emph{5.19}}}.
Metagenomes can be assigned into one of two groups, and those groups can
be visually compared (see Figure
{\hyperref[\detokenize{user_manual:fig:analysis-page-kegg-mapper-example}]{\emph{5.20}}}).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=2in]{{analysis-page-kegg-mapper-options}.png}
\caption{Options available for coloring the KEGG maps.}\label{\detokenize{user_manual:fig-analysis-page-kegg-mapper-options}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{analysis-page-kegg-mapper-example}.png}
\caption{Comparison of two datasets using the KEGG mapper. Parts of metabolism
common are shown in purple; unique to A are in blue; unique to B are
in red.}\label{\detokenize{user_manual:fig-analysis-page-kegg-mapper-example}}\end{figure}


\subsection{Bar charts}
\label{\detokenize{user_manual:bar-charts}}\label{\detokenize{user_manual:section-bar-charts}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{analysis-page-bar-chart}.png}
\caption{Bar chart view comparing normalized abundance of taxa. We have
expanded the Bacteria domain to display the next level of the
hierarchy.}\label{\detokenize{user_manual:fig-analysis-page-bar-chart}}\end{figure}

Figure {\hyperref[\detokenize{user_manual:fig:analysis-page-bar-chart}]{\emph{5.21}}} shows the bar chart
visualization option on the Analysis page. One important property of the
page is the built-in ability to drill down by clicking on a specific
category. In this example we have expanded the domain Bacteria to show
the normalized abundance (adjusted for sample sizes) of bacterial phyla.
The abundance information displayed can be downloaded into a local
spreadsheet. Once a subselection has been made (e.g., the domain
Bacteria selected).


\subsection{Heatmap/Dendrogram}
\label{\detokenize{user_manual:heatmap-dendrogram}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=4in]{{heatmap}.png}
\caption{Heatmap/dendogram example in MG-RAST. The MG-RAST heatmap/dendrogram
has two dendrograms, one indicating the similarity/dissimilarity
among metagenomic samples (x axis dendrogram) and another indicating
the similarity/dissimilarity among annotation categories (e.g.,
functional roles; the y-axis dendrogram).}\label{\detokenize{user_manual:fig-heatmap}}\end{figure}

The heatmap/dendrogram (Figure {\hyperref[\detokenize{user_manual:fig:heatmap}]{\emph{5.22}}}) allows an
enormous amount of information to be presented in a visual form that is
amenable to human interpretation. Dendrograms are trees that indicate
similarities between annotation vectors. The MG-RAST heatmap/dendrogram
has two dendrograms, one indicating the similarity/dissimilarity among
metagenomic samples (x-axis dendrogram) and another indicating the
similarity/dissimilarity among annotation categories (e.g., functional
roles; the y-axis dendrogram). A distance metric is evaluated between
every possible pair of sample abundance profiles. A clustering algorithm
(e.g., ward-based clustering) then produces the dendrogram trees. Each
square in the heatmap dendrogram represents the abundance level of a
single category in a single sample. The values used to generate the
heatmap/dendrogram figure can be downloaded as a table by clicking on
the download button.


\subsection{Ordination}
\label{\detokenize{user_manual:ordination}}
MG-RAST uses Principle Coordinate Analysis (PCoA) to reduce the
dimensionality of comparisons of multiple samples that consider
functional or taxonomic annotations. Dimensionality reduction is a
process that allows the complex variation found in a large datasets
(e.g., the abundance values of thousands of functional roles or
annotated species across dozens of metagenomic samples) to be reduced to
a much smaller number of variables that can be visualized as simple two-
or three-dimensional scatter plots. The plots enable interpretation of
the multidimensional data in a human-friendly presentation. Samples that
exhibit similar abundance profiles (taxonomic or functional) group
together, whereas those that differ are found farther apart.

A key feature of PCoA-based analyses is that users can compare
components not just to each other but to metadata recorded variables
(e.g., sample pH, biome, DNA extraction protocol) to reveal correlations
between extracted variation and metadata-defined characteristics of the
samples. It is also possible to couple PCoA with higher-resolution
statistical methods in order to identify individual sample features
(taxa or functions) that drive correlations observed in PCoA
visualizations. This coupling can be accomplished with permutation-based
statistics applied directly to the data before calculation of distance
measures used to produce PCoAs; alternatively, one can apply
conventional statistical approaches (e.g., ANOVA or Kruskal-Wallis test)
to groups observed in PCoA-based visualizations.


\subsection{Table}
\label{\detokenize{user_manual:table}}
The table tool creates a spreadsheet-based abundance table that can be
searched and restricted by the user. Tables can be generated at
user-selected levels of phylogenetic or functional resolution. Table
data can be visualized by using Krona (Ondov, Bergman, and Phillippy
2011) or can be exported in BIOM(McDonald et al. 2012) format to be used
in other tools (e.g., QIIME (Caporaso et al. 2010)). The tables also can
be exported as tab-separated text.

Abundance tables serve as the basis for all comparative analysis tools
in MG-RAST, from PCoA to heatmap/dendrograms.

Consider the following example showing how to use the taxonomic
information derived from an analysis of protein similarities found for
the data set 4447970.3. We use the best hit classification, SEED
database, \(10^{-5}\) evalue, 60\% identity, and a minimal alignment
length of 15 amino acids. We select table output. The results are shown
in Figure {\hyperref[\detokenize{user_manual:fig:analysis-page-table}]{\emph{5.23}}}.

The following control elements are connected to the table:
\begin{itemize}
\item {} 
group by \textendash{} allows summarizing entries below the level chosen here to
be subsumed.

\item {} 
download table \textendash{} downloads the entire table as a spreadsheet.

\item {} 
Krona \textendash{} invokes KRONA (Ondov, Bergman, and Phillippy 2011) with the
table data.

\item {} 
QIIME \textendash{} creates a BIOM(McDonald et al. 2012) format file with the
data being displayed in the table.

\item {} 
table size \textendash{} changes the number of elements to display for the web
page.

\end{itemize}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{analysis-page-table}.png}
\caption{View of the analysis page table.}\label{\detokenize{user_manual:fig-analysis-page-table}}\end{figure}

Below we explain the columns of the table and the functions available
for them. For each column we allow sorting the table by clicking on the
upward- and downward-pointing triangles.
\begin{itemize}
\item {} 
metagenome

In the case of multiple datasets being displayed, this column allows
sorting by metagenome ID or selection of a single metagenome.

\item {} 
source

This displays the annotation source for the data being displayed.

\item {} 
domain

The domain column allows subselecting from Archaea, Bacteria,
Eukarya, and Viruses.

\item {} 
phylum, class

Since we have selected to group results at the class level, only
phylum and class are being displayed. The text fields in the column
headers allow subsection (e.g., by entering Acidobacteria or
Actinobacteria in the phylum field). The searches are performed
inside the web browser and are efficient.

Any subselection will narrow down all datasets being displayed in the
table.

Users can elect to have the results grouped by other taxonomy levels
(e.g., genus), creating more columns in the table view.

\item {} 
abundance

This indicates the number of sequences found with the parameters
selected matching this taxonomic unit. (Note that the parameters
chosen are displayed on top of the table.) Clicking on the abundance
displays another page displaying the BLAT alignments underlying the
assignments.

The abundance is calculated by multiplying the actual number of
database hits found for the clusters by the number of cluster
members.

\item {} 
avg. evalue, avg percent identity, average alignment length

These indicate the average values for E value, percent identity, and
alignment length.

\item {} 
hits

This is the number of clusters found for this entity (function or
taxon) in the metagenome.

\item {} 
…

This option allows extending the table to display (or hide)
additional columns.

\end{itemize}


\subsection{The parameter widget}
\label{\detokenize{user_manual:the-parameter-widget}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{v4-analysis-page-parameters-initial}.png}
\caption{After loading all profiles, the analysis parameter widget is
displayed.}\label{\detokenize{user_manual:fig-v4-analysis-page-parameters-initial}}\end{figure}


\subsubsection{Evalue, percent identity, length and minimum abundance filters}
\label{\detokenize{user_manual:evalue-percent-identity-length-and-minimum-abundance-filters}}
As shown in Figure {\hyperref[\detokenize{user_manual:fig:v4-analysis-page-evalue-filter}]{\emph{5.25}}}
MG-RAST can changed the parameters for annotation transfer at analysis
time. As each data and each analysis is different, we cannot provide a
default parameter set for transferring annotations from the sequence
databases to the features predicted for the environmental sequence data.

Instead we provide a tool that puts the user at the helm, providing the
means to filter the sequences down by selecting only those matching
certain criteria.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=4in]{{v4-analysis-page-evalue-filter}.png}
\caption{By changing the e-value, minimum required percent identity or
alignment length the annotations to the features loaded, can be
modified. We note that the number of hits listed below the filter is
reduced and the display is adjusted instanteneously.}\label{\detokenize{user_manual:fig-v4-analysis-page-evalue-filter}}\end{figure}


\subsubsection{*Source type and level filters}
\label{\detokenize{user_manual:source-type-and-level-filters}}
Adding one or more filters will limit the scope of the sequences
analyzed to e.g. a the domain Bacteria (see Figure
{\hyperref[\detokenize{user_manual:fig:v4-analysis-page-domain-filter}]{\emph{5.26}}}). We note that multiple
filters can be used and they can be individually erased when no longer
needed. Thus the user can filter, e.g. a certain phylum and the identify
reads associated with a specific functional gene group.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=4in]{{v4-analysis-page-domain-filter}.png}
\caption{Adding a domain level filter for Bacteria. The filter is displayed as
a blue box and is clearly labeled.}\label{\detokenize{user_manual:fig-v4-analysis-page-domain-filter}}\end{figure}


\subsubsection{*Example: Display abundance for functional category filtered by taxonomic entities}
\label{\detokenize{user_manual:example-display-abundance-for-functional-category-filtered-by-taxonomic-entities}}
A key feature of the version 4.0 web interface is the ability to filter
results. Here we demonstrate filtering results down to the domain
Bacteria (Figure
{\hyperref[\detokenize{user_manual:fig:v4-Analysis-page-filtering-for-Bacteria-settings}]{\emph{5.27}}}). After
the filtering we select COG functional annotations using COG level 2
(Figure
{\hyperref[\detokenize{user_manual:fig:v4-Analysis-page-COG-Level2-for-Bacteria-settings}]{\emph{5.28}}}).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=4in]{{v4-Analysis-page-filtering-for-Bacteria-settings}.png}
\caption{The parameter widget allows creation of a Filter for taxonomic units,
in this case we use RefSeq annotation to filter at the domain level
for Bacteria.}\label{\detokenize{user_manual:fig-v4-analysis-page-filtering-for-bacteria-settings}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=4in]{{v4-Analysis-page-COG-Level2-for-Bacteria-settings}.png}
\caption{After creating a filter for Bacteria only (using RefSeq taxonomic
annotations) we select COG functional annotations using COG level 2.}\label{\detokenize{user_manual:fig-v4-analysis-page-cog-level2-for-bacteria-settings}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=4in]{{v4-Analysis-page-COG-Level2-for-Bacteria-results}.png}
\caption{COG level 2 abundance filtered for Bacteria. The results for the
settings shown in Figure
{\hyperref[\detokenize{user_manual:fig:v4-Analysis-page-COG-Level2-for-Bacteria-settings}]{\emph{5.28}}}}\label{\detokenize{user_manual:fig-v4-analysis-page-cog-level2-for-bacteria-results}}\end{figure}


\section{Viewing Evidence}
\label{\detokenize{user_manual:viewing-evidence}}
For individual proteins, the MG-RAST page allows users to retrieve the
sequence alignments underlying the annotation transfers (see Figure
{\hyperref[\detokenize{user_manual:fig:blat-alignment}]{\emph{5.30}}}). Using the M5nr (Wilke et al. 2012)
technology, users can retrieve alignments against the database of
interest with no additional overhead.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{blat-alignment}.png}
\caption{BLAT hit details with alignment.}\label{\detokenize{user_manual:fig-blat-alignment}}\end{figure}


\chapter{Standard operating procedures SOPs for MG-RAST}
\label{\detokenize{user_manual:standard-operating-procedures-sops-for-mg-rast}}

\section{SOP - Metagenome submission, publication and submission to INSDC via MG-RAST}
\label{\detokenize{user_manual:sop-metagenome-submission-publication-and-submission-to-insdc-via-mg-rast}}
MG-RAST can be used to host data for public access. There are three
interfaces for uploading and publishing data, the Web interface,
intended for most users, command line scripts, intended for programmers,
and the native RESTful API, recommended for experienced programmers.

When data is published in MG-RAST, it can also be released to the INSDC
databases. This tutorial covers both use cases.

We note that MG-RAST provides temporary IDs and permanent public
identifiers. The permanent identifiers are assigned at the time data is
made public. Permanent MG-RAST identifiers begin with “mgm” (e.g.
“mgm4449249.3”) for data sets and mgp (e.g.”mgp128”) for
projects/studies.

The following data types are supported:
\begin{itemize}
\item {} 
Shotgun metagenomes (“raw” and assembled)

\item {} 
Metatranscriptome data (“raw” and assembled)

\item {} 
Ribosomal amplicon data (16s, 18s, ITS amplicons)

\item {} 
Metabarcoding data (e.g. cytochrome C amplicons; basically all non
ribosomal amplicons)

\end{itemize}

PLEASE NOTE: We strongly prefer raw data over assembled data, if you
submit assembled data, please submit the raw reads in parallel. If you
perform local optimization e.g. adapter removal or quality clipping,
please submit the raw data as well.

This document is intended for experienced to very experienced users and
programmers. We recommend that most users not use the RESTful API. There
is also a document describing data publication and INSDC submission via
the web UI.

An access token for the MG-RAST API, this can be obtained from the
MG-RAST web page (\sphinxurl{http://mg-rast.org}) in the user section.

You will need a working python interpreter and the command line scripts
and example data can be found in
\sphinxurl{https://github.com/MG-RAST/MG-RAST-Tools}:

Scripts: MG-RAST-Tools/tools/bin Data: MG-RAST-Tools/examples/sop/data

Change into MG-RAST-Tools/examples/sop/data and call:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{sh} \PYG{n}{get\PYGZus{}test\PYGZus{}data}\PYG{o}{.}\PYG{n}{sh}
\end{sphinxVerbatim}

to add additional example data.

Either download the repository as a zipped archive from
\sphinxurl{https://github.com/MG-RAST/MG-RAST-Tools/archive/master.zip} or use the
git command line tool:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{git} \PYG{n}{clone} \PYG{n}{http}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{github}\PYG{o}{.}\PYG{n}{com}\PYG{o}{/}\PYG{n}{MG}\PYG{o}{\PYGZhy{}}\PYG{n}{RAST}\PYG{o}{/}\PYG{n}{MG}\PYG{o}{\PYGZhy{}}\PYG{n}{RAST}\PYG{o}{\PYGZhy{}}\PYG{n}{Tools}\PYG{o}{.}\PYG{n}{git}
\end{sphinxVerbatim}

We tested up to the following parameters:
\begin{itemize}
\item {} 
max. size per file: 10GB

\item {} 
max. project size: 200 metagenomes

\end{itemize}

While there is no reason to assume the software will not work with
larger numbers of files or larger files, we did not test for that.


\subsection{SOP:}
\label{\detokenize{user_manual:sop}}
Upload and submit sequence data and metadata to MG-RAST using the
command mg-submit.py Note: This is an asynchronous process that may take
some time depending on the size and number of datasets. (Note: We
recommend that novice users try the web frontend; the cmd-line is
primarily intended for programmers) The metadata in this example is in
Microsoft Excel format, there is also an option of using JSON formatted
data. Please note: We have observed multiple problems with spreadsheets
that were converted from older version of Excel or “compatible” tools
e.g. OpenOffice.

Example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{submit}\PYG{o}{.}\PYG{n}{py} \PYG{n}{submit} \PYG{n}{simple}  \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}  \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{metadata}
\end{sphinxVerbatim}

Verify the results and obtain a temporary identifier E.g. by using the
WebUI at \sphinxurl{http://mg-rast.org} \textendash{} you can also use that to publish the data
and trigger submission to INSDC.

Publish your project in MG-RAST and obtain a stable and public MG-RAST
project identifier

Note: once the data is made public the data is read only, but metadata
can be improved

Example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
mg\PYGZhy{}project make\PYGZhy{}public \PYGZdl{}temporary\PYGZus{}ID
\end{sphinxVerbatim}

Trigger release to INSDC/ submit to EBI

Note: Metadata updates are automatically synced with INSDC databases
within 48 hours.

Example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
mg\PYGZhy{}project submit\PYGZhy{}ebi \PYGZdl{}PROJECT\PYGZus{}ID
\end{sphinxVerbatim}

Check status of release to INSDC/ submission to EBI

Note: This is an asynchronous process that may take some time depending
on the size and number of datasets.

Example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
mg\PYGZhy{}project status\PYGZhy{}ebi \PYGZdl{}PROJECT\PYGZus{}ID
\end{sphinxVerbatim}

We include a sample submission below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
From within the MG\PYGZhy{}RAST\PYGZhy{}Tool repository directory

\PYGZsh{} Retrieve repository and setup environment
git clone http://github.com/MG\PYGZhy{}RAST/MG\PYGZhy{}RAST\PYGZhy{}Tools.git
cd MG\PYGZhy{}RAST\PYGZhy{}Tools

\PYGZsh{} Path to scripts for this example
PATH=\PYGZdl{}PATH:{}`pwd{}`/tools/bin

\PYGZsh{} set environment variables
source set\PYGZus{}env.sh

\PYGZsh{} Set credentials, obtain token from your user preferences in the UI
mg\PYGZhy{}submit.py login \PYGZhy{}\PYGZhy{}token

\PYGZsh{} Create metadata spreadsheet. Make sure you map your samples to your
\PYGZsh{} sequence files
\PYGZsh{} Upload metagenomes and metadata to MG\PYGZhy{}RAST

mg\PYGZhy{}submit.py submit simple \PYGZbs{}
           examples/sop/data/sample\PYGZus{}1.fasta.gz \PYGZbs{}
           examples/sop/data/sample\PYGZus{}2.fasta.gz \PYGZbs{}
           \PYGZhy{}\PYGZhy{}metadata examples/sop/data/metadata.xlsx

\PYGZsh{} Output
\PYGZgt{} Temp Project ID: ed2102aa666d676d343735323836382e33
\PYGZgt{} Submission ID: 77a1a1a5\PYGZhy{}4cbd\PYGZhy{}4673\PYGZhy{}86bf\PYGZhy{}f87c9096c3e1

\PYGZsh{} Remember IDs for later use
SUBMISSION\PYGZus{}ID=77a1a1a5\PYGZhy{}4cbd\PYGZhy{}4673\PYGZhy{}86bf\PYGZhy{}f87c9096c3e1
TEMP\PYGZus{}ID=mgp128

\PYGZsh{} Check if project is finished
mg\PYGZhy{}submit.py status \PYGZdl{}SUBMISSION\PYGZus{}ID

\PYGZsh{} Output
\PYGZgt{} Submission: 77a1a1a5\PYGZhy{}4cbd\PYGZhy{}4673\PYGZhy{}86bf\PYGZhy{}f87c9096c3e1 Status: in\PYGZhy{}progress


\PYGZsh{} Make project public in MG\PYGZhy{}RAST
mg\PYGZhy{}project.py make\PYGZhy{}public \PYGZdl{}TEMP\PYGZus{}ID

\PYGZsh{} Output
\PYGZgt{} \PYGZsh{} Your project is public.
\PYGZgt{} Project ID: mgp128
\PYGZgt{} URL: https://mg\PYGZhy{}rast.org/linkin.cgi?project=mgp128
PROJECT\PYGZus{}ID=mgp128

\PYGZsh{} Release project to INSDC archives
mg\PYGZhy{}project.py submit\PYGZhy{}ebi \PYGZdl{}PROJECT\PYGZus{}ID

\PYGZsh{} Output
\PYGZgt{} \PYGZsh{} Your Project mgp128 has been submitted
\PYGZgt{} Submission ID: 0cf7d811\PYGZhy{}1d43\PYGZhy{}4554\PYGZhy{}ab97\PYGZhy{}3cb1f5ceb6aa

\PYGZsh{} Check if project is finished
mg\PYGZhy{}project.py status\PYGZhy{}ebi \PYGZdl{}PROJECT\PYGZus{}ID

\PYGZsh{} Output
\PYGZgt{} Completed
\PYGZgt{} ENA Study Accession: ERP104408
\end{sphinxVerbatim}


\subsection{REST API uploader}
\label{\detokenize{user_manual:rest-api-uploader}}
The following upload instructions are for using the MG-RAST REST API
with the curl program. In order to operate the API the user has to
authenticate with an MG-RAST token. The token can be retrieved from the
“Account Management” \textendash{}\(>\) “Manage personal preferences” \textendash{}\(>\)
“Web Services” \textendash{}\(>\) “authentication key” page via MG-RAST Web
site.

We strongly suggest that you use the scripts we provide, instead of the
native REST API.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
\item {} 
You can upload a file into your inbox with

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{curl} \PYG{o}{\PYGZhy{}}\PYG{n}{X} \PYG{n}{POST} \PYG{o}{\PYGZhy{}}\PYG{n}{H} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{auth: \PYGZlt{}myToken\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{n}{F} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{upload=@\PYGZlt{}path\PYGZus{}to\PYGZus{}file\PYGZgt{}/\PYGZlt{}file\PYGZus{}name\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://api.mg\PYGZhy{}rast.org/inbox}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

\item {} 
If you have a compressed file to upload, supports gzip or bzip2

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{curl} \PYG{o}{\PYGZhy{}}\PYG{n}{X} \PYG{n}{POST} \PYG{o}{\PYGZhy{}}\PYG{n}{H} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{auth: \PYGZlt{}myToken\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{n}{F} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{upload=@\PYGZlt{}path\PYGZus{}to\PYGZus{}file\PYGZgt{}/\PYGZlt{}gzip\PYGZus{}file\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{n}{F} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{compression=gzip}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://api.mg\PYGZhy{}rast.org/inbox}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{curl} \PYG{o}{\PYGZhy{}}\PYG{n}{X} \PYG{n}{POST} \PYG{o}{\PYGZhy{}}\PYG{n}{H} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{auth: \PYGZlt{}myToken\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{n}{F} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{upload=@\PYGZlt{}path\PYGZus{}to\PYGZus{}file\PYGZgt{}/\PYGZlt{}gzip\PYGZus{}file\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{n}{F} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{compression=bzip2}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://api.mg\PYGZhy{}rast.org/inbox}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

\item {} 
If you have an archive file containing multiple files to upload do
the following two steps, supports: .zip, .tar, .tar.gz, .tar.bz2

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+m+mf}{1.} \PYG{n}{curl} \PYG{o}{\PYGZhy{}}\PYG{n}{X} \PYG{n}{POST} \PYG{o}{\PYGZhy{}}\PYG{n}{H} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{auth: \PYGZlt{}myToken\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{n}{F} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{upload=@\PYGZlt{}path\PYGZus{}to\PYGZus{}file\PYGZgt{}/\PYGZlt{}archive\PYGZus{}file\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://api.mg\PYGZhy{}rast.org/inbox}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+m+mf}{2.} \PYG{n}{curl} \PYG{o}{\PYGZhy{}}\PYG{n}{X} \PYG{n}{POST} \PYG{o}{\PYGZhy{}}\PYG{n}{H} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{auth: \PYGZlt{}myToken\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{n}{F} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{format=\PYGZlt{}one of: zip, tar, tar.gz, tar.bz2\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://api.mg\PYGZhy{}rast.org/inbox/unpack/\PYGZlt{}uploaded\PYGZus{}file\PYGZus{}id\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

\end{enumerate}


\subsection{Generating metadata for the submission}
\label{\detokenize{user_manual:generating-metadata-for-the-submission}}\label{\detokenize{user_manual:section-generating-metadata}}
MG-RAST uses questionnaires to capture metadata for each project with
one or more samples. Users have two options, they can download and fill
out the questionnaire and then submit it or use our online editor,
MetaZen. Questionnaires are validated automatically by MG-RAST for
completeness and compliance with the controlled vocabularies for certain
fields.

MG-RAST has implemented the use of Minimum Information about any (X)
Sequence (MIxS)(Yilmaz et al. 2010) developed by the Genomic Standards
Consortium. In addition to the minimal checklists, more detailed data
can be captured in optional environmental packages.

We use simple spreadsheets to capture metadata, with a minimal number of
required fields (in red in the spreadsheets) and a number of optional
fields. The spreadsheet is separated into multiple tabs representing the
different metadata categories. The MG-RAST metadata spreadsheet template
is available on the MG-RAST upload page or at
\sphinxurl{ftp://ftp.mg-rast.org/data/misc/metadata/MGRAST\_MetaData\_template\_1.3.xlsx}.

A filled-out version of the spreadsheet is available at
\sphinxurl{ftp://ftp.mg-rast.org/data/misc/metadata/MGRAST\_MetaData\_template\_example.xlsx}.

In Figure {\hyperref[\detokenize{user_manual:fig:project-spreadsheet}]{\emph{9.4}}} we show the template tab
for project and the required field labels (in red) (in essence, your
contact information). Figure
{\hyperref[\detokenize{user_manual:fig:project-spreadsheet-multiple-tabs}]{\emph{9.5}}} shows the various tabs
in the spreadsheet.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{project-spreadsheet}.png}
\caption{Project spreadsheet. In red are required fields. Note that the 2nd
row contains information on how to fill out the form.}\label{\detokenize{user_manual:fig-project-spreadsheet}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{project-spreadsheet-multiple-tabs}.png}
\caption{The various tabs in the spreadsheet. Project, sample and one of
library metagenome or library mimarks survey are required.}\label{\detokenize{user_manual:fig-project-spreadsheet-multiple-tabs}}\end{figure}

Note: Use the third line in the spreadsheet and as shown in Figure
{\hyperref[\detokenize{user_manual:fig:project-spreadsheet-with-3-samples}]{\emph{9.6}}} to enter your data. Do
not attempt to alter the first two lines or delete them; they are read
only. The first line contains the field labels, and the second line
contains descriptions that can help explain how to fill out the fields,
along with what unit to use (e.g., temperature in Celsius and distance
in meters), URL for the bioportal ontology site etc..

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{project-spreadsheet-with-3-samples}.png}
\caption{Sample tab with 3 new samples (sample1, sample2, and sample3) added.
Again red text in the first row indicates required fields. Rows 1 and
2 cannot be altered.}\label{\detokenize{user_manual:fig-project-spreadsheet-with-3-samples}}\end{figure}

Required sheets

You need to fill out four sheets to describe your metadata:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Project \textendash{} This sheet has only one row, and describes a set of samples
uploaded together; the other sheets have one row per sample.

\item {} 
Sample \textendash{} This sheet includes either the filename or metagenome name
used for matching.

\item {} 
Library \textendash{} This sheet includes either the metagenome (for WGS and
WXS), mimarks-survey (for 16s and amplicon) or metatranscriptome.

\item {} 
Environmental package (ep) \textendash{} Several packages of suggested standard
metadata are available. Choose the package that best describes your
dataset (e.g., water, human-skin, soil).

\end{enumerate}

Sample sheet

The sample sheet requires minimal information (including the sample
name) about where and when the sample was taken. Note that some fields
in the spreadsheet must be filled out with terms from a controlled
vocabulary or in a certain way. Country and environment (biome, feature,
material) fields require entries from curated ontologies, gazetteer and
environmental ontology, respectively.

Figure {\hyperref[\detokenize{user_manual:fig:project-spreadsheet-with-3-samples}]{\emph{9.6}}} shows the
sample tab with three new samples (sample1, sample2, and sample3) added.
Again red text in the first row indicates required fields.

Mandatory fields

Five fields must be completed.
\begin{itemize}
\item {} 
Country \textendash{} e.g. United States of America, Netherlands, Australia,
Uruguay

\item {} 
Latitude and longitude \textendash{} e.g. {[}106.84517, -104.60667{]},
{[}2842.306:math:\sphinxtitleref{’}N, 8824.099\('\)W{]}, {[}45.30 N, 73.35 W{]}

\item {} 
Biome \textendash{} e.g. small lake biome, urban biome, mangrove biome. This term
must be one of the terms from the bioportal ontology
(\sphinxurl{http://bioportal.bioontology.org/ontologies/1069?p=terms\&conceptid=ENVO\%3A00000428}).
Terms that are not listed on this site are not valid.

\item {} 
Feature \textendash{} e.g. city, fish farm, livestock-associated habitat, marine
habitat, ocean basin, microbial mat. This term must be one of the
terms from the bioportal ontology. Terms that are not listed on this
site are not valid.

\item {} 
Material \textendash{} e.g. air, dust, volcanic soil, saliva, blood, dairy
product, surface water, piece of gravel. This term must be one of the
terms from the bioportal ontology. Terms that are not listed on this
site are not valid.

\end{itemize}

Library section

The library section captures technical data on the preparation and
sequencing done. You should choose the library tab to fill out
(“metagenome” for shotgun sequencing, “mimarks-survey” for amplicon or
“metatranscriptome”) based on the type of sequencing done. These are
separated as different sequencing techniques involving different
metadata fields. Each row describes one library for one sample. The
required fields are colored red.

The \sphinxstylestrong{sample\_name} value in the library sheet must exactly match one of
the values used in the sample sheet.

The \sphinxstylestrong{file\_name} field holds the filename of the sequence file
uploaded, or the filename to use for creating the demultiplexed file if
you uploaded a multiplexed sequence file and have barcode sequences in
the spreadsheet. This is used for mapping sequence files to metadata.

The \sphinxstylestrong{metagenome\_name} field holds the name of the metagenome you are
submitting. If the file\_name field is empty, the metagenome\_name will be
used to map metadata to sequence files, in this case it would need to
match the uploaded sequence filename without the file extension, e.g. a
sequence file “test-sequence.fasta” would be mapped to the metadata in
the row which has the metagenome\_name value “test-sequence”.

The \sphinxstylestrong{investigation\_type} field is required to be “metagenome” for
shotgun metagenome samples, “mimarks-survey” for amplicon studies or
“metatrascriptome”, reflecting which tab was filled out.

The type of sequencing instrument used is another required field. Values
are, for example, Sanger, pyrosequencing, ABI-solid, 454, Illumina,
assembled, other.

Again, only a limited number of fields are required. However, the more
information you provide, the easier it is for you and others to
understand any potential uses of your data and to understand why results
appear in a particular way. It might, for example, allow understanding
of specific biases caused by technology choices or sampled environments.

Environmental Package (ep) sheet

You can fill out one or more environmental metadata packages. Currently
we provide support for the following GSC environmental packages:
\begin{itemize}
\item {} 
Air

\item {} 
Built Environment

\item {} 
Host-associated

\item {} 
Human-associated

\item {} 
Human-oral

\item {} 
Human-skin

\item {} 
Human-gut

\item {} 
Human-vaginal

\item {} 
Microbial mat/biofilm

\item {} 
Miscellaneous natural or artificial environment

\item {} 
Plant-associated

\item {} 
Sediment

\item {} 
Soil

\item {} 
Wastewater sludge

\item {} 
Water

\end{itemize}

We strongly encourage users to submit rich metadata, but we understand
the effort required in providing it. Using the environmental packages
(which were designed and are used by practitioners in the respective
field) should make it reasonably simple to report the essential metadata
required to analyze the data. If there is no environmental package to
report metadata for your specific sample, please contact MG-RAST staff:
we will work with the GSC(Field et al. 2011) to create the required
questionnaire.


\subsubsection{Using MetaZen}
\label{\detokenize{user_manual:using-metazen}}\label{\detokenize{user_manual:section-using-metazen}}
MG-RAST uses a simple spreadsheet with 12 mandatory terms. MetaZen
designed to help you fill out your metadata spreadsheet. The metadata
you provide, helps us to analyze your data more accurately and helps
make MG-RAST a more useful analysis resource for everyone.

This tool will help you get started on completing your metadata
spreadsheet by filling in any information that is common across all of
your samples and/or libraries. This tool currently only allows users to
enter one environmental package for your samples and all samples must
have been sequenced by the same number of sequencing technologies with
the same number of replicates. This information is entered in tab 2.

Note: If your project deviates from this convention, you must either
produce multiple separate metadata spreadsheets or generate your
spreadsheet and then edit the appropriate fields manually.

Metazen’s online form allows users to either use an existing project, or
add in new information to start a new project (Figure
{\hyperref[\detokenize{user_manual:fig:metazen_form}]{\emph{{[}fig:metazen\_form{]}}}}). Users will expand each tab
and fill in their metadata information. One of the benefits to using
this form is that it provides compliant ENVO terms to select from to
describe your sample, without the cumbersome task of looking them up
outside of MG-RAST. Figure
{\hyperref[\detokenize{user_manual:fig:metazen_expanded}]{\emph{{[}fig:metazen\_expanded{]}}}} shows an example of
this for entering in environmental information.

The first tab is for project information where you enter the project
name and description as well as PI information, information for the
technical contact and cross-references to different analysis tools so
that your dataset can be linked across these resources.

What you enter in the second tab (sample set information) will dictate
what the next tabs will be. Note: You must submit the information here
before proceeding with the rest of the form. Enter the information about
your set of samples. First, indicate the total number of samples in your
set. Second, tell us which environmental package your samples belong to.
Then, indicate how many times each of your samples was sequenced by each
sequencing method. Each entry of more than zero for number of shotgun,
metatranscriptome or amplicon libraries will produce an additional tab
to fill out about your sample (Figure
{\hyperref[\detokenize{user_manual:fig:metazen_step2}]{\emph{{[}fig:metazen\_step2{]}}}}. Once you add or change
information into this form you will need to press the button “show
library input forms” to update subsequent tabs.

Note: It is allowable to indicate here if your samples were sequenced
using more than one sequencing method.

Once the data has been entered, click on “download excel spreadsheet” to
download your filled sheet. You can now use this for upload and
submission to MG-RAST.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{metazen_form}.png}
\caption{The Metazen form for filling out metadata allows users to fill in
data online and add data to existing projects or start new ones. Tabs
are expandable and reveal forms for the various required metadata
sections.}\label{\detokenize{user_manual:id14}}\end{figure}

{[}fig:metazen\_form{]}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{metazen_expanded}.png}
\caption{The Metazen form for filling out metadata allows users to fill in
data using standard nomenclature.}\label{\detokenize{user_manual:id15}}\end{figure}

{[}fig:metazen\_expanded{]}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{metazen_step2}.png}
\caption{The second tab in the Metazen form must be filled out before moving
further down the forms. Selecting the number of libraries (other than
zero) adds forms for those libraries. Click on the “show library
input forms” button to display them. If no libraries are entered,
then only the default tabs for environment and sample information are
provided.}\label{\detokenize{user_manual:id16}}\end{figure}

{[}fig:metazen\_step2{]}


\subsection{Can I upload files to my inbox through the MG-RAST API?}
\label{\detokenize{user_manual:can-i-upload-files-to-my-inbox-through-the-mg-rast-api}}
Yes. You can upload files to your user inbox using the MG-RAST API with
the command-line tool cURL, invoked as:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{curl} \PYG{o}{\PYGZhy{}}\PYG{n}{H} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{auth: webkey}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{n}{X} \PYG{n}{POST} \PYG{o}{\PYGZhy{}}\PYG{n}{F} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{upload=@/path\PYGZus{}to\PYGZus{}file/metagenome.fasta}\PYG{l+s+s2}{\PYGZdq{}}
          \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://api.mg\PYGZhy{}rast.org/1/inbox/}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZgt{}} \PYG{n}{curl\PYGZus{}output}\PYG{o}{.}\PYG{n}{txt}
\end{sphinxVerbatim}

where you need to substitute “webkey” with the unique string of text
generated by MG-RAST for your account. Your webkey is valid for a
limited time period and ensures that the uploads you perform from the
command line are recognized as belonging to your MG-RAST account and
placed in the correct inbox.


\subsection{How do I handle the metadata for paired end reads?}
\label{\detokenize{user_manual:how-do-i-handle-the-metadata-for-paired-end-reads}}
With paired reads (e.g. R1 and R2) the reads can be merged prior to
submission, in this case the metadata should only refer to the new
merged reads.

You only need to include metadata for the R1 and R2 reads separately if
you choose to treat the second read (R2) as a technical replicate. The
mate pair merging can be handled by the Web UI by the submission script
we provide in the MG-RAST tools repository. TBA


\subsection{What type of sequence files should I upload?}
\label{\detokenize{user_manual:what-type-of-sequence-files-should-i-upload}}
Your sequence data can be in FASTA, FASTQ or SFF format. These are
recognized by the file name extension with valid extensions for the
appropriate formats .fasta, .fna, .fastq, .fq, and .sff and FASTA and
FASTQ files need to be in plain text ASCII. Compressing large files will
reduce the upload time and the chances of a failed upload, you can use
gzip (.gz), bzip2 (.bz2) Zip (.zip less than 4 GB in size) as well as
tar archives compressed with gzip (.tar.gz) or bzip2 (.tar.bz2), rar
files are not accepted. We suggest you upload raw data (in FASTQ or SFF
format) and let MG-RAST perform the quality control step, see Section
{\hyperref[\detokenize{user_manual:section:mgrast_pipeline_details}]{\emph{3}}} for details.


\subsection{What type of sequence files should I NOT upload?}
\label{\detokenize{user_manual:what-type-of-sequence-files-should-i-not-upload}}
MG-RAST will not analyze the following:
\begin{itemize}
\item {} 
protein sequences,

\item {} 
WGS reads \textless{}75bp,

\item {} 
complete genomes,

\item {} 
sequence data less than 1Mbp,

\item {} 
sequences containing alignment information,

\item {} 
ABIsolid sequences in colorspace,

\item {} 
rar compressed files,

\item {} 
Zip files over 4GB,

\item {} 
Word documents,

\item {} 
Rich Text Format files, and

\item {} 
files without the extension .fna, .fasta, .fq, .fastq or .sff in
their name.

\end{itemize}


\subsection{How do I prepare my metadata for upload?}
\label{\detokenize{user_manual:how-do-i-prepare-my-metadata-for-upload}}
You can submit metadata for your samples during the upload/submission
process. The metadata is transferred to MG-RAST in a spreadsheet in
which you can enter metadata for one or more samples along with
information about the project the samples should be placed in. Step one
in the first section, ‘Prepare data’, has the empty metadata spreadsheet
template available for download with the required fields labeled in red.
The metadata is hierarchical with three levels, project, sample and
library. There has to be a sequence file corresponding to each library
entry and the sequence filename must match the library file\_name fields
or match the library metagenome\_name fields minus extension. Once you
have filled out the spreadsheet with metadata you can upload it along
with the sequence files to your inbox with the MG-RAST uploader.


\subsection{Will my metadata file in .xls format work OK?}
\label{\detokenize{user_manual:will-my-metadata-file-in-xls-format-work-ok}}
Yes, the site is designed to handle .xls metadata files and we have
successfully tested uploading and validating .xls files. The metadata
template file we provide is a .xlsx file and that is the preferred
format If you do experience problems with a .xls file being recognized,
Microsoft provides a convertor to the .xslx format:
\begin{itemize}
\item {} 
for Mac:

\sphinxurl{http://www.microsoft.com/mac/downloads?pid=Mactopia\_AddTools\&fid=6B9238E1-CF69-48C4-BF2D-C4A8ACEEE520}

\item {} 
for Windows:

\sphinxurl{http://www.microsoft.com/en-us/download/details.aspx?id=3}

\end{itemize}


\subsection{How are the projects listed on the upload page during submission selected?}
\label{\detokenize{user_manual:how-are-the-projects-listed-on-the-upload-page-during-submission-selected}}
During the submission process, you can choose to place the new datasets
in an existing project. All the projects you have write access to will
be listed for selection, this includes all the projects you own as well
as projects owned by other users for which you have been granted write
access. You can also specify a particular project from this list in the
metadata template file or create a new project for your dataset(s) by
typing in the name.


\subsection{How much time will it take to upload my data to MG-RAST?}
\label{\detokenize{user_manual:how-much-time-will-it-take-to-upload-my-data-to-mg-rast}}
Based on observed values, upload times per 1GB (10:sup:\sphinxtitleref{9} bytes) vary
from 2 minutes to over an hour with typical times being 10 to 15
minutes. Your experience will vary depending on the speed of your
connection to the internet and the quality of service in your region.
The fastest times that could be expected for the technology you are
using is listed in table
{\hyperref[\detokenize{user_manual:table:upload_speeds}]{\emph{{[}table:upload\_speeds{]}}}}. In practice the time
taken will be more than indicated in the table.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Upload speeds for different technologies}\label{\detokenize{user_manual:id17}}
\sphinxaftertopcaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Technology}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Rate}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Time for 1GB Upload}
\\
\hline
Modem 14.4 (2400 baud)
&
14.4 kbit/s
&
154 hours
\\
\hline
ADSL Lite
&
1.5 Mbit/s
&
1.5 hours
\\
\hline
Ethernet
&
10 Mbit/s
&
13.33 minutes
\\
\hline
T3
&
44.74 Mbit/s
&
3 minutes
\\
\hline
Fast Ethernet
&
100 Mbit/s
&
1.33 minutes
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

{[}table:upload\_speeds{]}


\subsection{Do I need to compress my files before uploading to MG-RAST?}
\label{\detokenize{user_manual:do-i-need-to-compress-my-files-before-uploading-to-mg-rast}}
It is not required that you compress your files before uploading to
MG-RAST, but it is highly recommended.

Compressing your sequence data using Zip or gzip before it is uploaded
will reduce the time required for the upload. The compression rate
depends on the nature of the sequences, typical compression rates for
uploaded sequence data that we have observed is between 30-35\%. This
means the time taken for the upload may be reduced by a third or even
more. On a slow connection where uploading 1GB takes over an hour this
could be a considerable reduction in time. In addition, the shortened
time will also reduce the chance of a failed upload if something goes
wrong.


\subsection{What does the “Join paired-ends” function do?}
\label{\detokenize{user_manual:what-does-the-join-paired-ends-function-do}}
The ‘Join paired-ends’ function on the Upload page allows users to merge
two fastq files which represent paired end reads from the same
sequencing run. The fastq-join utility
(\sphinxurl{http://code.google.com/p/ea-utils/wiki/FastqJoin}) is used to merge
mate-pairs with a minimum overlap setting of 8bp and a maximum
difference of 10\% (parameters: -m 8 -p 10). There is an option to retain
or remove the pairs which do not overlap—the ‘remove’ option drops
paired reads for which no overlap is found and the ‘retain’ option will
keep non-overlapping paired reads in your output file as separate
individual (non-joined) sequences. There is also an option to include an
index file (if you have one) that contains the barcode for each
mate-pair. If this file is included, the barcodes will be
reverse-complemented and then prepended to the output sequences.


\subsection{What does the “assembled” pipeline option do?}
\label{\detokenize{user_manual:what-does-the-assembled-pipeline-option-do}}
The “assembled” pipeline option allows users to submit sequence data
under a slightly altered analysis pipeline that is more appropriate for
assembled sequences. Your assembled contigs should be uploaded in FASTA
format and should include the abundance of each contig in your dataset
with the following format:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}}\PYG{n}{sequence\PYGZus{}number\PYGZus{}1\PYGZus{}}\PYG{p}{[}\PYG{n}{cov}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{]}
\PYG{n}{CTAGCGCACATAGCATTCAGCGTAGCAGTCACTAGTACGTAGTACGTACC}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{o}{\PYGZgt{}}\PYG{n}{sequence\PYGZus{}number\PYGZus{}2\PYGZus{}}\PYG{p}{[}\PYG{n}{cov}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{]}
\PYG{n}{ACGTAGCTCACTCCAGTAGCAGGTACGTCGAGAAGACGTCTAGTCATCAT}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\end{sphinxVerbatim}

The abundance information must be appended without spaces to the end of
the sequence name (also without whitespace) in the format

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{\PYGZus{}}\PYG{p}{[}\PYG{n}{cov}\PYG{o}{=}\PYG{n}{n}\PYG{p}{]}
\end{sphinxVerbatim}

where ‘n’ is the coverage or abundance of each contig.


\subsection{Can I use the coverage information in my Velvet sequence file?}
\label{\detokenize{user_manual:can-i-use-the-coverage-information-in-my-velvet-sequence-file}}
Yes, coverage information can be included in the header lines of
FASTA-formatted files, for the exact format see the FAQ entry on the
assembled pipeline.

The following unix command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{cat} \PYG{n}{contigs}\PYG{o}{.}\PYG{n}{fa} \PYG{o}{\textbar{}}
   \PYG{n}{sed} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{s/\PYGZus{}cov\PYGZus{}}\PYG{l+s+s1}{\PYGZbs{}}\PYG{l+s+s1}{([0\PYGZhy{}9]*}\PYG{l+s+s1}{\PYGZbs{}}\PYG{l+s+s1}{).[0\PYGZhy{}9]*/\PYGZus{}[cov=}\PYG{l+s+se}{\PYGZbs{}1}\PYG{l+s+s1}{]/;}\PYG{l+s+s1}{\PYGZsq{}} \PYG{o}{\PYGZgt{}} \PYG{n}{Assembly}\PYG{o}{\PYGZhy{}}\PYG{n}{formatted}\PYG{o}{\PYGZhy{}}\PYG{k}{for}\PYG{o}{\PYGZhy{}}\PYG{n}{MGRAST}\PYG{o}{.}\PYG{n}{fa}
\end{sphinxVerbatim}

should transform Velvet’s default FASTA output into MG-RAST’s preferred
output.

Adding one more term:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{cat} \PYG{n}{contigs}\PYG{o}{.}\PYG{n}{fa} \PYG{o}{\textbar{}}
     \PYG{n}{sed} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{s/\PYGZus{}cov\PYGZus{}}\PYG{l+s+s1}{\PYGZbs{}}\PYG{l+s+s1}{([0\PYGZhy{}9]*}\PYG{l+s+s1}{\PYGZbs{}}\PYG{l+s+s1}{).[0\PYGZhy{}9]*/\PYGZus{}[cov=}\PYG{l+s+se}{\PYGZbs{}1}\PYG{l+s+s1}{]/;}
          \PYG{n}{s}\PYG{o}{/}\PYG{n}{NODE}\PYG{o}{/}\PYG{n}{Assembly}\PYG{o}{\PYGZhy{}}\PYG{o+ow}{and}\PYG{o}{\PYGZhy{}}\PYG{n}{sample}\PYG{o}{\PYGZhy{}}\PYG{n}{name}\PYG{o}{/}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ \PYGZgt{} Assembly\PYGZhy{}formatted\PYGZhy{}for\PYGZhy{}MGRAST.fa}
\end{sphinxVerbatim}

will give the contigs better names than NODE\_4\_etc., substitute your
information for ’Assembly-and-sample-name’.


\section{Job processing}
\label{\detokenize{user_manual:job-processing}}

\subsection{How long does it take to analyze a metagenome?}
\label{\detokenize{user_manual:how-long-does-it-take-to-analyze-a-metagenome}}
The answer depends on three factors:
\begin{itemize}
\item {} 
the priority assigned to your dataset,

\item {} 
the size of your dataset, and

\item {} 
the current server load.

\end{itemize}

In practice the time taken will range between a few hours and a week.


\subsection{How is the job processing priority assigned?}
\label{\detokenize{user_manual:how-is-the-job-processing-priority-assigned}}
MG-RAST assigns a priority to each dataset which will influence the
order in which datasets are selected for processing as well as the
processing speed for individual stages in the analysis pipeline. The
priority of processing a dataset is based on its usefulness to the
scientific community and is estimated using a combination of the amount
of metadata supplied and the length of time before the dataset will be
made public. The highest priority is given to datasets with complete
metadata that will be made public immediately.


\section{Analysis pipeline}
\label{\detokenize{user_manual:analysis-pipeline}}

\subsection{How is the dereplication step performed?}
\label{\detokenize{user_manual:how-is-the-dereplication-step-performed}}
The dereplication step is performed to remove replicates which can be
produced during sequencing. MG-RAST identifies two reads as replicates
if they have 100\% identity over the first 50 basepairs. This step is
optional and you should skip it for amplicon data.


\subsection{What does the “demultiplex” function do?}
\label{\detokenize{user_manual:what-does-the-demultiplex-function-do}}
The ‘demultiplex’ function on the Upload page gives users the ability to
demultiplex a multiplexed sequence file. The user enters the multiplexed
sequence file and a bar codes file. A process is then run that separates
out sequences, based upon bar codes, into separate sequence files. The
separate sequence files are then turned into separate jobs in MG-RAST
upon submission..


\subsection{How is the job processing priority assigned?}
\label{\detokenize{user_manual:how-is-the-job-processing-priority-assigned-1}}\label{\detokenize{user_manual:id6}}
MG-RAST assigns a priority to each dataset which will influence the
order in which datasets are selected for processing as well as the
processing speed for individual stages in the analysis pipeline. The
priority of processing a dataset is based on its usefulness to the
scientific community and is estimated using a combination of the amount
of metadata supplied and the length of time before the dataset will be
made public. The highest priority is given to datasets with complete
metadata that will be made public immediately.


\section{Analysis results}
\label{\detokenize{user_manual:analysis-results}}

\subsection{What annotations does MG-RAST display?}
\label{\detokenize{user_manual:what-annotations-does-mg-rast-display}}
At the moment, the annotations provided by MG-RAST are annotations
produced by the MG-RAST v3.2 analysis pipeline. Different pipelines (and
different pipeline strategies) may produce different results, and the
results of different annotation strategies are notoriously different to
reconcile. Some users have reported and published using annotations that
differ from those produced by MG-RAST; we provide the MG-RAST
annotations. While in theory the various annotation tools and approaches
do similar things (annotating reads based on similarity to sequences in
the public databases), the various approaches can provide significantly
different descriptions, particularly at the species level.


\subsection{Why don’t the numbers of annotations add up to the number of reads?}
\label{\detokenize{user_manual:why-dont-the-numbers-of-annotations-add-up-to-the-number-of-reads}}
See Section {\hyperref[\detokenize{user_manual:section:annotation_numbers}]{\emph{4.6}}}.


\subsection{Is the alignment length in amino acids or in nucleotides?}
\label{\detokenize{user_manual:is-the-alignment-length-in-amino-acids-or-in-nucleotides}}
For the protein similarities against the protein databases, alignment
length is in amino acids. For the nucleic acid similarities against the
RNA databases, the alignment length is in nucleotides.


\subsection{Why am I seeing RNA similarities in my shotgun dataset?}
\label{\detokenize{user_manual:why-am-i-seeing-rna-similarities-in-my-shotgun-dataset}}
MG-RAST identifies sequences similar to known RNA sequences in shotgun
data and annotates them in addition to providing protein function
annotation and protein-derived taxonomic annotation. Your mileage may
vary.


\subsection{Why am I seeing protein similarities in my RNA dataset?}
\label{\detokenize{user_manual:why-am-i-seeing-protein-similarities-in-my-rna-dataset}}
These are called “false positives”. We fall back on human judgment when
computers give results that don’t make sense.


\subsection{Why don’t you suppress the false positives?}
\label{\detokenize{user_manual:why-dont-you-suppress-the-false-positives}}
If we suppress protein similarities when we think a dataset is RNA, we
will sometimes make mistakes, and suppress protein similarities on a
dataset that is, say, a metatranscriptome, for which the protein
similarities are the principal objective. These might be called “false
negatives”, and our users don’t want that.


\subsection{What do all those symbols in the similarities table mean?}
\label{\detokenize{user_manual:what-do-all-those-symbols-in-the-similarities-table-mean}}
The MG-RAST system was designed to annotate large datasets; the
similarities output is designed for the convenience of the MG-RAST
system and not the end user. MG-RAST uses 32-character symbols like this
\sphinxcode{\sphinxupquote{28614b98db4f4efc13b8b20b21ee9b95}} (md5 protein identifiers) as the
labels for protein sequences, regardless of database.


\subsection{Can I run a BLAST search against all public metagenomes?}
\label{\detokenize{user_manual:can-i-run-a-blast-search-against-all-public-metagenomes}}
No. Such a search is too computationally expensive. But you can find
public metagenomes that contain proteins that hit your favorite sequence
from the Search page.


\section{Download}
\label{\detokenize{user_manual:download}}

\subsection{Where is the table of reads with the annotation for each read?}
\label{\detokenize{user_manual:where-is-the-table-of-reads-with-the-annotation-for-each-read}}
MG-RAST versions 1 and 2 had this type of output, but MG-RAST v3 does
not. MG-RAST version 3 has been optimized for large (Gbase+) datasets,
and per-read annotation for large datasets is extremely bulky and
difficult to interpret. The per-read annotations are not stored in a
file on the server, but can be downloaded using the MG-RAST API.


\subsection{Where can I download the results of the metagenome analysis?}
\label{\detokenize{user_manual:where-can-i-download-the-results-of-the-metagenome-analysis}}
Every completed MG-RAST dataset has a page where you can download the
files produced by the different stages of the analysis, click on the
link on the metagenome overview page. Datasets which have been made
public have links to an ftp site at the top of this download page where
you can access additional information.


\subsection{How do I download everything?}
\label{\detokenize{user_manual:how-do-i-download-everything}}
As of April 2014 we have over 7 x 10$^{\text{12}}$ bases of public sequence
data, so you might want to consider if all the data is really what you
need to answer your research question.

Public datasets, including sequence data and annotation data products,
are available from our API.


\section{Privacy}
\label{\detokenize{user_manual:privacy}}

\subsection{Who can access my uploaded data?}
\label{\detokenize{user_manual:who-can-access-my-uploaded-data}}
Your uploaded data will remain confidential as long as you do not share
it with other users. You will have the ability to share the data with
individuals or publish it to the MG-RAST community.


\subsection{Will my private jobs ever be deleted?}
\label{\detokenize{user_manual:will-my-private-jobs-ever-be-deleted}}
Currently MG-RAST policy is that private jobs will not be deleted for
120 days after submission as mentioned in the Terms of Service. We do
not enforce the 120 days as a strict deadline and your private jobs
theoretically can remain in the system indefinitely, we will not delete
your job without giving you ample warning. You are strongly encouraged
to make your data public once it has been published to ensure it will
never be considered for deletion.


\subsection{How do I make a job public?}
\label{\detokenize{user_manual:how-do-i-make-a-job-public}}
There is a ‘make public’ button on the metagenome overview page accessed
by clicking on the MG-RAST ID on the metagenome browse page. Making a
dataset public requires entering the relevant metadata without which the
dataset is of limited use. The website will lead you through the process
of entering metadata (if you have not done so earlier) and making the
dataset public.


\subsection{Will my public jobs ever be deleted?}
\label{\detokenize{user_manual:will-my-public-jobs-ever-be-deleted}}
No, we will not delete MG-RAST jobs which have been made public.


\section{Webkey}
\label{\detokenize{user_manual:webkey}}

\subsection{What is an MG-RAST webkey?}
\label{\detokenize{user_manual:what-is-an-mg-rast-webkey}}
See Section {\hyperref[\detokenize{user_manual:section:webkey}]{\emph{{[}section:webkey{]}}}}.


\subsection{How do I generate a webkey?}
\label{\detokenize{user_manual:how-do-i-generate-a-webkey}}
See Section {\hyperref[\detokenize{user_manual:section:webkey}]{\emph{{[}section:webkey{]}}}}.


\chapter{Putting It All in Perspective}
\label{\detokenize{user_manual:putting-it-all-in-perspective}}
We have described MG-RAST, a community resource for the analysis of
metagenomic sequence data. We have developed a new pipeline and
environment for automated analysis of shotgun metagenomic data, as well
as a series of interactive tools for comparative analysis. The pipeline
is also being used for analyzing metatranscriptome data as well as
amplicon data of various kinds. This service is being used by thousands
of users worldwide, many contributing their data and analysis results to
the community. We believe that community resources such as MG-RAST will
fill a vital role in the bioinformatics ecosystem in the years to come.


\section{MG-RAST, a community resource}
\label{\detokenize{user_manual:mg-rast-a-community-resource}}
MG-RAST has become a community clearinghouse for metagenomic data and
analysis, with over 12,000 public datasets that can be freely used.
Because analysis was performed in a uniform way, these datasets can
serve as building blocks for new comparative analysis; so long as new
datasets are analyzed similarly, results are robustly comparable between
new and old dataset analysis. These datasets (and the resulting analysis
data products) are made available for download and reuse as well.

Community resources like MG-RAST provide a clear value proposition to
the metagenomics community. First, it enables low-cost meta-analysis.
Users utilize the data products in MG-RAST as a basis for comparison
without the need to reanalyze every dataset used in their studies. The
high computational cost of analysis (Wilkening et al. 2009) makes
precomputation a prerequisite for large-scale meta-analyses. In 2001,
Angiuli et al. (Angiuoli et al. 2011) determined the real currency cost
of reanalysis for the over 12,000 datasets openly available on MG-RAST
to be in excess of \$30 million if Amazon’s EC2 platform is used. This
figure does not consider the 66,000 private datasets that have been
analyzed with MG-RAST.

Second, it provides incentives to the community to adopt standards, in
terms of both metadata and analysis approaches. Without this
standardization, data products are not readily reusable, and
computational costs quickly become unsustainable. We are not arguing
that a single analysis is necessarily suitable for all users; rather, we
are pointing out that if one particular type of analysis is run for all
datasets, the results can be efficiently reused, amortizing costs. Open
access to data and analyses foster community interactions that make it
easier for researchers’ efforts to achieve consensus with respect to
establishing best practices as well as identifying methods and analyses
that could provide misleading results.

Third, community resources drive increased efficiency and computational
performance. Community resources consolidate the demand for analysis
resources sufficiently to drive innovation in algorithms and approaches.
Because of this demand, the MG-RAST team has needed to scale the
efficiency of their pipeline by a factor of nearly 1,000 over the past
four years. This drive has caused improvements in gene calling,
clustering, and sequence quality analysis, as well as many other areas.
In less specialized groups with less extreme computational needs, this
sort of efficiency gain would be difficult to achieve. Moreover, the
large quantities of datasets that flow through the system have forced
the hardening of the pipeline against a large variety of sequence
pathology types that would not be readily observed in smaller systems.

We believe that our experiences in the design and operation of MG-RAST
are representative of bioinformatics as a whole. The community resource
model is critical if we are to benefit from the exponential growth in
sequence data. This data has the potential to enable new insights into
the world around us, but only if we can analyze it effectively. Only
because of this approach have we been able to scale to the demands of
our users effectively, analyzing over 200 billion sequences thus far.

We note that scaling to the required throughput by adding hardware to
the system or simply renting time using an unoptimized pipeline on. For
example, Amazon’s EC2 machine would not be economically feasible. The
real currency cost on EC2 for the data currently analyzed in MG-RAST (26
terabasepairs) would be in excess of \$100 million using an unoptimized
workflow such as CLOVR (Angiuoli et al. 2011).

All of MG-RAST is open source and available on
\sphinxurl{https://github.com/MG-RAST}.


\section{Future Work}
\label{\detokenize{user_manual:future-work}}
While MG-RAST v3 is a substantial improvement over prior systems, much
work remains to be done. Dataset sizes continue to increase at an
exponential pace. Keeping up with this change remains a top priority, as
metagenomics users continue to benefit from increased resolution of
microbial communities. Upcoming versions of MG-RAST will include (1)
mechanisms for speeding pipeline up using data reduction strategies that
are biologically motivated; (2) opening up the data ecosystem via an API
that will enable third-party development and enhancements; (3) providing
distributed compute capabilities using user-provided resources; and (4)
providing virtual integration of local datasets to allow comparison
between local data and shared data without requiring full integration.


\subsection{Roadmap}
\label{\detokenize{user_manual:roadmap}}
We maintain a rough roadmap for future version of MG-RAST.


\subsubsection{version 3.5}
\label{\detokenize{user_manual:version-3-5}}\begin{itemize}
\item {} 
provide a web services API

\item {} 
develop an R client

\item {} 
provide alpha version of MG-RAST remote compute client (using VMs)

\end{itemize}


\subsubsection{4.0}
\label{\detokenize{user_manual:id7}}\begin{itemize}
\item {} 
provide reviewer access tokens

\item {} 
consolidate all SQL onto PostGRES

\item {} 
provide beta version of MG-RAST remote compute client (using VMs)

\item {} 
include IPython-based notebooks for analysis

\item {} 
use AWE for all computations and SHOCK for all pipeline storage

\item {} 
provide multi-metagenome recruitment plot

\item {} 
convert all file access to SHOCK

\end{itemize}


\subsubsection{version 4.x}
\label{\detokenize{user_manual:version-4-x}}\begin{itemize}
\item {} 
rewrite web interface to support many browsers

\item {} 
provide BAM upload support

\item {} 
provide BAM download support

\item {} 
provide variation study support

\end{itemize}


\subsubsection{version 5.0}
\label{\detokenize{user_manual:version-5-0}}\begin{itemize}
\item {} 
provide federated SHOCK system

\item {} 
provide an assembly based pipeline

\end{itemize}


\section{Acknowledgments}
\label{\detokenize{user_manual:acknowledgments}}
This project is funded by the NIH grant R01AI123037 and by NSF grant
1645609

This work used the Magellan machine (U.S.Department of Energy, Office of
Science, Advanced Scientific Computing Research, under contract
DE-AC02-06CH11357) at Argonne National Laboratory, and the PADS resource
(National Science Foundation grant OCI-0821678) at the Argonne National
Laboratory/University of Chicago Computation Institute.

In the past the following sources contributed to MG-RAST development:
\begin{itemize}
\item {} 
U.S. Dept. of Energy under Contract DE-AC02-06CH11357

\item {} 
Sloan Foundation (SLOAN \#2010-12),

\item {} 
NIH NIAID (HHSN272200900040C),

\item {} 
NIH Roadmap HMP program (1UH2DK083993-01).

\end{itemize}


\chapter{The downloadable files for each data set}
\label{\detokenize{user_manual:the-downloadable-files-for-each-data-set}}\label{\detokenize{user_manual:chapter-downloads}}
\sphinxstylestrong{Uploaded File(s) DNA} (4465825.3.25422.fna)

Uploaded nucleotide sequence data in FASTA format. Preprocessing

Depending on the options chosen, the preprocessing step filters
sequences based on length, number of ambiguous bases and quality values
if available.

\sphinxstylestrong{passed, DNA} (4465825.3.100.preprocess.passed.fna)

A FASTA formatted file containing the sequences which were accepted and
will be passed on to the next stage of the analysis pipeline.

\sphinxstylestrong{removed, DNA} (4465825.3.100.preprocess.removed.fna)

A FASTA formatted file containing the sequences which were rejected and
will not be passed on to the next stage of the analysis pipeline.
Dereplication

The optional dereplication step removes redundant “technical replicate”
sequences from the metagenomic sample. Technical replicates are
identified by binning reads with identical first 50 base-pairs. One copy
of each 50-base-pair identical bin is retained.

\sphinxstylestrong{passed, DNA} (4465825.3.150.dereplication.passed.fna)

A FASTA formatted file containing one sequence from each bin which will
be passed on to the next stage of the analysis pipeline.

\sphinxstylestrong{removed, DNA} (4465825.3.150.dereplication.removed.fna)

A FASTA formatted file containing the sequences which were identified as
technical replicates and will not be passed on to the next stage of the
analysis pipeline. Screening

The optional screening step screens reads against model organisms using
bowtie to remove reads which are similar to the genome of the selected
species.

\sphinxstylestrong{passed, DNA} (4465825.3.299.screen.passed.fna)

A FASTA formatted file containing the reads which which had no
similarity to the selected genome and will be passed on to the next
stage of the analysis pipeline. Prediction of protein coding sequences

Coding regions within the sequences are predicted using FragGeneScan, an
ab-initio prokaryotic gene calling algorithm. Using a hidden Markov
model for coding regions and non-coding regions, this step identifies
the most likely reading frame and translates nucleotide sequences into
amino acids sequences. The predicted coding regions, possibly more than
one per fragment, are called features.

\sphinxstylestrong{coding, Protein} (4465825.3.350.genecalling.coding.faa)

A amino-acid sequence FASTA formatted file containing the translations
of the predicted coding regions.

\sphinxstylestrong{coding, DNA} (4465825.3.350.genecalling.coding.fna)

A nucleotide sequence FASTA formatted file containing the predicted
coding regions. RNA Clustering

Sequences from step 2 (before dereplication) are pre-screened for at
least 60\% identity to ribosomal sequences and then clustered at 97\%
identity using UCLUST. These clusters are checked for similarity against
the ribosomal RNA databases (Greengenes(DeSantis et al. 2006), LSU and
SSU from (Pruesse et al. 2007), and RDP(Cole et al. 2003)).

\sphinxstylestrong{rna97, DNA} (4465825.3.440.cluster.rna97.fna)

A FASTA formatted file containing sequences that have at least 60\%
identity to ribosomal sequences and are checked for RNA similarity.

\sphinxstylestrong{rna97, Cluster} (4465825.3.440.cluster.rna97.mapping)

A tab-delimited file that identifies the sequence clusters and the
sequences that comprise them.

The columns making up each line in this file are:

Cluster ID, e.g. rna97\_998

Representative read ID, e.g. 11909294

List of IDs for other reads in the cluster, e.g. 11898451,11944918

List of percentage identities to the representative read sequence, e.g.
97.5\%,100.0\%

\sphinxstylestrong{RNA similarities}

The two files labelled “expand” are comma- and semicolon- delimited
files that provide the mappings from md5s to function and md5s to
taxonomy:

\sphinxstylestrong{annotated, Sims} (4465825.3.450.rna.expand.lca)

\sphinxstylestrong{annotated, Sims} (4465825.3.450.rna.expand.rna)

Packaged results of the blat search against all the DNA databases with
MD5 value of the database sequence hit followed by sequence or cluster
ID, similarity information, annotation, organism, database name.

\sphinxstylestrong{raw, Sims} (4465825.3.450.rna.sims)

This is the similarity output from BLAT. This includes the identifier
for the query which is either the FASTA id or the cluster ID, and the
internal identifier for the sequence that it hits.

The fields are in BLAST m8 format:

Query id (either fasta ID or cluster ID), e.g. 11847922

Hit id, e.g. lcl\textbar{}501336051b4d5d412fb84afe8b7fdd87

percentage identity, e.g. 100.00

alignment length, e.g. 107

number of mismatches, e.g. 0

number of gap openings, e.g. 0

q.start, e.g. 1

q.end, e.g. 107

s.start, e.g. 1262

s.end, e.g. 1156

e-value, e.g. 1.7e-54

score in bits, e.g. 210.0

\sphinxstylestrong{filtered, Sims} (15:04 4465825.3.450.rna.sims.filter)

This is a filtered version of the raw Sims file above that removes all
but the best hit for each data source. Gene Clustering

Protein coding sequences are clustered at 80\% identity with UCLUST. This
process does not remove any sequences but instead makes the similarity
search step easier. Following the search, the original reads are loaded
into MG-RAST for retrieval on-demand.

\sphinxstylestrong{aa90, Protein} (4465825.3.550.cluster.aa90.faa)

An amino acid sequence FASTA formatted file containing the translations
of one sequence from each cluster (by cluster ids starting with aa90)
and all the unclustered (singleton) sequences with the original sequence
ID.

\sphinxstylestrong{aa90, Cluster} (4465825.3.550.cluster.aa90.mapping)

A tab-separated file in which each line describes a single cluster.

The fields are:

Cluster ID, e.g. aa90\_3270

protein coding sequence ID including hit location and strand, e.g.
11954908\_1\_121\_+

additional sequence ids including hit location and strand, e.g.
11898451\_1\_119\_+,11944918\_19\_121\_+

sequence \% identities, e.g. 94.9\%,97.0\%

Protein similarities

\sphinxstylestrong{annotated, Sims} (4465825.3.650.superblat.expand.lca)

The expand.lca file decodes the MD5 to the taxonomic classification it
is annotated with.

The format is:

md5(s), e.g.
cf036dfa9cdde3a8a4c09d7fabfd9ba5;1e538305b8319dab322b8f28da82e0a1

feature id (for singletons) or cluster id of hit including hit location
and strand, e.g. 11857921\_1\_101-

alignment \%, e.g. 70.97;70.97

alignment length, e.g. 31;31

E-value, e.g. 7.5e-05;7.5e-05

Taxonomic string, e.g. Bacteria;Actinobacteria;Actinobacteria
(class);Coriobacteriales;Coriobacteriaceae;Slackia;Slackia exigua;-

\sphinxstylestrong{annotated, Sims} (4465825.3.650.superblat.expand.protein)

Packaged results of the blat search against all the protein databases
with MD5 value of the database sequence hit followed by sequence or
cluster ID, similarity information, functional annotation, organism,
database name.

Format is:

md5 (identifier for the database hit), e.g.
88848aa7224ca2f3ac117e7953edd2d9

feature id (for singletons) or cluster ID for the query, e.g. aa90\_22837

alignment \% identity, e.g. 76.47

alignment length, e.g. 34

E-value, e.g. 1.3e-06

protein functional label, e.g. SsrA-binding protein

Species name associated with best protein hit, e.g. Prevotella bergensis
DSM 17361 RefSeq 585502

\sphinxstylestrong{raw, Sims} (4465825.3.650.superblat.sims)

Blat output with sequence or cluster ID, md5 value for the sequence in
the database and similarity information.

\sphinxstylestrong{filtered, Sims} (4465825.3.650.superblat.sims.filter)

Blat output filtered to take only the best hit from each data source.


\chapter{Terms of Service}
\label{\detokenize{user_manual:terms-of-service}}\begin{itemize}
\item {} 
MG-RAST is a web-based computational metagenome analysis service
provided on a best-effort basis. We strive to provide correct
analysis, privacy, but can not guarantee correctness of results,
integrity of data or privacy. That being said, we are not responsible
for any HIPPA regulations regarding human samples uploaded by users.
We will try to provide as much speed as possible and will try to
inform users about wait times. We will inform users about changes to
the system and the underlying data.

\item {} 
We reserve the right to delete non public data sets after 120 days.

\item {} 
We reserve the right to reject data set that are not complying with
the purpose of MG-RAST.

\item {} 
We reserve the right to perform additional data analysis (e.g. search
for novel sequence errors to improve our sequence quality detection,
clustering to improve sequence similarity searches etc.) AND in
certain cases utilize the results. We will NOT release user provided
data without consent and or publish on user data before the user.

\item {} 
User acknowledges the restrictions stated about and will cite MG-RAST
when reporting on their work.

\item {} 
User acknowledges the fact that data sharing on MG-RAST is meant as a
pre-publication mechanism and we strongly encourage users to make
data publicly accessible in MG-RAST once published in a journal (or
after 120 days).

\item {} 
User acknowledges that data (including metadata) provided is a)
correct and b) user either owns the data or has the permission of the
owner to upload data and or publish data on MG-RAST.

\item {} 
We reserve the right to curate and update public meta data.

\item {} 
We reserve the right at any time to modify this agreement. Such
modifications and additional terms and conditions will be effective
immediately and incorporated into this agreement. MG-RAST will make a
reasonable effort to contact users via email of any changes and your
continued use of MG-RAST will be deemed acceptance thereof.

\end{itemize}


\chapter{Tools and data used by MG-RAST}
\label{\detokenize{user_manual:tools-and-data-used-by-mg-rast}}
The MG-RAST team is happy to acknowledge the use of the following great
software and data products: Databases

MG-RAST uses a number of protein and ribosomal RNA databases integrated
into the M5nr (Wilke et al. 2012) (Wilke et al, BMC Bioinformatics 2012.
Vol 13, No. 151) non-redundant database using the M5nr tools.


\section{Databases}
\label{\detokenize{user_manual:databases}}

\subsection{Protein databases}
\label{\detokenize{user_manual:protein-databases}}\begin{itemize}
\item {} 
The SEED (Overbeek et al. 2005) (Overbeek et al., NAR, 2005, Vol. 33,
Issue 17)

\item {} 
GenBank (Benson et al. 2013) (Benson et al., NAR, 2011, Vol. 39,
Database issue)

\item {} 
RefSeq (Pruitt, Tatusova, and Maglott 2007) (Pruitt et al., NAR,
2009, Vol. 37, Database issue)

\item {} 
IMG/M (Markowitz et al., NAR, 2008, Vol. 36, Database issue)

\item {} 
UniProt (Magrane and Consortium 2011) (Apweiler et al., NAR, 2011,
Vol. 39, Database issue)

\item {} 
eggNOGG (Jensen et al. 2008) (Muller et al., NAR, 2010, Vol. 38,
Database issue)

\item {} 
KEGG (Kanehisa 2002) (Kanehisa et al., NAR, 2008, Vol. 36, Database
issue)

\item {} 
PATRIC (Snyder et al. 2007) (Gillespie et al., Infect. Immun., 2011,
Vol. 79, no. 11)

\end{itemize}


\subsection{Ribosomal RNA databases}
\label{\detokenize{user_manual:ribosomal-rna-databases}}\begin{itemize}
\item {} 
greengenes (DeSantis et al. 2006) (DeSantis et al., Appl Environ
Microbiol., 2006, Vol. 72, no. 7)

\item {} 
SILVA (Pruesse et al. 2007) (Pruesse et al., NAR, 2007, Vol. 35,
issue 21)

\item {} 
RDP (Cole et al. 2003) (Cole et al., NAR, 2009, Vol. 37, Database
issue)

\end{itemize}


\section{Software}
\label{\detokenize{user_manual:software}}

\subsection{Bioinformatics codes}
\label{\detokenize{user_manual:bioinformatics-codes}}\label{\detokenize{user_manual:section-bioinformatics-codes}}\begin{itemize}
\item {} 
FragGeneScan (Rho, Tang, and Ye 2010) (Rho et al, NAR, 2010, Vol. 38,
issue 20)

\item {} 
BLAT (Kent 2002) (J. Kent, Genome Res, 2002, Vol. 12, No. 4)

\item {} 
QIIME (Caporaso et al. 2010) (Caporaso et al, Nature Methods, 2010,
Vol. 7, No. 5) (we also use uclust that is part of QIIME)

\item {} 
Biopython

\item {} 
Bowtie (Langmead et al. 2009) (Langmead et al., Genome Biol. 2009,
Vol 10, issue 3)

\item {} 
sff\_extract, Jose Blanca and Joaquin Cañizares

\item {} 
Dynamic Trim, part of SolexaQA, (Cox, Peterson, and Biggs 2010) (Cox
et al., BMC Bioinformatics, 2011, Vol. 11, 485)

\item {} 
FastqJoin

\end{itemize}


\subsection{Web/UI tools}
\label{\detokenize{user_manual:web-ui-tools}}\begin{itemize}
\item {} 
Krona (Ondov, Bergman, and Phillippy 2011) (Ondov et. al. BMC
Bioinformatics, 2011, Vol. 12, 385)

\item {} 
Raphael JavaScript Library (Dmitry Baranovskiy)

\item {} 
jQuery

\item {} 
Circos (Krzywinski et al., Genome Res. 2009, Vol. 19)

\item {} 
cURL

\end{itemize}


\subsection{Behind the scenes}
\label{\detokenize{user_manual:behind-the-scenes}}\begin{itemize}
\item {} 
Perl

\item {} 
Python

\item {} 
R

\item {} 
Go

\item {} 
Google’s V8 JavaScript engine

\item {} 
Node.js

\item {} 
nginx

\item {} 
OpenStack

\end{itemize}

Angiuoli, S. V., M. Matalka, A. Gussman, K. Galens, M. Vangala, D.
R. Riley, C. Arze, J. R. White, O. White, and W. F. Fricke. 2011.
“CloVR: A Virtual Machine for Automated and Portable Sequence
Analysis from the Desktop Using Cloud Computing.” \sphinxstyleemphasis{BMC
Bioinformatics} 12: 356.

Aziz, Ramy, Daniela Bartels, Aaron Best, Matthew DeJongh, Terrence
Disz, Robert Edwards, Kevin Formsma, et al. 2008. “The RAST
Server: Rapid Annotations Using Subsystems Technology.” \sphinxstyleemphasis{BMC
Genomics} 9 (1): 75. \sphinxurl{https://doi.org/10.1186/1471-2164-9-75}.

Benson, D. A., M. Cavanaugh, K. Clark, I. Karsch-Mizrachi, D. J.
Lipman, J. Ostell, and E. W. Sayers. 2013. “GenBank.” \sphinxstyleemphasis{Nucleic
Acids Res} 41 (Database issue): D36\textendash{}42.

Board, OpenMP Architecture Review. 2011. “OpenMP Application
Program Interface Version 3.1.”

Bolotin, A., B. Quinquis, A. Sorokin, and S. D. Ehrlich. 2005.
“Clustered Regularly Interspaced Short Palindrome Repeats
(CRISPRs) Have Spacers of Extrachromosomal Origin.” \sphinxstyleemphasis{Microbiology}
151 (Pt 8): 2551\textendash{}61.

Buchfink, Benjamin, Chao Xie, and Daniel H Huson. 2015. “Fast and
Sensitive Protein Alignment Using Diamond.” \sphinxstyleemphasis{Nature Methods} 12
(1): 59\textendash{}60.

Caporaso, J. G., J. Kuczynski, J. Stombaugh, K. Bittinger, F. D.
Bushman, E. K. Costello, N. Fierer, et al. 2010. “QIIME Allows
Analysis of High-Throughput Community Sequencing Data.” \sphinxstyleemphasis{Nat
Methods} 7 (5): 335\textendash{}6.

Cole, J. R., B. Chai, T. L. Marsh, R. J. Farris, Q. Wang, S. A.
Kulam, S. Chandra, et al. 2003. “The Ribosomal Database Project
(RDP-II): Previewing a New Autoaligner That Allows Regular Updates
and the New Prokaryotic Taxonomy.” \sphinxstyleemphasis{Nucleic Acids Research} 31
(1): 442\textendash{}43. \sphinxurl{http://www.ncbi.nlm.nih.gov/pmc/articles/PMC165486/}.

Cox, M. P., D. A. Peterson, and P. J. Biggs. 2010. “SolexaQA:
At-a-Glance Quality Assessment of Illumina Second-Generation
Sequencing Data.” \sphinxstyleemphasis{BMC Bioinformatics} 11: 485.

DeSantis, T. Z., P. Hugenholtz, N. Larsen, M. Rojas, E. L. Brodie,
K. Keller, T. Huber, D. Dalevi, P. Hu, and G. L. Andersen. 2006.
“Greengenes, a Chimera-Checked16S rRNA Gene Database and Workbench
Compatible with ARB.” \sphinxstyleemphasis{Appl. Environ. Microbiol.} 72 (7): 5069\textendash{}72.
\sphinxurl{https://doi.org/10.1128/aem.03006-05}.

Edgar, R. C. 2010. “Search and Clustering Orders of Magnitude
Faster Than BLAST.” \sphinxstyleemphasis{Bioinformatics} 26 (19): 2460\textendash{}1.

Field, D., L. Amaral-Zettler, G. Cochrane, J. R. Cole, P. Dawyndt,
G. M. Garrity, J. Gilbert, F. O. Glöckner, L. Hirschman, and I.
Karsch-Mizrachi. 2011. “The Genomic Standards Consortium.” \sphinxstyleemphasis{PLOS
Biology} 9 (6): e1001088.

Gerlach, Wolfgang, Wei Tang, Kevin Keegan, Travis Harrison,
Andreas Wilke, Jared Bischof, Mark D’Souza, et al. 2014. “Skyport:
Container-Based Execution Environment Management for Multi-Cloud
Scientific Workflows.” In \sphinxstyleemphasis{Proceedings of the 5th International
Workshop on Data-Intensive Computing in the Clouds}, 25\textendash{}32.
DataCloud ’14. Piscataway, NJ, USA: IEEE Press.
\sphinxurl{https://doi.org/10.1109/DataCloud.2014.6}.

Gomez-Alvarez, V., T. K. Teal, and T. M. Schmidt. 2009.
“Systematic Artifacts in Metagenomes from Complex Microbial
Communities.” \sphinxstyleemphasis{ISME J} 3 (11): 1314\textendash{}7.

Huse, S. M., J. A. Huber, H. G. Morrison, M. L. Sogin, and D. M.
Welch. 2007. “Accuracy and Quality of Massively Parallel DNA
Pyrosequencing.” \sphinxstyleemphasis{Genome Biol} 8 (7): R143.

Huson, D. H., A. F. Auch, J. Qi, and S. C. Schuster. 2007. “MEGAN
Analysis of Metagenomic Data.” \sphinxstyleemphasis{Genome Res} 17 (3): 377\textendash{}86.

Institute, National Human Genome Research. 2012. “Cost Per Raw
Megabase of Dna Sequence.”
\sphinxurl{http://www.genome.gov/images/content/cost\_per\_megabase.jpg}.

Jensen, L. J., P. Julien, M. Kuhn, C. von Mering, J. Muller, T.
Doerks, and P. Bork. 2008. “EggNOG: Automated Construction and
Annotation of Orthologous Groups of Genes.” \sphinxstyleemphasis{Nucleic Acids Res} 36
(Database issue): D250\textendash{}4.

Kanehisa, M. 2002. “The KEGG Database.” \sphinxstyleemphasis{Novartis Found Symp} 247:
91\textendash{}101; discussion 101\textendash{}3, 119\textendash{}28, 244\textendash{}52.

Keegan, K. P., W. L. Trimble, J. Wilkening, A. Wilke, T. Harrison,
M. D’Souza, and F. Meyer. 2012. “A Platform-Independent Method for
Detecting Errors in Metagenomic Sequencing Data: DRISEE.” \sphinxstyleemphasis{PLOS
Comput Biol} 8 (6): e1002541.

Kent, W. J. 2002. “BLAT\textendash{}the BLAST-Like Alignment Tool.” \sphinxstyleemphasis{Genome
Res} 12 (4): 656\textendash{}64.

Langmead, B., C. Trapnell, M. Pop, and S. L. Salzberg. 2009.
“Ultrafast and Memory-Efficient Alignment of Short DNA Sequences
to the Human Genome.” \sphinxstyleemphasis{Genome Biol} 10 (3): R25.

Loman, Nicholas J., Raju V. Misra, Timothy J. Dallman, Chrystala
Constantinidou, Saheer E Gharbia, John Wain, and Mark J. Pallen.
2012. “Performance Comparison of Benchtop High-Throughput
Sequencing Platforms.” \sphinxstyleemphasis{Nature Biotechnology} 30 (5): 434\textendash{}39.
\sphinxurl{https://doi.org/10.1038/nbt.2198}.

Magrane, Michele, and UniProt Consortium. 2011. “UniProt
Knowledgebase: A Hub of Integrated Protein Data.” \sphinxstyleemphasis{Database: The
Journal of Biological Databases and Curation} 2011 (January).
\sphinxurl{https://doi.org/10.1093/database/bar009}.

Markowitz, V. M., N. N. Ivanova, E. Szeto, K. Palaniappan, K. Chu,
D. Dalevi, I. M. Chen, et al. 2008. “IMG/M: A Data Management and
Analysis System for Metagenomes.” \sphinxstyleemphasis{Nucleic Acids Res} 36 (Database
issue): D534\textendash{}8.

McDonald, D., J. C. Clemente, J. Kuczynski, J. Rideout, J.
Stombaugh, D. Wendel, A. Wilke, S. Huse, J. Hufnagle, and F.
Meyer. 2012. “The Biological Observation Matrix (BIOM) Format or:
How I Learned to Stop Worrying and Love the Ome-Ome.”
\sphinxstyleemphasis{Gigascience}.

Meyer, F., D. Paarmann, M. D’Souza, R. Olson, E. M. Glass, M.
Kubal, T. Paczian, et al. 2008. “The Metagenomics RAST Server - a
Public Resource for the Automatic Phylogenetic and Functional
Analysis of Metagenomes.” \sphinxstyleemphasis{BMC Bioinformatics} 9 (1): 386.
\sphinxurl{https://doi.org/10.1186/1471-2105-9-386}.

Ondov, B. D., N. H. Bergman, and A. M. Phillippy. 2011.
“Interactive Metagenomic Visualization in a Web Browser.” \sphinxstyleemphasis{BMC
Bioinformatics} 12: 385.

Overbeek, R., T. Begley, R. M. Butler, J. V. Choudhuri, N. Diaz,
H.-Y. Chuang, M. Cohoon, et al. 2005. “The Subsystems Approach to
Genome Annotation and Its Use in the Project to Annotate 1000
Genomes.” \sphinxstyleemphasis{Nucleic Acids Res} 33 (17).

Pruesse, Elmar, Christian Quast, Katrin Knittel, Bernhard M.
Fuchs, Wolfgang Ludwig, Jörg Peplies, and Frank Oliver O.
Glöckner. 2007. “SILVA: A Comprehensive Online Resource for
Quality Checked and Aligned Ribosomal RNA Sequence Data Compatible
with ARB.” \sphinxstyleemphasis{Nucleic Acids Research} 35 (21): 7188\textendash{}96.
\sphinxurl{https://doi.org/10.1093/nar/gkm864}.

Pruitt, K. D., T. Tatusova, and D. R. Maglott. 2007. “NCBI
Reference Sequences (RefSeq): A Curated Non-Redundant Sequence
Database of Genomes, Transcripts and Proteins.” \sphinxstyleemphasis{Nucleic Acids
Res} 35 (Database issue).
\sphinxurl{http://view.ncbi.nlm.nih.gov/pubmed/17130148}.

R., Kottmann, Gray T., Murphy S., Kagan L., Kravitz S., Lombardot
T., Field D., and Glöckner FO; Genomic Standards Consortium. 2008.
“A Standard MIGS/MIMS Compliant XML Schema: Toward the Development
of the Genomic Contextual Data Markup Language (GCDML).” \sphinxstyleemphasis{OMICS}
12 (2): 115\textendash{}21. \sphinxurl{https://doi.org/10.1089/omi.2008.0A10}.

Reeder, J., and R. Knight. 2009. “The ‘Rare Biosphere’: A Reality
Check.” \sphinxstyleemphasis{Nat Methods} 6 (9): 636\textendash{}7.

Rho, Mina, Haixu Tang, and Yuzhen Ye. 2010. “FragGeneScan:
Predicting Genes in Short and Error-Prone Reads.” \sphinxstyleemphasis{Nucleic Acids
Research} 38 (20): e191\textendash{}e191.

Riesenfeld, C. S., P. D. Schloss, and J. Handelsman. 2004.
“Metagenomics: Genomic Analysis of Microbial Communities.” \sphinxstyleemphasis{Annu
Rev Genet} 38: 525\textendash{}52.

Snyder, E. E., N. Kampanya, J. Lu, E. K. Nordberg, H. R. Karur, M.
Shukla, J. Soneja, et al. 2007. “PATRIC: The VBI PathoSystems
Resource Integration Center.” \sphinxstyleemphasis{Nucleic Acids Res} 35 (Database
issue). \sphinxurl{https://doi.org/10.1093/nar/gkl858}.

Speed, Terry. 2003. \sphinxstyleemphasis{Statistical Analysis of Gene Expression
Microarray Data}. Chapman; Hall/CRC.
\sphinxurl{http://www.amazon.com/Statistical-Analysis-Gene-Expression-Microarray/dp/1584883278/}.

Tatusov, R. L., N. D. Fedorova, J. D. Jackson, A. R. Jacobs, B.
Kiryutin, E. V. Koonin, D. M. Krylov, et al. 2003. “The COG
Database: An Updated Version Includes Eukaryotes.” \sphinxstyleemphasis{BMC
Bioinformatics} 4: 41.

Thomas, Torsten, Jack Gilbert, and Folker Meyer. 2012.
“Metagenomics - a Guide from Sampling to Data Analysis.”
\sphinxstyleemphasis{Microbial Informatics and Experimentation} 2 (1): 3.
\sphinxurl{https://doi.org/10.1186/2042-5783-2-3}.

Trimble, W. L., K. P. Keegan, M. D’Souza, A. Wilke, J. Wilkening,
J. Gilbert, and F. Meyer. 2012. “Short-Read Reading-Frame
Predictors Are Not Created Equal: Sequence Error Causes Loss of
Signal.” \sphinxstyleemphasis{BMC Bioinformatics} 13 (1): 183.

Wilke, A., T. Harrison, J. Wilkening, D. Field, E. M. Glass, N.
Kyrpides, K. Mavrommatis, and F. Meyer. 2012. “The M5nr: A Novel
Non-Redundant Database Containing Protein Sequences and
Annotations from Multiple Sources and Associated Tools.” \sphinxstyleemphasis{BMC
Bioinformatics} 13: 141.

Wilke, Andreas, Wolfgang Gerlach, Travis Harrison, Tobias Paczian,
Wei Tang, William L. Trimble, Jared Wilkening, Narayan Desai, and
Folker Meyer. 2015. “Shock: Active Storage for Multicloud
Streaming Data Analysis.” In \sphinxstyleemphasis{2nd IEEE/ACM International Symposium
on Big Data Computing, BDC 2015, Limassol, Cyprus, December 7-10,
2015}, edited by Ioan Raicu, Omer F. Rana, and Rajkumar Buyya,
68\textendash{}72. IEEE. \sphinxurl{https://doi.org/10.1109/BDC.2015.40}.

Wilke, A., J. Wilkening, E. M. Glass, N. Desai, and F. Meyer.
2011. “An Experience Report: Porting the MG-RAST Rapid
Metagenomics Analysis Pipeline to the Cloud.” \sphinxstyleemphasis{Concurrency and
Computation: Practice and Experience} 23 (17): 2250\textendash{}7.

Wilkening, J., A. Wilke, N. Desai, and F. Meyer. 2009. “Using
Clouds for Metagenomics: A Case Study.” In \sphinxstyleemphasis{IEEE Cluster 2009}.

Yilmaz, Pelin, Renzo Kottmann, Dawn Field, Rob Knight, James Cole,
Linda Amaral-Zettler, Jack Gilbert, et al. 2010. “The ‘Minimum
Information About an ENvironmental Sequence’ (MIENS)
Specification.” \sphinxstyleemphasis{Nature Biotechnology}.


\chapter{API — The MG-RAST Application Programming Interface}
\label{\detokenize{api:api-the-mg-rast-application-programming-interface}}\label{\detokenize{api:api}}\label{\detokenize{api::doc}}

\section{URLs}
\label{\detokenize{api:urls}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{api}\PYG{o}{.}\PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{rast}\PYG{o}{.}\PYG{n}{org}\PYG{o}{/}
\end{sphinxVerbatim}

Further documentation, with a complete parameter listing for all
resources available is at:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{api}\PYG{p}{,}\PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{rast}\PYG{o}{.}\PYG{n}{org}\PYG{o}{/}\PYG{n}{api}\PYG{o}{.}\PYG{n}{html}
\end{sphinxVerbatim}

Github repository of script tools, examples, and contributed code for
using the MG-RAST API:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{github}\PYG{o}{.}\PYG{n}{com}\PYG{o}{/}\PYG{n}{MG}\PYG{o}{\PYGZhy{}}\PYG{n}{RAST}\PYG{o}{/}\PYG{n}{MG}\PYG{o}{\PYGZhy{}}\PYG{n}{RAST}\PYG{o}{\PYGZhy{}}\PYG{n}{Tools}
\end{sphinxVerbatim}


\section{Introduction}
\label{\detokenize{api:introduction}}\label{\detokenize{api:introduction-1}}
Over 110,000 metagenomic data sets have been uploaded and analyzed in
MG-RAST since 2007, totaling over 43 terabases (TBp). Data uploaded
falls in three classes: shotgun metagenomic data, amplicon data, and,
more recently, metatranscriptomic data. The MG-RAST pipeline normalizes
all samples by applying a uniform pipeline with the appropriate quality
control mechanisms for the various data sources. Uniform processing and
robust sequence quality control enable comparison across experimental
systems and, to some extent, across sequencing platforms. With the
inclusion of standardized metadata MG-RAST has enabled meta-analysis
available through its web-based user interface. This provides an
easy-to-use way to upload and download data, perform analyses, and
create and share projects.

As with most GUIs, however, there are limitations to what can be done,
for example, regarding the number of samples processed in a single
analysis, access to complete metadata, and easy access to raw data and
quality metrics for each sample. As part of the DOE Systems Biology
knowledgebase project (KBase) we have implemented a web services
application programmers interface (API) that exposes all data to
(authenticated) programmers, enabling access to available data and
functionality through software applications. This makes user access to
MG-RAST’s internal data structures possible.

The MG-RAST API enables programmatic access to data and analyses in
MG-RAST without requiring local installations. Using the API, users can
authenticate against the service, submit their data, download results,
and perform extensive comparisons of data sets. The API uses the
Representational State Transfer (REST) {[}3{]} architecture which allows
download of data in ASCII format, allowing users to query the system via
URLs and returning MG-RAST data objects in their native format (e.g.
similarity tables or sequence files). For structured data (e.g. metadata
or project information) the MG-RAST API uses JSON (Javascript Object
Notation, a widely used standard) as its data format.

This allows users to use simple tools to download data files or view the
JSON in their web browsers using one of the many available JSON viewers.
In addition many programming languages have libraries for convenient
HTTP interaction and JSON conversions. The API has a minimal number of
prerequisites; and any language with HTTP and JSON support or command
line utilities such as “curl” can easily integrate with the design.

If you are not a programmer or you are not willing to spend the time
learning the API, the Example scripts (see chapter
{\hyperref[\detokenize{api:API-Examples}]{\emph{7}}}.)


\section{Design and Implementation}
\label{\detokenize{api:design-and-implementation}}
The MG-RAST API enables programmatic access to data and analyses in
MG-RAST without requiring local installations. Users can authenticate
against the service, submit their data, download results, and perform
extensive comparisons of data sets. We chose to use the Representational
State Transfer (REST) {[}3{]} architecture. The REST approach allows
download of data in ASCII format, allowing users to query the system via
URLs and returning MG-RAST data objects in their native format (e.g.
similarity tables or sequence files). For structured data (e.g. metadata
or project information) the MG-RAST API uses JSON (Javascript Object
Notation, a widely used standard) as its data format.

Using this approach users can use simple tools to download data files to
their machines or view the JSON in their web browsers using one of the
many available JSON viewers. In addition many programming languages have
libraries for convenient HTTP interaction and JSON conversions.

Most of the API calls are simply URLs which can be entered in the
address bar of a web browser to perform the download through the
browser. These URLs can also be used with a command line tool like curl,
in programing-language-specific libraries, or in command line scripts.
The examples in the Results section illustrate the use of each of these
methods. The example scripts are available on in the supplementary
materials and on github (\sphinxurl{https://github.com/MG-RAST/MG-RAST-Tools}) along
with other useful illustrative scripts.

The MG-RAST API covers most of the functionality available through the
MG-RAST website, with access to annotations, analyses, metadata and
access to the MG-RAST user inbox to view contents as well as upload
files. All sequence data and data products from intermediate stages in
the analysis pipeline are available for download. Other resources
provide services not available through the website, e.g. the m5nr
resource lets you query the m5nr database.

Each query to the API is represented as a URI beginning with

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{api}\PYG{o}{.}\PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{rast}\PYG{o}{.}\PYG{n}{org}\PYG{o}{/}
\end{sphinxVerbatim}

and has a defined structure to pass the requests and parameters to the
API server. These URI queries can be used from the command line, e.g.
using curl, in a browser, or incorporated in a shell script or program.

Each URI has the form:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
https://api.mg\PYGZhy{}rast.org/\PYGZob{}version\PYGZcb{}/\PYGZob{}resourcepath\PYGZcb{}?\PYGZob{}querystring\PYGZcb{}
\end{sphinxVerbatim}

where

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}\PYG{n}{version}\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

explicitly directs the request to a specific version of the API. If it
is omitted the latest API version will be used. The current version
number is ‘1’.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}\PYG{n}{resourcepath}\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

is constructed from the path parameters listed below to define a
specific resource.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}\PYG{n}{querystring}\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

is used to filter the results obtained for the resource, this is
optional.

For example, in:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
https://api.mg\PYGZhy{}rast.org/1/annotation/sequence/mgm4447943.3?evalue=10\PYGZam{}type=organism\PYGZam{}source=SwissProt
\end{sphinxVerbatim}

the resource path

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{annotation}\PYG{o}{/}\PYG{n}{sequence}\PYG{o}{/}\PYG{n}{mgm4447943}\PYG{o}{.}\PYG{l+m+mi}{3}
\end{sphinxVerbatim}

defines a request for the annotated sequences for the MG-RAST job with
ID 4447943.3. The optional query string

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{evalue}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{o}{\PYGZam{}}\PYG{n+nb}{type}\PYG{o}{=}\PYG{n}{organism}\PYG{o}{\PYGZam{}}\PYG{n}{source}\PYG{o}{=}\PYG{n}{SwissProt}
\end{sphinxVerbatim}

modifies the results by setting an evalue cutoff, annotation type and
database source.

The API provides an authentication mechanism for access to private
MG-RAST jobs and users’ inbox. The ’auth\_key’ (or ’webkey’) is a 25
character long string, e.g.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{j6FNL61ekNarTgqupMma6eMx5}
\end{sphinxVerbatim}

which is used by the API to identify an MG-RAST user account and
determine access rights to metagenomes. Note that the auth\_key is valid
for a limited time after which queries using the key will be rejected.
You can create a new auth\_key or view the expiration date and time of an
existing auth\_key on the MG-RAST website. An account can have only one
valid auth\_key and creating a new key will invalidate an existing key.

All public data in MG-RAST is available without an auth\_key. All API
queries for private data which either do not have an auth\_key or use an
invalid or expired auth\_key will get a “insufficient permissions to view
this data” response.

The auth\_key can be included in the query string like:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
https://api.mg\PYGZhy{}rast.org/1/annotation/sequence/mgm4447943.3?evalue=10\PYGZam{}type=organism\PYGZam{}source=SwissProt\PYGZam{}auth\PYGZus{}key=j6FNL61ekNarTgqupMma6eMx5
\end{sphinxVerbatim}

or in a request using curl like:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{curl} \PYG{o}{\PYGZhy{}}\PYG{n}{X} \PYG{n}{GET} \PYG{o}{\PYGZhy{}}\PYG{n}{H} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{auth: j6FNL61ekNarTgqupMma6eMx5}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://api.mg\PYGZhy{}rast.org/1/annotation/sequence/mgm4447943.3?evalue=10\PYGZam{}type=organism\PYGZam{}source=SwissProt}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

Note that for the curl command the quotes are necessary for the query to
be passed to the API correctly.

If an optional parameter passed through the query string has a list of
values only the first will be used. When multiple values are required,
e.g. for multiple md5 checksum values, they can be passed to the API
like:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{curl} \PYG{o}{\PYGZhy{}}\PYG{n}{X} \PYG{n}{POST} \PYG{o}{\PYGZhy{}}\PYG{n}{d} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZob{}}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{data}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{:[}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{000821a2e2f63df1a3873e4b280002a8}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{,}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{15bf1950bd9867099e72ea6516e3d602}\PYG{l+s+s1}{\PYGZdq{}}\PYG{l+s+s1}{]\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://api.mg\PYGZhy{}rast.org//m5nr/md5}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

In some cases, the data requested is in the form of a list with a large
number of entries. In these cases the ‘limit’ and ‘offset’ parameters
can be used to step through the list, e.g.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
https://api.mg\PYGZhy{}rast.org/1/project?order=name\PYGZam{}limit=20\PYGZam{}offset=100
\end{sphinxVerbatim}

will limit the number of entries returned to 20 with an offset of 100.
If these parameters are not provided default values of \sphinxcode{\sphinxupquote{limit=10}} and
\sphinxcode{\sphinxupquote{offset=0}} are used. The returned JSON structure will contain the
‘next’ and ‘prev’ (previous) URIs to simplify stepping through the list.

The data returned may be plain text, compressed gzipped files or a JSON
structure.

Most API queries are ‘synchronous’ and results are returned immediately.
Some queries may require a substantial time to compute results, in these
cases you can select the asynchronous option by adding
\sphinxcode{\sphinxupquote{‘\&asynchronous=1’}} to the end of the query string. This query will
then return a URL which will return the query results when they are
ready.

Most of the API calls are simply URLs which can be entered in the
address bar of a web browser to perform the download through the
browser. These URLs can also be used with a command line tool like curl,
in programing-language-specific libraries, or in command line scripts.
The examples below illustrate the use of each of these methods. The
example scripts are available on the github site along with other useful
illustrative scripts.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Top-level resources available through the MG-RAST-API}\label{\detokenize{api:id7}}
\sphinxaftertopcaption
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxstylestrong{Resource/Object}
&\sphinxstyletheadfamily 
\sphinxstylestrong{Description}
\\
\hline
\sphinxstylestrong{annotation}
&
taxonomic and functional annotations made by comparison with the M5nr database
\\
\hline
\sphinxstylestrong{compute}
&
resource to compute PCoA , heatmap, and normalization for a set of input metagenomes
\\
\hline
\sphinxstylestrong{download}
&
download results of the MG-RAST pipeline
\\
\hline
\sphinxstylestrong{inbox}
&
upload and listing of data in the staging area prior to execution of the MG-RAST pipeline
\\
\hline
\sphinxstylestrong{library}
&
library information for uploaded metagenome provided by the user
\\
\hline
\sphinxstylestrong{matrix}
&
abundance profiles in BIOM (5) format for a list of metagenomes
\\
\hline
\sphinxstylestrong{M5nr}
&
access M5 nonredundant protein database used for annotation of metagenomic sequences
\\
\hline
\sphinxstylestrong{metadata}
&
creation, export, and validation of metadata templates and spreadsheets
\\
\hline
\sphinxstylestrong{metagenome}
&
container for sample, library, project, and precomputed data for an uploaded metagenomic sequence file
\\
\hline
\sphinxstylestrong{profile}
&
returns a single data object in BIOM format
\\
\hline
\sphinxstylestrong{project}
&
project summary for metagenome provided by user
\\
\hline
\sphinxstylestrong{sample}
&
sample information provided by user
\\
\hline
\sphinxstylestrong{search}
&
search MG-RAST by MG-ID, metadata, function, or taxonomy; or implement a more complex search.
\\
\hline
\sphinxstylestrong{validation}
&
validates templates for correct structure and data
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

{[}table:upload\_speeds{]}


\section{Examples}
\label{\detokenize{api:examples}}
The API provides index-driven access to data subsets using the following
data types as indices into the data: functions, functional hierarchy
data, and taxonomic data. Whenever possible we have employed standards
to expose data and metadata, such as the BIOM standard for encoding
abundance profiles. The examples below are intended to illustrate usage
for the various resources available, they do not cover the entire
functionality of the API, see the documentation at the API website for
the comprehensive listing.
\begin{itemize}
\item {} 
\sphinxstylestrong{annotation}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
https://api.mg\PYGZhy{}rast.org/1/annotation/sequence/mgm4440036.3?type=function\PYGZam{}filter=protease\PYGZam{}source=Subsystems
\end{sphinxVerbatim}

Retrieve the reads from a metagenome with ID mgm4440036.3 which were
annotated as protease in SEED Subsystems.

\item {} 
\sphinxstylestrong{download}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{api}\PYG{o}{.}\PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{rast}\PYG{o}{.}\PYG{n}{org}\PYG{o}{/}\PYG{l+m+mi}{1}\PYG{o}{/}\PYG{n}{download}\PYG{o}{/}\PYG{n}{mgm4447943}\PYG{o}{.}\PYG{l+m+mi}{3}
\end{sphinxVerbatim}

Retrieve information formatted as a JSON object about all the files
available for download for metagenome mgm4447943.3 with information
about the files and sequence statistics where applicable. Each file
listed has a URL included which can be used to download the file,
e.g.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
https://api.mg\PYGZhy{}rast.org/1/download/mgm4447943.3?file=650.1
\end{sphinxVerbatim}

will download the protein.sims file containing the BLAT similarities.

\item {} 
\sphinxstylestrong{inbox}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{curl} \PYG{o}{\PYGZhy{}}\PYG{n}{X} \PYG{n}{POST} \PYG{o}{\PYGZhy{}}\PYG{n}{H} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{auth: auth\PYGZus{}key}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{n}{F} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{upload=@sequences.fastq}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://api.mg\PYGZhy{}rast.org/1/inbox}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

Upload the file ’sequences.fastq’ to your inbox. This API call
requires user authentication using the auth\_key described above. It
can not be used in a browser, but needs to be run from the command
line or from a script.

\item {} 
\sphinxstylestrong{matrix}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
https://api.mg\PYGZhy{}rast.org/matrix/organism?group\PYGZus{}level=family\PYGZam{}source=SEED\PYGZam{}evalue=5\PYGZam{}id=mgm4440442.5\PYGZam{}id=mgm4440026.3
\end{sphinxVerbatim}

Retrieve the taxonomic abundance profile on family level for 2
metagenomes based on SEED assignments with an evalue cutoff of 1e-5.

\item {} 
\sphinxstylestrong{metagenome}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{api}\PYG{o}{.}\PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{rast}\PYG{o}{.}\PYG{n}{org}\PYG{o}{/}\PYG{l+m+mi}{1}\PYG{o}{/}\PYG{n}{metagenome}\PYG{o}{/}\PYG{n}{mgm4440026}\PYG{o}{.}\PYG{l+m+mi}{3}
\end{sphinxVerbatim}

List analysis submission parameters and other details for a
metagenome. The metagenome resource can also be used to search
metadata, function and taxonomy.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
https://api.mg\PYGZhy{}rast.org/metagenome?function=dnaA\PYGZam{}organism=coli\PYGZam{}biome=marine\PYGZam{}match=all\PYGZam{}order=created
\end{sphinxVerbatim}

This call will find all marine metagenomes with reads annotated as
dnaA and have taxonomic assignment containing the text ‘coli’, the
results will be ordered based on creation date for the metagenome.

\item {} 
\sphinxstylestrong{project}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
https://api.mg\PYGZhy{}rast.org/project/mgp31?verbosity=full
\end{sphinxVerbatim}

Retrieve available information about the project with ID mgp31.

\item {} 
\sphinxstylestrong{sample}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
https://api.mg\PYGZhy{}rast.org/1/sample/mgs12326?verbosity=full
\end{sphinxVerbatim}

Retrieve available information about individual samples, including
IDs and metadata.

\item {} 
\sphinxstylestrong{metadata}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{api}\PYG{o}{.}\PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{rast}\PYG{o}{.}\PYG{n}{org}\PYG{o}{/}\PYG{o}{/}\PYG{n}{metadata}\PYG{o}{/}\PYG{n}{template}
\end{sphinxVerbatim}

Retrieve the static template for metadata object relationships and
types used by MG-RAST.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{api}\PYG{o}{.}\PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{rast}\PYG{o}{.}\PYG{n}{org}\PYG{o}{/}\PYG{o}{/}\PYG{n}{metadata}\PYG{o}{/}\PYG{n}{export}\PYG{o}{/}\PYG{n}{mgp128}
\end{sphinxVerbatim}

Retrieve all metadata for project mgp128.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{api}\PYG{o}{.}\PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{rast}\PYG{o}{.}\PYG{n}{org}\PYG{o}{/}\PYG{n}{metadata}\PYG{o}{/}\PYG{n}{cv}
\end{sphinxVerbatim}

Retrieve a set of lists of all our controlled metadata terms,
including the ontologies.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
https://api.mg\PYGZhy{}rast.org/metadata/ontology?name=biome\PYGZam{}version=2013\PYGZhy{}04\PYGZhy{}27
\end{sphinxVerbatim}

Retrieve a more detailed list (with relationships) for a specific
version of the ontology.

\item {} 
\sphinxstylestrong{m5nr}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
https://api.mg\PYGZhy{}rast.org/1/m5nr/md5/ffc62262a18b38671c3e337150ef535f?source=SwissProt
\end{sphinxVerbatim}

Retrieve the UniProt ID for a given sequence identifier.

\end{itemize}


\chapter{Example scripts using the MG-RAST REST API}
\label{\detokenize{api:example-scripts-using-the-mg-rast-rest-api}}\label{\detokenize{api:api-examples}}
.


\section{Introduction}
\label{\detokenize{api:introduction-2}}\label{\detokenize{api:id1}}
As part of the RESTful API (see chapter {\hyperref[\detokenize{api:API}]{\emph{6}}}), we are providing
a collection of example scripts.

Each script has comments in the source code as well as a help function.
This document provides a brief overview of the available scripts and
their intended purpose. Please see the help associated with all of the
individual files for a complete list of options and more details.

We believe these scripts to be the best starting point for many users,
he we attempt to provide a listing of the most important tools.


\subsection{URLs}
\label{\detokenize{api:urls-1}}\label{\detokenize{api:id2}}
The Examples are located on github at:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{github}\PYG{o}{.}\PYG{n}{com}\PYG{o}{/}\PYG{n}{MG}\PYG{o}{\PYGZhy{}}\PYG{n}{RAST}\PYG{o}{/}\PYG{n}{MG}\PYG{o}{\PYGZhy{}}\PYG{n}{RAST}\PYG{o}{\PYGZhy{}}\PYG{n}{Tools}
\end{sphinxVerbatim}

This is the base directory for the rest of this chapter, go here to find
the tools and examples described below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{github}\PYG{o}{.}\PYG{n}{com}\PYG{o}{/}\PYG{n}{MG}\PYG{o}{\PYGZhy{}}\PYG{n}{RAST}\PYG{o}{/}\PYG{n}{MG}\PYG{o}{\PYGZhy{}}\PYG{n}{RAST}\PYG{o}{\PYGZhy{}}\PYG{n}{Tools}\PYG{o}{/}\PYG{n}{tree}\PYG{o}{/}\PYG{n}{master}\PYG{o}{/}\PYG{n}{tools}\PYG{o}{/}\PYG{n+nb}{bin}
\end{sphinxVerbatim}

Each script has a verbose help option (\textendash{}help) to list all options and
explain their usage.


\section{Download DNA sequence for a function \textendash{} mg-get-sequences-for-function.py}
\label{\detokenize{api:download-dna-sequence-for-a-function-mg-get-sequences-for-function-py}}
This script will retrieve sequences and annotation for a given function
or functional class.

The output is a tab-delimited list of: m5nr id, dna sequence, semicolon
seperated list of annotations, sequence id.

\sphinxstylestrong{Example:}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{get}\PYG{o}{\PYGZhy{}}\PYG{n}{sequences}\PYG{o}{\PYGZhy{}}\PYG{k}{for}\PYG{o}{\PYGZhy{}}\PYG{n}{function}\PYG{o}{.}\PYG{n}{py} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{id} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{mgm4441680.3}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{name} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Central carbohydrate metabolism}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{level} \PYG{n}{level2} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{source} \PYG{n}{Subsystems} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{evalue} \PYG{l+m+mi}{10}
\end{sphinxVerbatim}


\section{Download DNA sequences for a taxon or taxonomic group\textendash{} mg-get-sequences-for-taxon.py}
\label{\detokenize{api:download-dna-sequences-for-a-taxon-or-taxonomic-group-mg-get-sequences-for-taxon-py}}
This script will retrieve sequences and annotation for a given taxon or
taxonomic group.

The output is a tab-delimited list of: m5nr id, dna sequence, semicolon
seperated list of annotations, sequence id

\sphinxstylestrong{Example:}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{get}\PYG{o}{\PYGZhy{}}\PYG{n}{sequences}\PYG{o}{\PYGZhy{}}\PYG{k}{for}\PYG{o}{\PYGZhy{}}\PYG{n}{taxon}\PYG{o}{.}\PYG{n}{py} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{id} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{mgm4441680.3}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{name} \PYG{n}{Lachnospiraceae} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{level} \PYG{n}{family} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{source} \PYG{n}{RefSeq} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{evalue} \PYG{l+m+mi}{8}
\end{sphinxVerbatim}


\section{Download sequences annotated with function and taxonomy \textendash{} mg-get-annotation-set.py}
\label{\detokenize{api:download-sequences-annotated-with-function-and-taxonomy-mg-get-annotation-set-py}}
Retrieve functional annotations for given metagenome and organism.

The output is a tab-delimited list of annotations: feature list,
function, abundance for function, avg evalue for function, organism.

\sphinxstylestrong{Example:}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{get}\PYG{o}{\PYGZhy{}}\PYG{n}{annotation}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{set}\PYG{o}{.}\PYG{n}{py} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{id} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{mgm4441680.3}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{top} \PYG{l+m+mi}{5} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{level} \PYG{n}{genus} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{source} \PYG{n}{SEED}
\end{sphinxVerbatim}


\section{Download the n most abundant functions for a metagenome \textendash{} mg-abundant-functions.py}
\label{\detokenize{api:download-the-n-most-abundant-functions-for-a-metagenome-mg-abundant-functions-py}}
Retrieve the top n abundant functions for metagenome.

The output is a tab-delimited list of function and abundance sorted by
abundance (largest first). ’top’ option controls number of rows
returned.

\sphinxstylestrong{Example:}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{abundant}\PYG{o}{\PYGZhy{}}\PYG{n}{functions}\PYG{o}{.}\PYG{n}{py} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{id} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{mgm4441680.3}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{level} \PYG{n}{level3} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{source} \PYG{n}{Subsystems} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{top} \PYG{l+m+mi}{20} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{evalue} \PYG{l+m+mi}{8}
\end{sphinxVerbatim}


\section{Download and translate similarities into different namespaces e.g. SEED or GenBank \textendash{} m5nr-tools.pl}
\label{\detokenize{api:download-and-translate-similarities-into-different-namespaces-e-g-seed-or-genbank-m5nr-tools-pl}}
MG-RAST computes similarities against a non-redundant database (Wilke et
al. 2012) and later translates them into any of the supported
namespaces. As a result you can view your annotations (or indeed the
similarity results) in each of these namespaces. Sometimes this can lead
to new features and or differences becoming visible that would otherwise
be obscured.

m5nr-tools can translate accession ids, md5 checksums, or protein
sequence into annotations. One option for output is a blast m8 formatted
file.

\sphinxstylestrong{Example:}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{m5nr}\PYG{o}{\PYGZhy{}}\PYG{n}{tools}\PYG{o}{.}\PYG{n}{pl} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{api} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://api.mg\PYGZhy{}rast.org/1}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{option} \PYG{n}{annotation} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{source} \PYG{n}{RefSeq} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{md5} \PYG{l+m+mi}{0}\PYG{n}{b95101ffea9396db4126e4656460ce5}\PYG{p}{,}\PYG{l+m+mf}{068792e95}\PYG{n}{e38032059ba7d9c26c1be78}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{n}{b96c92ce600d8b2427eedbc221642f1}
\end{sphinxVerbatim}


\section{Download multiple abundance profiles for comparison \textendash{} mg-compare-functions}
\label{\detokenize{api:download-multiple-abundance-profiles-for-comparison-mg-compare-functions}}
Retrieve matrix of functional abundance profiles for multiple
metagenomes. The output is either tab-delimited table of functional
abundance profiles, metagenomes in columns and functions in rows or BIOM
format of functional abundance profiles.

\sphinxstylestrong{Example:}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{compare}\PYG{o}{\PYGZhy{}}\PYG{n}{functions}\PYG{o}{.}\PYG{n}{py} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{ids} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{mgm4441679.3,mgm4441680.3,mgm4441681.3,mgm4441682.3}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{level} \PYG{n}{level2} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{source} \PYG{n}{KO} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{format} \PYG{n}{text} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{evalue} \PYG{l+m+mi}{8}
\end{sphinxVerbatim}


\chapter{Standard operating procedures SOPs for MG-RAST}
\label{\detokenize{api:standard-operating-procedures-sops-for-mg-rast}}

\section{SOP - Metagenome submission, publication and submission to INSDC via MG-RAST}
\label{\detokenize{api:sop-metagenome-submission-publication-and-submission-to-insdc-via-mg-rast}}
MG-RAST can be used to host data for public access. There are three
interfaces for uploading and publishing data, the Web interface,
intended for most users, command line scripts, intended for programmers,
and the native RESTful API, recommended for experienced programmers.

When data is published in MG-RAST, it can also be released to the INSDC
databases. This tutorial covers both use cases.

We note that MG-RAST provides temporary IDs and permanent public
identifiers. The permanent identifiers are assigned at the time data is
made public. Permanent MG-RAST identifiers begin with “mgm” (e.g.
“mgm4449249.3”) for data sets and mgp (e.g.”mgp128”) for
projects/studies.

The following data types are supported:
\begin{itemize}
\item {} 
Shotgun metagenomes (“raw” and assembled)

\item {} 
Metatranscriptome data (“raw” and assembled)

\item {} 
Ribosomal amplicon data (16s, 18s, ITS amplicons)

\item {} 
Metabarcoding data (e.g. cytochrome C amplicons; basically all non
ribosomal amplicons)

\end{itemize}

PLEASE NOTE: We strongly prefer raw data over assembled data, if you
submit assembled data, please submit the raw reads in parallel. If you
perform local optimization e.g. adapter removal or quality clipping,
please submit the raw data as well.

This document is intended for experienced to very experienced users and
programmers. We recommend that most users not use the RESTful API. There
is also a document describing data publication and INSDC submission via
the web UI.

An access token for the MG-RAST API, this can be obtained from the
MG-RAST web page (\sphinxurl{http://mg-rast.org}) in the user section.

You will need a working python interpreter and the command line scripts
and example data can be found in
\sphinxurl{https://github.com/MG-RAST/MG-RAST-Tools}:

Scripts: MG-RAST-Tools/tools/bin Data: MG-RAST-Tools/examples/sop/data

Change into MG-RAST-Tools/examples/sop/data and call:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{sh} \PYG{n}{get\PYGZus{}test\PYGZus{}data}\PYG{o}{.}\PYG{n}{sh}
\end{sphinxVerbatim}

to add additional example data.

Either download the repository as a zipped archive from
\sphinxurl{https://github.com/MG-RAST/MG-RAST-Tools/archive/master.zip} or use the
git command line tool:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{git} \PYG{n}{clone} \PYG{n}{http}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{github}\PYG{o}{.}\PYG{n}{com}\PYG{o}{/}\PYG{n}{MG}\PYG{o}{\PYGZhy{}}\PYG{n}{RAST}\PYG{o}{/}\PYG{n}{MG}\PYG{o}{\PYGZhy{}}\PYG{n}{RAST}\PYG{o}{\PYGZhy{}}\PYG{n}{Tools}\PYG{o}{.}\PYG{n}{git}
\end{sphinxVerbatim}

We tested up to the following parameters:
\begin{itemize}
\item {} 
max. size per file: 10GB

\item {} 
max. project size: 200 metagenomes

\end{itemize}

While there is no reason to assume the software will not work with
larger numbers of files or larger files, we did not test for that.


\subsection{SOP:}
\label{\detokenize{api:sop}}
Upload and submit sequence data and metadata to MG-RAST using the
command mg-submit.py Note: This is an asynchronous process that may take
some time depending on the size and number of datasets. (Note: We
recommend that novice users try the web frontend; the cmd-line is
primarily intended for programmers) The metadata in this example is in
Microsoft Excel format, there is also an option of using JSON formatted
data. Please note: We have observed multiple problems with spreadsheets
that were converted from older version of Excel or “compatible” tools
e.g. OpenOffice.

Example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{submit}\PYG{o}{.}\PYG{n}{py} \PYG{n}{submit} \PYG{n}{simple}  \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}  \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{metadata}
\end{sphinxVerbatim}

Verify the results and obtain a temporary identifier E.g. by using the
WebUI at \sphinxurl{http://mg-rast.org} \textendash{} you can also use that to publish the data
and trigger submission to INSDC.

Publish your project in MG-RAST and obtain a stable and public MG-RAST
project identifier

Note: once the data is made public the data is read only, but metadata
can be improved

Example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
mg\PYGZhy{}project make\PYGZhy{}public \PYGZdl{}temporary\PYGZus{}ID
\end{sphinxVerbatim}

Trigger release to INSDC/ submit to EBI

Note: Metadata updates are automatically synced with INSDC databases
within 48 hours.

Example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
mg\PYGZhy{}project submit\PYGZhy{}ebi \PYGZdl{}PROJECT\PYGZus{}ID
\end{sphinxVerbatim}

Check status of release to INSDC/ submission to EBI

Note: This is an asynchronous process that may take some time depending
on the size and number of datasets.

Example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
mg\PYGZhy{}project status\PYGZhy{}ebi \PYGZdl{}PROJECT\PYGZus{}ID
\end{sphinxVerbatim}

We include a sample submission below:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
From within the MG\PYGZhy{}RAST\PYGZhy{}Tool repository directory

\PYGZsh{} Retrieve repository and setup environment
git clone http://github.com/MG\PYGZhy{}RAST/MG\PYGZhy{}RAST\PYGZhy{}Tools.git
cd MG\PYGZhy{}RAST\PYGZhy{}Tools

\PYGZsh{} Path to scripts for this example
PATH=\PYGZdl{}PATH:{}`pwd{}`/tools/bin

\PYGZsh{} set environment variables
source set\PYGZus{}env.sh

\PYGZsh{} Set credentials, obtain token from your user preferences in the UI
mg\PYGZhy{}submit.py login \PYGZhy{}\PYGZhy{}token

\PYGZsh{} Create metadata spreadsheet. Make sure you map your samples to your
\PYGZsh{} sequence files
\PYGZsh{} Upload metagenomes and metadata to MG\PYGZhy{}RAST

mg\PYGZhy{}submit.py submit simple \PYGZbs{}
           examples/sop/data/sample\PYGZus{}1.fasta.gz \PYGZbs{}
           examples/sop/data/sample\PYGZus{}2.fasta.gz \PYGZbs{}
           \PYGZhy{}\PYGZhy{}metadata examples/sop/data/metadata.xlsx

\PYGZsh{} Output
\PYGZgt{} Temp Project ID: ed2102aa666d676d343735323836382e33
\PYGZgt{} Submission ID: 77a1a1a5\PYGZhy{}4cbd\PYGZhy{}4673\PYGZhy{}86bf\PYGZhy{}f87c9096c3e1

\PYGZsh{} Remember IDs for later use
SUBMISSION\PYGZus{}ID=77a1a1a5\PYGZhy{}4cbd\PYGZhy{}4673\PYGZhy{}86bf\PYGZhy{}f87c9096c3e1
TEMP\PYGZus{}ID=mgp128

\PYGZsh{} Check if project is finished
mg\PYGZhy{}submit.py status \PYGZdl{}SUBMISSION\PYGZus{}ID

\PYGZsh{} Output
\PYGZgt{} Submission: 77a1a1a5\PYGZhy{}4cbd\PYGZhy{}4673\PYGZhy{}86bf\PYGZhy{}f87c9096c3e1 Status: in\PYGZhy{}progress


\PYGZsh{} Make project public in MG\PYGZhy{}RAST
mg\PYGZhy{}project.py make\PYGZhy{}public \PYGZdl{}TEMP\PYGZus{}ID

\PYGZsh{} Output
\PYGZgt{} \PYGZsh{} Your project is public.
\PYGZgt{} Project ID: mgp128
\PYGZgt{} URL: https://mg\PYGZhy{}rast.org/linkin.cgi?project=mgp128
PROJECT\PYGZus{}ID=mgp128

\PYGZsh{} Release project to INSDC archives
mg\PYGZhy{}project.py submit\PYGZhy{}ebi \PYGZdl{}PROJECT\PYGZus{}ID

\PYGZsh{} Output
\PYGZgt{} \PYGZsh{} Your Project mgp128 has been submitted
\PYGZgt{} Submission ID: 0cf7d811\PYGZhy{}1d43\PYGZhy{}4554\PYGZhy{}ab97\PYGZhy{}3cb1f5ceb6aa

\PYGZsh{} Check if project is finished
mg\PYGZhy{}project.py status\PYGZhy{}ebi \PYGZdl{}PROJECT\PYGZus{}ID

\PYGZsh{} Output
\PYGZgt{} Completed
\PYGZgt{} ENA Study Accession: ERP104408
\end{sphinxVerbatim}


\section{Acknowledgments}
\label{\detokenize{api:acknowledgments}}
This project is funded by the NIH grant R01AI123037 and by NSF grant
1645609

This work used the Magellan machine (U.S.Department of Energy, Office of
Science, Advanced Scientific Computing Research, under contract
DE-AC02-06CH11357) at Argonne National Laboratory, and the PADS resource
(National Science Foundation grant OCI-0821678) at the Argonne National
Laboratory/University of Chicago Computation Institute.

In the past the following sources contributed to MG-RAST development:
\begin{itemize}
\item {} 
U.S. Dept. of Energy under Contract DE-AC02-06CH11357

\item {} 
Sloan Foundation (SLOAN \#2010-12),

\item {} 
NIH NIAID (HHSN272200900040C),

\item {} 
NIH Roadmap HMP program (1UH2DK083993-01).

\end{itemize}

Angiuoli, S. V., M. Matalka, A. Gussman, K. Galens, M. Vangala, D.
R. Riley, C. Arze, J. R. White, O. White, and W. F. Fricke. 2011.
“CloVR: A Virtual Machine for Automated and Portable Sequence
Analysis from the Desktop Using Cloud Computing.” \sphinxstyleemphasis{BMC
Bioinformatics} 12: 356.

Aziz, Ramy, Daniela Bartels, Aaron Best, Matthew DeJongh, Terrence
Disz, Robert Edwards, Kevin Formsma, et al. 2008. “The RAST
Server: Rapid Annotations Using Subsystems Technology.” \sphinxstyleemphasis{BMC
Genomics} 9 (1): 75. \sphinxurl{https://doi.org/10.1186/1471-2164-9-75}.

Benson, D. A., M. Cavanaugh, K. Clark, I. Karsch-Mizrachi, D. J.
Lipman, J. Ostell, and E. W. Sayers. 2013. “GenBank.” \sphinxstyleemphasis{Nucleic
Acids Res} 41 (Database issue): D36\textendash{}42.

Board, OpenMP Architecture Review. 2011. “OpenMP Application
Program Interface Version 3.1.”

Bolotin, A., B. Quinquis, A. Sorokin, and S. D. Ehrlich. 2005.
“Clustered Regularly Interspaced Short Palindrome Repeats
(CRISPRs) Have Spacers of Extrachromosomal Origin.” \sphinxstyleemphasis{Microbiology}
151 (Pt 8): 2551\textendash{}61.

Buchfink, Benjamin, Chao Xie, and Daniel H Huson. 2015. “Fast and
Sensitive Protein Alignment Using Diamond.” \sphinxstyleemphasis{Nature Methods} 12
(1): 59\textendash{}60.

Caporaso, J. G., J. Kuczynski, J. Stombaugh, K. Bittinger, F. D.
Bushman, E. K. Costello, N. Fierer, et al. 2010. “QIIME Allows
Analysis of High-Throughput Community Sequencing Data.” \sphinxstyleemphasis{Nat
Methods} 7 (5): 335\textendash{}6.

Cole, J. R., B. Chai, T. L. Marsh, R. J. Farris, Q. Wang, S. A.
Kulam, S. Chandra, et al. 2003. “The Ribosomal Database Project
(RDP-II): Previewing a New Autoaligner That Allows Regular Updates
and the New Prokaryotic Taxonomy.” \sphinxstyleemphasis{Nucleic Acids Research} 31
(1): 442\textendash{}43. \sphinxurl{http://www.ncbi.nlm.nih.gov/pmc/articles/PMC165486/}.

Cox, M. P., D. A. Peterson, and P. J. Biggs. 2010. “SolexaQA:
At-a-Glance Quality Assessment of Illumina Second-Generation
Sequencing Data.” \sphinxstyleemphasis{BMC Bioinformatics} 11: 485.

DeSantis, T. Z., P. Hugenholtz, N. Larsen, M. Rojas, E. L. Brodie,
K. Keller, T. Huber, D. Dalevi, P. Hu, and G. L. Andersen. 2006.
“Greengenes, a Chimera-Checked16S rRNA Gene Database and Workbench
Compatible with ARB.” \sphinxstyleemphasis{Appl. Environ. Microbiol.} 72 (7): 5069\textendash{}72.
\sphinxurl{https://doi.org/10.1128/aem.03006-05}.

Edgar, R. C. 2010. “Search and Clustering Orders of Magnitude
Faster Than BLAST.” \sphinxstyleemphasis{Bioinformatics} 26 (19): 2460\textendash{}1.

Field, D., L. Amaral-Zettler, G. Cochrane, J. R. Cole, P. Dawyndt,
G. M. Garrity, J. Gilbert, F. O. Glöckner, L. Hirschman, and I.
Karsch-Mizrachi. 2011. “The Genomic Standards Consortium.” \sphinxstyleemphasis{PLOS
Biology} 9 (6): e1001088.

Gerlach, Wolfgang, Wei Tang, Kevin Keegan, Travis Harrison,
Andreas Wilke, Jared Bischof, Mark D’Souza, et al. 2014. “Skyport:
Container-Based Execution Environment Management for Multi-Cloud
Scientific Workflows.” In \sphinxstyleemphasis{Proceedings of the 5th International
Workshop on Data-Intensive Computing in the Clouds}, 25\textendash{}32.
DataCloud ’14. Piscataway, NJ, USA: IEEE Press.
\sphinxurl{https://doi.org/10.1109/DataCloud.2014.6}.

Gomez-Alvarez, V., T. K. Teal, and T. M. Schmidt. 2009.
“Systematic Artifacts in Metagenomes from Complex Microbial
Communities.” \sphinxstyleemphasis{ISME J} 3 (11): 1314\textendash{}7.

Huse, S. M., J. A. Huber, H. G. Morrison, M. L. Sogin, and D. M.
Welch. 2007. “Accuracy and Quality of Massively Parallel DNA
Pyrosequencing.” \sphinxstyleemphasis{Genome Biol} 8 (7): R143.

Huson, D. H., A. F. Auch, J. Qi, and S. C. Schuster. 2007. “MEGAN
Analysis of Metagenomic Data.” \sphinxstyleemphasis{Genome Res} 17 (3): 377\textendash{}86.

Institute, National Human Genome Research. 2012. “Cost Per Raw
Megabase of Dna Sequence.”
\sphinxurl{http://www.genome.gov/images/content/cost\_per\_megabase.jpg}.

Jensen, L. J., P. Julien, M. Kuhn, C. von Mering, J. Muller, T.
Doerks, and P. Bork. 2008. “EggNOG: Automated Construction and
Annotation of Orthologous Groups of Genes.” \sphinxstyleemphasis{Nucleic Acids Res} 36
(Database issue): D250\textendash{}4.

Kanehisa, M. 2002. “The KEGG Database.” \sphinxstyleemphasis{Novartis Found Symp} 247:
91\textendash{}101; discussion 101\textendash{}3, 119\textendash{}28, 244\textendash{}52.

Keegan, K. P., W. L. Trimble, J. Wilkening, A. Wilke, T. Harrison,
M. D’Souza, and F. Meyer. 2012. “A Platform-Independent Method for
Detecting Errors in Metagenomic Sequencing Data: DRISEE.” \sphinxstyleemphasis{PLOS
Comput Biol} 8 (6): e1002541.

Kent, W. J. 2002. “BLAT\textendash{}the BLAST-Like Alignment Tool.” \sphinxstyleemphasis{Genome
Res} 12 (4): 656\textendash{}64.

Langmead, B., C. Trapnell, M. Pop, and S. L. Salzberg. 2009.
“Ultrafast and Memory-Efficient Alignment of Short DNA Sequences
to the Human Genome.” \sphinxstyleemphasis{Genome Biol} 10 (3): R25.

Loman, Nicholas J., Raju V. Misra, Timothy J. Dallman, Chrystala
Constantinidou, Saheer E Gharbia, John Wain, and Mark J. Pallen.
2012. “Performance Comparison of Benchtop High-Throughput
Sequencing Platforms.” \sphinxstyleemphasis{Nature Biotechnology} 30 (5): 434\textendash{}39.
\sphinxurl{https://doi.org/10.1038/nbt.2198}.

Magrane, Michele, and UniProt Consortium. 2011. “UniProt
Knowledgebase: A Hub of Integrated Protein Data.” \sphinxstyleemphasis{Database: The
Journal of Biological Databases and Curation} 2011 (January).
\sphinxurl{https://doi.org/10.1093/database/bar009}.

Markowitz, V. M., N. N. Ivanova, E. Szeto, K. Palaniappan, K. Chu,
D. Dalevi, I. M. Chen, et al. 2008. “IMG/M: A Data Management and
Analysis System for Metagenomes.” \sphinxstyleemphasis{Nucleic Acids Res} 36 (Database
issue): D534\textendash{}8.

McDonald, D., J. C. Clemente, J. Kuczynski, J. Rideout, J.
Stombaugh, D. Wendel, A. Wilke, S. Huse, J. Hufnagle, and F.
Meyer. 2012. “The Biological Observation Matrix (BIOM) Format or:
How I Learned to Stop Worrying and Love the Ome-Ome.”
\sphinxstyleemphasis{Gigascience}.

Meyer, F., D. Paarmann, M. D’Souza, R. Olson, E. M. Glass, M.
Kubal, T. Paczian, et al. 2008. “The Metagenomics RAST Server - a
Public Resource for the Automatic Phylogenetic and Functional
Analysis of Metagenomes.” \sphinxstyleemphasis{BMC Bioinformatics} 9 (1): 386.
\sphinxurl{https://doi.org/10.1186/1471-2105-9-386}.

Ondov, B. D., N. H. Bergman, and A. M. Phillippy. 2011.
“Interactive Metagenomic Visualization in a Web Browser.” \sphinxstyleemphasis{BMC
Bioinformatics} 12: 385.

Overbeek, R., T. Begley, R. M. Butler, J. V. Choudhuri, N. Diaz,
H.-Y. Chuang, M. Cohoon, et al. 2005. “The Subsystems Approach to
Genome Annotation and Its Use in the Project to Annotate 1000
Genomes.” \sphinxstyleemphasis{Nucleic Acids Res} 33 (17).

Pruesse, Elmar, Christian Quast, Katrin Knittel, Bernhard M.
Fuchs, Wolfgang Ludwig, Jörg Peplies, and Frank Oliver O.
Glöckner. 2007. “SILVA: A Comprehensive Online Resource for
Quality Checked and Aligned Ribosomal RNA Sequence Data Compatible
with ARB.” \sphinxstyleemphasis{Nucleic Acids Research} 35 (21): 7188\textendash{}96.
\sphinxurl{https://doi.org/10.1093/nar/gkm864}.

Pruitt, K. D., T. Tatusova, and D. R. Maglott. 2007. “NCBI
Reference Sequences (RefSeq): A Curated Non-Redundant Sequence
Database of Genomes, Transcripts and Proteins.” \sphinxstyleemphasis{Nucleic Acids
Res} 35 (Database issue).
\sphinxurl{http://view.ncbi.nlm.nih.gov/pubmed/17130148}.

R., Kottmann, Gray T., Murphy S., Kagan L., Kravitz S., Lombardot
T., Field D., and Glöckner FO; Genomic Standards Consortium. 2008.
“A Standard MIGS/MIMS Compliant XML Schema: Toward the Development
of the Genomic Contextual Data Markup Language (GCDML).” \sphinxstyleemphasis{OMICS}
12 (2): 115\textendash{}21. \sphinxurl{https://doi.org/10.1089/omi.2008.0A10}.

Reeder, J., and R. Knight. 2009. “The ‘Rare Biosphere’: A Reality
Check.” \sphinxstyleemphasis{Nat Methods} 6 (9): 636\textendash{}7.

Rho, Mina, Haixu Tang, and Yuzhen Ye. 2010. “FragGeneScan:
Predicting Genes in Short and Error-Prone Reads.” \sphinxstyleemphasis{Nucleic Acids
Research} 38 (20): e191\textendash{}e191.

Riesenfeld, C. S., P. D. Schloss, and J. Handelsman. 2004.
“Metagenomics: Genomic Analysis of Microbial Communities.” \sphinxstyleemphasis{Annu
Rev Genet} 38: 525\textendash{}52.

Snyder, E. E., N. Kampanya, J. Lu, E. K. Nordberg, H. R. Karur, M.
Shukla, J. Soneja, et al. 2007. “PATRIC: The VBI PathoSystems
Resource Integration Center.” \sphinxstyleemphasis{Nucleic Acids Res} 35 (Database
issue). \sphinxurl{https://doi.org/10.1093/nar/gkl858}.

Speed, Terry. 2003. \sphinxstyleemphasis{Statistical Analysis of Gene Expression
Microarray Data}. Chapman; Hall/CRC.
\sphinxurl{http://www.amazon.com/Statistical-Analysis-Gene-Expression-Microarray/dp/1584883278/}.

Tatusov, R. L., N. D. Fedorova, J. D. Jackson, A. R. Jacobs, B.
Kiryutin, E. V. Koonin, D. M. Krylov, et al. 2003. “The COG
Database: An Updated Version Includes Eukaryotes.” \sphinxstyleemphasis{BMC
Bioinformatics} 4: 41.

Thomas, Torsten, Jack Gilbert, and Folker Meyer. 2012.
“Metagenomics - a Guide from Sampling to Data Analysis.”
\sphinxstyleemphasis{Microbial Informatics and Experimentation} 2 (1): 3.
\sphinxurl{https://doi.org/10.1186/2042-5783-2-3}.

Trimble, W. L., K. P. Keegan, M. D’Souza, A. Wilke, J. Wilkening,
J. Gilbert, and F. Meyer. 2012. “Short-Read Reading-Frame
Predictors Are Not Created Equal: Sequence Error Causes Loss of
Signal.” \sphinxstyleemphasis{BMC Bioinformatics} 13 (1): 183.

Wilke, A., T. Harrison, J. Wilkening, D. Field, E. M. Glass, N.
Kyrpides, K. Mavrommatis, and F. Meyer. 2012. “The M5nr: A Novel
Non-Redundant Database Containing Protein Sequences and
Annotations from Multiple Sources and Associated Tools.” \sphinxstyleemphasis{BMC
Bioinformatics} 13: 141.

Wilke, Andreas, Wolfgang Gerlach, Travis Harrison, Tobias Paczian,
Wei Tang, William L. Trimble, Jared Wilkening, Narayan Desai, and
Folker Meyer. 2015. “Shock: Active Storage for Multicloud
Streaming Data Analysis.” In \sphinxstyleemphasis{2nd IEEE/ACM International Symposium
on Big Data Computing, BDC 2015, Limassol, Cyprus, December 7-10,
2015}, edited by Ioan Raicu, Omer F. Rana, and Rajkumar Buyya,
68\textendash{}72. IEEE. \sphinxurl{https://doi.org/10.1109/BDC.2015.40}.

Wilke, A., J. Wilkening, E. M. Glass, N. Desai, and F. Meyer.
2011. “An Experience Report: Porting the MG-RAST Rapid
Metagenomics Analysis Pipeline to the Cloud.” \sphinxstyleemphasis{Concurrency and
Computation: Practice and Experience} 23 (17): 2250\textendash{}7.

Wilkening, J., A. Wilke, N. Desai, and F. Meyer. 2009. “Using
Clouds for Metagenomics: A Case Study.” In \sphinxstyleemphasis{IEEE Cluster 2009}.

Yilmaz, Pelin, Renzo Kottmann, Dawn Field, Rob Knight, James Cole,
Linda Amaral-Zettler, Jack Gilbert, et al. 2010. “The ‘Minimum
Information About an ENvironmental Sequence’ (MIENS)
Specification.” \sphinxstyleemphasis{Nature Biotechnology}.


\chapter{FAQ \textendash{} Frequently asked questions about MG-RAST}
\label{\detokenize{faq:faq-frequently-asked-questions-about-mg-rast}}\label{\detokenize{faq::doc}}
The answers to some of these Frequently Asked Questions can be found
elsewhere in this manual, they are listed here for users who would like
a quick answer to a simple question. Other sections of the manual will
generally contain more detail than the answers in this chapter. Some
answers are just links to relevant sections in other chapters.


\section{General}
\label{\detokenize{faq:general}}

\subsection{What is MG-RAST?}
\label{\detokenize{faq:what-is-mg-rast}}
The MG-RAST server is an open source system for annotation and
comparative analysis of metagenomes. Users can upload raw sequence data
in fasta format; the sequences will be normalized and processed and
summaries automatically generated. The server provides several methods
to access the different data types, including phylogenetic and metabolic
reconstructions, and the ability to compare the metabolism and
annotations of one or more metagenomes and genomes. In addition, the
server offers a comprehensive search capability. Access to the data is
password protected, and all data generated by the automated pipeline is
available for download in a variety of common formats.


\subsection{Contacting the MG-RAST team and help desk}
\label{\detokenize{faq:contacting-the-mg-rast-team-and-help-desk}}\label{\detokenize{faq:section-contact-mgrast}}
The MG-RAST project uses a ticket system to manage interactions with
users, please use the email address for the MG-RAST project shown in
Figure {\hyperref[\detokenize{faq:fig:mgrastemail}]{\emph{9.1}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=3in]{{mgrastemail}.png}
\caption{The email address for the MG-RAST project. Note that it was inserted
into this document as an image and can not be copied as text, you
will have to type it.}\label{\detokenize{faq:fig-mgrastemail}}\end{figure}

We recommend including as much detail as possible into your emails to
the help-desk, details like account names, MG-RAST identifiers will help
us identify any issues and speed up resolving them.

Below are examples of the types of details we would like to receive:
\begin{itemize}
\item {} 
your name

\item {} 
your account name for MG-RAST (please do NOT include your password or
webkey)

\item {} 
a clear text description of your problem

\item {} 
any MG-RAST identifiers (those are the 444xxxx.3 numbers)

\item {} 
any project numbers

\item {} 
the browser and which version you are using, if the problem relates
to the web site

\item {} 
what platform your data was created on

\item {} 
if your data was a failure in the web site, what time the failure
occurred

\item {} 
the URL and name of the page you were viewing

\item {} 
screenshot(s) of the problem

\end{itemize}


\subsection{What kinds of data sets does MG-RAST analyze?}
\label{\detokenize{faq:what-kinds-of-data-sets-does-mg-rast-analyze}}
MG-RAST is designed to annotate a large set of nucleotide sequences, not
a complete genome and not amino acid sequences. The RAST server should
be used if you want to annotate complete, or nearly complete prokaryotic
genomes. Version 3.2 accepts reads of length 75bp and up, and is capable
of handling sequences of several dozen kilobases. For whole metagenome
shotgun data we use a gene prediction step that is not suitable for
eukaryotes, for that reason do not expect MG-RAST v3.2 to work with
eukaryotic data sets or for the eukaryotic subsets of your data.


\subsection{How many metagenomes can I submit?}
\label{\detokenize{faq:how-many-metagenomes-can-i-submit}}
We do not restrict user submission of samples. However, the computation
required is massive and samples are processed on a first-come,
first-serve basis. MG-RAST v3 is over 200 times faster than the previous
version. We will also provide a CLOUD client (shortly after the initial
release) that connects to MG-RAST and will allow you to add processing
power to your jobs in MG-RAST.


\subsection{Can I use MG-RAST as a repository for my metagenomic data?}
\label{\detokenize{faq:can-i-use-mg-rast-as-a-repository-for-my-metagenomic-data}}
MG-RAST has become an unofficial repository for metagenomic data,
providing a means to make your data public so that it is available for
download and viewing of the analysis without registration, as well as a
static link that you can use in publications. It also requires that you
include experimental metadata about your sample when it is made public
to increase the usefulness to the community. We undertake to maintain
public datasets within MG-RAST and they are not subject to deletion.


\subsection{Who should I contact with questions or problems with MG-RAST?}
\label{\detokenize{faq:who-should-i-contact-with-questions-or-problems-with-mg-rast}}
All questions, comments or problems regarding MG-RAST should be directed
to our support team using either the letter symbol in the navigation
toolbox or via email to:

\sphinxcode{\sphinxupquote{help at mg-rast.org}}

.


\subsection{How should I link to MG-RAST in a publication?}
\label{\detokenize{faq:how-should-i-link-to-mg-rast-in-a-publication}}
You can provide a stable link to an MG-RAST job or project using the
following URLs:

\sphinxcode{\sphinxupquote{http://mg-rast.org/linkin.cgi?metagenome=}}

\sphinxcode{\sphinxupquote{http://mg-rast.org/linkin.cgi?project=}}

For example, for the metagenome ID 4440283.3 the URL is:

\sphinxurl{http://mg-rast.org/linkin.cgi?metagenome=4440283.3}

This URL provides a stable method of linking to your data which does not
require the viewer to have an MG-RAST account. Please do not use the URL
you see when you are browsing the site.

Note that by default your data is not visible to others, you will need
to explicitly grant permission for it to be visible to anyone on the
internet by making it public through the MG-RAST website.


\subsection{Identifiers}
\label{\detokenize{faq:section-identifier}}\label{\detokenize{faq:identifiers}}
MG-RAST automatically assigns a unique identifier to every dataset
submitted. Upon completion of the automated pipeline, datasets can be
viewed via the web interface by using the identifiers. The dataset
identifiers are of the form \sphinxcode{\sphinxupquote{integer prefix}}.\sphinxcode{\sphinxupquote{revision}}. An
example is \sphinxcode{\sphinxupquote{4440283.3}}.

In addition to individual datasets, projects (groups of datasets) can be
addressed with simple numerical project identifiers. An example is
\sphinxcode{\sphinxupquote{128}}.


\subsection{Linking to MG-RAST}
\label{\detokenize{faq:linking-to-mg-rast}}\label{\detokenize{faq:section-linkin}}
Because future versions of MG-RAST may change, we provide a link-in
mechanism as a stable way of linking to MG-RAST. To link to datasets or
projects in MG-RAST, users should always use the \sphinxcode{\sphinxupquote{linkin.cgi}},
especially in publications.

Note: You must make the data set PUBLIC before you can publicly share
the link. It will not work for others until you do.

Note: Do not use the URL that is displayed in the browser when browsing
the site.

\sphinxcode{\sphinxupquote{https://mg-rast.org/linkin.cgi?metagenome=}}

\sphinxcode{\sphinxupquote{https://mg-rast.org/linkin.cgi?project=}}

For example, for the public dataset with metagenome ID \sphinxcode{\sphinxupquote{4440283.3}} the
URL is: \sphinxurl{http://mg-rast.org/linkin.cgi?metagenome=4440283.3}. For the
public project with project ID \sphinxcode{\sphinxupquote{128}} the URL is:
\sphinxurl{http://mg-rast.org/linkin.cgi?project=128}.

These URLs provides a stable method of linking to data that does not
require the viewer to have an MG-RAST account.


\subsection{Privacy}
\label{\detokenize{faq:privacy}}\label{\detokenize{faq:section-data-visibility}}
By default, a user’s data is not visible to others; the user needs to
explicitly grant permission for the data to be visible to anyone on the
Internet, either by sharing with individuals or by making it public
through the MG-RAST website. Only the owner of a dataset (the original
submitter) can make a dataset public and this requires explicit action
on their part, MG-RAST does not make data public without this action.
Owners can grant anonymous access to manuscript reviewers (see Section
{\hyperref[\detokenize{faq:section:reviewer_sharing}]{\emph{{[}section:reviewer\_sharing{]}}}}).

The web interface allows sharing and publication of data, requiring the
presence of minimal metadata (see Section {\hyperref[\detokenize{faq:section:metadata}]{\emph{4.7}}})
for data that is made public. Data can be shared or made public only
after the computation has finished.


\subsubsection{Sharing with individual users}
\label{\detokenize{faq:sharing-with-individual-users}}\label{\detokenize{faq:section-user-sharing}}
Data and analyses can be shared with individual users. To share data,
users simply enter their email address via clicking the \sphinxcode{\sphinxupquote{Sharing}} link
on the Metagenome Overview page. The dialogue shown in Figure
{\hyperref[\detokenize{faq:fig:sharing}]{\emph{9.2}}} will allow entering email addresses.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=6in]{{Images/sharing}}
\caption{Dialogue showing the sharing mechanism. The mechanism requires a
valid email address for the user with whom the data is to be shared.
A list of users with access to the data is displayed at the bottom on
the page.}\label{\detokenize{faq:fig-sharing}}\end{figure}

Both individual jobs as well as entire projects containing one or more
jobs can be shared using a similar mechanism from the Job Overview and
Project pages respectively.

As shown in Figure {\hyperref[\detokenize{faq:fig:Data-sharing-in-mg-rast}]{\emph{9.3}}}, we tend to
see dataset sharing between small groups of users.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=3in]{{Images/Data-sharing-in-mg-rast}}
\caption{Data sets shared in MG-RAST by users (orange dots), shown as
connecting edges.}\label{\detokenize{faq:fig-data-sharing-in-mg-rast}}\end{figure}


\subsubsection{Anonymous sharing with reviewers}
\label{\detokenize{faq:anonymous-sharing-with-reviewers}}\label{\detokenize{faq:section-reviewer-sharing}}
To grant manuscript reviewers access to a project while preserving their
anonymity click on the ’Create Reviewer Access Token’ button on the
project page. This button is visible only to the owner of a project by
clicking on the ’Share Project’ link. It will generate a token that can
be sent to the publisher to pass on to reviewers. When a reviewer
receives the token from the publisher they need to use the included link
to access MG-RAST. If necessary the reviewer will need to register for
an account and their account will have anonymous access to the project.
The number of reviewers who have accessed the project is displayed to
the owner in the list of users the project is shared with, but the
identity of the reviewers is not disclosed. The owner of the project can
revoke the token at any time to disable access.


\subsection{Publishing}
\label{\detokenize{faq:publishing}}\label{\detokenize{faq:section-publishing}}
MG-RAST provides a mechanism to make data and analyses publicly
accessible. All sequence data, metadata, analyses, and analyses files
for a dataset will be freely available for download once it is made
public. Only the submitting user can make data public on MG-RAST and
once this is done it can not be reversed. Metadata is mandatory for
dataset publication (see Section {\hyperref[\detokenize{faq:section:metadata}]{\emph{4.7}}}).

The following checklist describes the process of making MG-RAST datasets
and projects public:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Ownership of the datasets: To make a dataset public your account
needs to be labelled as the owner in MG-RAST.

\item {} 
Ownership of the project: Your account should be the owner of the
project as well, this is usually just the account that was used to
create the project.

\item {} 
Metadata: MG-RAST requires that you enter metadata for the project,
samples and libraries before it is made public to increase its
utility to the community. This is done through a pre-formatted excel
spreadsheet which you fill in with the necessary metadata. If you
have already entered metadata, e.g. during submission, and want to
make changes, you can download this file with the existing metadata
prefilled from the project page with the ‘Export Metadata’ link.

If you have not entered metadata for your project, download the
latest metadata template file from:
\sphinxurl{ftp://ftp.mg-rast.org/data/misc/metadata/} The first sheet is a README
containing some important tips for entering the metadata. The second
row in each sheet in the template contains some explanation and
instructions for each column. The columns marked with red headers are
required.

You can enter your data directly into the template, a better route
would be to use the tool we built to facilitate metadata entry \textendash{}
MetaZen: \sphinxurl{http://mg-rast.org/metazen.cgi}. MetaZen will step you
through the data entry and then give you a pre-filled excel
spreadsheet to download which you can then edit further if necessary.

Once you have the metadata file ready, upload with the ‘Upload
Metadata’ link on the project page.

\item {} 
Release metagenomes: Make each dataset public, there is a ‘Make
public’ link in the blue bar near the top of the Metagenome Overview
page.

\item {} 
Project Data: Edit the project page information if you wish with the
‘Edit Project Data’ link. You can enter an abstract, links to
publications, additional description, contacts etc. This page is the
central point in MG-RAST from where people will access your data and
analyses so add all information that may be useful.

\item {} 
Final step: Make the project public from the project page (project
page blue bar, ‘Make Public’).

\end{enumerate}

The link for a public project which should be used in a publication is
listed near the top of the project page, e.g.:
\sphinxurl{http://mg-rast.org/metagenomics.cgi?page=MetagenomeProject\&project=128}
where 128 is the MG-RAST project ID.

The link for individual public metagenomes which should be used in a
publication is listed near the top of the metagenome overview page,
e.g.:
\sphinxhref{http://mg-rast.org/linkin.cgi?metagenome=4440283.3}{http: //mg-rast.org/linkin.cgi?metagenome=4440283.3}
where 4440283.3 is the MG-RAST metagenome ID.

The publication to cite for MG-RAST is at
\sphinxurl{http://www.biomedcentral.com/1471-2105/9/386}.


\subsection{Who should I cite when I use this service?}
\label{\detokenize{faq:who-should-i-cite-when-i-use-this-service}}
See Section {\hyperref[\detokenize{faq:section:MG-RAST-citation}]{\emph{1.5}}}.


\subsection{Is MG-RAST open source and can I install it locally?}
\label{\detokenize{faq:is-mg-rast-open-source-and-can-i-install-it-locally}}
MG-RAST is indeed open source. We make the current stable versions
available on github: \sphinxurl{https://github.com/MG-RAST/} However MG-RAST is a
complex system to install (note: we have not been funded to create a
readily installable version) and even more complex to operate. We advise
against attempting to create a private installation and can not provide
any help installing MG-RAST locally.

If you are a biologist worried about runtime of your jobs, there is a
way to run your jobs on computational resources provided by you that
will significantly help. Please contact us at our usual address mg-rast
at mg-rast.org to inquire about ways of setting this up.

If you are a bioinformatician and want to contribute code or test
alternatives for individual steps, we are currently preparing a system
that will make all components of MG-RAST easily accessible. This is not
currently sea-worthy. Same as with the biologists, please contact us at
help at mg-rast.org for details.


\section{Accounts}
\label{\detokenize{faq:accounts}}
The analyses of all public datasets in MG-RAST can be viewed in entirety
without an MG-RAST account. An account is required to submit sequence
data for analysis or view the analyses of datasets which have been
shared with you.

\sphinxstylestrong{Accounts are for individuals, not services or groups.} In our
experience account sharing (e.g. two or more users having access to the
same username/password information) will always lead to problems, we
\sphinxstylestrong{strongly} discourage account sharing.

As scientist typically will switch employers every few years we
encourage users to provide two email addresses, the primary email
address could be your work email, the secondary your private email. By
providing a second email address you can avoid losing access to your
account if and when you switch employers and your work email is no
longer available.


\subsection{Account registration}
\label{\detokenize{faq:account-registration}}
Use the “Register” link on the front page of the website to request an
account with MG-RAST, you will need to enter a unique login name and
email address along with other minimal information. Use an email address
you use regularly as it will be used to communicate with you when
necessary. After registering you will receive an automated email with a
temporary password after your account has been authorized, usually
within a day.

If you forget your password you can request a new password on the
MG-RAST website using your login and registered email address, a new
password will be generated and sent by email to this address.


\subsection{Account webkey}
\label{\detokenize{faq:account-webkey}}\label{\detokenize{faq:section-webkey}}
The webkey is a unique string of text, e.g. “b8Dvg2d5DCp7KsWKBPzY2GS4i”
associated with your account which is used by MG-RAST for identification
purposes. Your webkey is valid for a limited time period after which it
expires and will not work anymore. You can generate a new webkey at any
time, even if your current webkey has not expired.

The MG-RAST website provides two locations where you can generate a new
webkey:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Log in to MG-RAST and go to the Account Management page. Press the
button under “Preferences” to go the the Manage Preferences page
where the Web Services section displays your current webkey with its
termination date. Click on the “generate new key” button to generate
a new key and then click the “set preferences” button.

\item {} 
Log in to MG-RAST and go to the Upload page and click on the
“generate webkey” button in the “upload files” tab and then click on
the “generate new key” button.

\end{enumerate}

Note that generating a new webkey will invalidate your old webkey and
your new webkey will be valid until the termination date displayed on
the page.


\subsection{Why do I need to register for this service?}
\label{\detokenize{faq:why-do-i-need-to-register-for-this-service}}
If you do not plan to submit data for analysis to MG-RAST and only want
to browse data which is publicly available there is no need to register.
Otherwise we request that users register, with a valid email address, so
we can contact you once the computation is finished or in case user
intervention is required.


\subsection{I have forgotten my password, what should I do?}
\label{\detokenize{faq:i-have-forgotten-my-password-what-should-i-do}}
In the navigation toolbox (top right corner of the webpage) there is a
’Forgot?’ link displayed. Click on this and enter your login and the
email address you registered with MG-RAST. A changed password will be
sent by email to this address. For security purposes you should login
and change this new password as soon as you receive the email.


\subsection{Can I change my account information?}
\label{\detokenize{faq:can-i-change-my-account-information}}
Yes, you can change or modify your password, email address, name and
funding source for your account. Login and make the changes on the
account management page.


\section{Upload and Submission}
\label{\detokenize{faq:upload-and-submission}}\label{\detokenize{faq:section-uploading-to-mg-rast}}
MG-RAST was designed to allow users to upload sequence data directly
from next-generation sequencing machines. Data can be in FASTA, FASTQ,
or SFF format.

We suggest uploading raw data (in FASTQ or SFF format) and letting
MG-RAST perform the quality control step because this approach will
allow us to identify any issues with the sequencing run. Frequently,
local quality control will identify some issues but mask others.

Compressing large files will reduce the upload time and the chances of a
failed upload. Users can upload gzip (.gz) and bzip2 (.bz2) or Zip
(.zip) files, as well as tar archives compressed with gzip (.tar.gz) or
bzip2 (.tar.bz2).

It is not necessary to assemble data prior to upload to MG-RAST. The
system has been optimized for short reads and can handle uploads of many
hundreds of gigabytes.

Assembled data can be uploaded to MG-RAST and read abundance information
for contigs can be imported as well from FASTA files. The “assembled”
option for the pipeline will attempt to retrieve read abundance
information from the FASTA sequence files.


\subsection{Data submission via the web interface}
\label{\detokenize{faq:data-submission-via-the-web-interface}}
To start uploading data to MG-RAST through the website, click on the
green up arrow. Doing so opens the Upload page. On this page you can
upload files, modify the files where needed, add metadata, and submit
files for analysis.

The page has three stages (see Figure
{\hyperref[\detokenize{faq:fig:submission_stages}]{\emph{{[}fig:submission\_stages{]}}}}). The first
“Upload” to upload, manipulate, and collect all the files required for a
submission, and “Submit,” to create the MG-RAST job(s), set analysis
parameters, and start the analysis. The last is “Progress”, where you
can monitor your job status.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=4in]{{submission_stages}.png}
\caption{The flow for MG-RAST submissions via the web interface}\label{\detokenize{faq:id2}}\end{figure}

{[}fig:submission\_stages{]}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=4in]{{upload_button}.png}
\caption{The MG-RAST upload page with its three main stages}\label{\detokenize{faq:id3}}\end{figure}

{[}fig:upload\_button{]}

Starting with version 3.6 of MG-RAST, the web upload page will provide
significantly more user guidance and help with ensuring the files
uploaded are both compliant with the required naming scheme and are
transferred intact.


\subsubsection{Data requirements for upload}
\label{\detokenize{faq:data-requirements-for-upload}}
Files larger than 50 MB should be compressed before upload, using gzip
(preferable), bzip2 or Zip (less than 4 GB in size). Compression will
reduce the time taken for the upload of the file, which in turn reduces
the chance that the upload will fail. The requirements for submission
are sequence information (required), metadata (strongly recommended) and
barcode information (for multiplexed datasets only).

We note that priority will be giving to data that has compete GSC
metadata and has been marked for eventual release to the public. The
data release is under user control, MG-RAST staff will not release the
data for the user.

To ensure files are uploaded properly, MG-RAST performs automatic
MD5 {\color{red}\bfseries{}{[}4{]}\_} checking on client and server side (for most files) to ensure
that files are received correctly by MG-RAST. This is an important part
of data hygiene as files may get corrupted in flight. The new interface
(from version 3.6 onwards), will check the integrity and will give you
immediate feedback about whether your upload was successful. If not
detected at upload time, a damaged file will lead to errors later in the
pipeline, wasting both valuable compute cycles and, even more
importantly, your time.

All files uploaded to MG-RAST should be named using only alphanumeric
and .\_ characters without spaces. As of version 3.6, the upload system
ensures that files are compliant with the mandatory naming scheme, using
only alphanumeric and .-characters without spaces. In addition, there is
no need to extract/uncompress files after upload. MG-RAST does this
automatically along with checking metadata and sequence file format and
nomenclature compliance.

Advanced options provides the option to change chunk size. Chunked
uploading allows us to break a large file into small chunks, and send
these pieces to the upload server one-by-one. If an upload fails, we
need only resume from the last successful chunk and allows for resuming
uploads. As a rule, the larger the file and the faster your connection,
the larger the chunk size should be. Set the size lower if your
connection is slow. We have a default setting that works well for most
data sets and connection speeds. If you are encountering upload failure
(outside of formatting issues), try a smaller chunk size.

The following three kinds of files can be uploaded:
\begin{itemize}
\item {} 
Sequence files

Sequence files must be in either FASTA, FASTQ, or SFF formats

Sequence file names must have one of the following extensions \textendash{}
‘.fasta’, ‘.fna’, ‘.fastq’, ‘.fq’, or ‘.sff’.

FASTA and FASTQ files should be in plain text ASCII.

FASTA files (and all sequence data submitted to MG-RAST) should not
contain protein sequences.

Assembled data with read abundance information must be in FASTA
format and the coverage included in the sequence ID using the
following simple format:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}}\PYG{n}{sequence\PYGZus{}number\PYGZus{}1\PYGZus{}}\PYG{p}{[}\PYG{n}{cov}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{]}
\PYG{n}{CTAGCGCACATAGCATTCAGCGTAGCAGTCACTAGTACGTAGTACGTACC}
\PYG{o}{\PYGZgt{}}\PYG{n}{sequence\PYGZus{}number\PYGZus{}2\PYGZus{}}\PYG{p}{[}\PYG{n}{cov}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{]}
\PYG{n}{ACGTAGCTCACTCCAGTAGCAGGTACGTCGAGAAGACGTCTAGTCATCAT}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\end{sphinxVerbatim}

The abundance information must be appended without spaces to the end
of the sequence name (also without whitespace) in the format
“\_{[}cov=n{]}”, where n is the coverage or abundance of each contig.
Sequence files in this format should be submitted with the
“assembled” option selected and the pipeline will retrieve read
abundance information from the sequence file.

\item {} 
Metadata file

We provide a spreadsheet template that can be filled out with all the
available metadata information for a dataset, there is a link to the
template on the upload page. Download the template and edit to
include as much information as is available. While the number of
fields in the template is large, the number of required fields,
colored in red in the template, is small. The template file can be
used to upload metadata for one or multiple samples and submit them
to MG-RAST as a single project. The metadata can be modified at any
time after submission to add information or to correct errors. See
Section
{\hyperref[\detokenize{faq:section:generating_metadata}]{\emph{{[}section:generating\_metadata{]}}}} for
more details.

We note that a good strategy is to copy an existing metadata file and
modify the values appropriately. Our experience has also shown that
editing the metadata file with tools other than Microsoft Excel will
corrupt the files.

\item {} 
Barcode file

Barcoding reads allows multiplexing multiple samples into a single
sequence file. Barcode files allow demultiplexing those files.
Consequently, Barcode files are required only for sequence data which
will be demultiplexed on the MG-RAST website. In many cases
(typically for shotgun metagenomes) the demultiplexing will have
already been done by the sequencing center. If you have demultiplexed
sequence data, you do not need to enter the barcodes associated with
your samples in a Barcode file. While suitable for all kinds of
barcodes and sequence data, we expect the built-in demultiplexing to
be used mostly for custom barcoded amplicon sequences.

The barcode file should be in plain text ASCII.

If the sequencing facility generated the libraries and did not
demultiplex them for you, make sure to get the barcodes corresponding
to each of your samples. The barcode file should be in plain text
ASCII, a downloadable example can be found at:
\sphinxurl{ftp://ftp.mg-rast.org/data/manual/example/}.

Each line of the file should contain a single barcode sequence
followed by a tab and then a unique filename, with as many lines as
necessary for the barcodes in the sequence file you are submitting.
Additional columns are ignored.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Example}\PYG{p}{:}
\PYG{n}{ACTCTCGTG}    \PYG{n}{sample\PYGZus{}1}
\PYG{n}{CAGACATCT}    \PYG{n}{sample\PYGZus{}2}
\PYG{n}{GTAGATCAC}    \PYG{n}{sample\PYGZus{}3}
\end{sphinxVerbatim}

The barcode file typically will be provided by whoever created the
amplicons, in many cases that is the sequencing center.

\end{itemize}


\subsubsection{Uploading data}
\label{\detokenize{faq:uploading-data}}
In this first step, data is uploaded into your private inbox on the
MG-RAST server, this area is write-only and only accessible to you. Data
in the inbox cannot be read or re-exported, its sole purpose is to serve
as a starting point for the pipeline.

When an upload is started it can be aborted or paused. Pausing will
cause the current chunk to complete and then pause the upload. Abort
will interrupt the upload immediately. A paused upload can be resumed by
clicking the resume button in the upload dialog. Aborted uploads can be
resumed or deleted just like other incomplete uploads by clicking the
resume button in the top bar.

When an upload completes (that is not an archived file), an automatic
md5 check will be calculated and the result presented to the user. In
the case of an archive file uploaded, the user has to produce the
checksum of the local file themselves and can paste it into a check
field for validation. A note will be displayed to the user to calculate
the md5sum on the uncompressed file. Archived files will be decompressed
automatically.

At upload:
\begin{itemize}
\item {} 
Sequence files will automatically trigger sequence stats calculation

\item {} 
Sequence files with calculated stats will display those stats upon
selection

\item {} 
Sequence files will show buttons for demultiplexing and joining of
paired ends

\item {} 
Barcode files will automatically show a button for demultiplexing

\end{itemize}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=4in]{{upload_inbox}.png}
\caption{The main elements of the file browser explained. The left side pane
shows a list of uploaded files. The top bar provides available
actions. Users can select files to view information and whether the
file passes formatting check.}\label{\detokenize{faq:id4}}\end{figure}

{[}fig:upload\_inbox{]}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=4in]{{upload_progress}.png}
\caption{Once selected from the file browser you can start the upload and
observe progress in the right side pane.}\label{\detokenize{faq:id5}}\end{figure}

{[}fig:upload\_progress{]}

From the inbox data needs to be submitted to the annotation pipeline.
Once files are uploaded, the inbox allows a set of operations to be
performed.


\subsubsection{Expected upload speeds}
\label{\detokenize{faq:expected-upload-speeds}}
Based on observed values, upload times per 1 GB (\(10^9\) bytes)
vary from 2 minutes to over an hour, with typical times being 10 to 15
minutes. Your experience will vary depending on the speed of your
connection to the internet and the quality of service in your region.

Table 1 summarizes observed upload times that might help users estimate
how long the upload should take.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Summary of upload times}\label{\detokenize{faq:id6}}
\sphinxaftertopcaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
Technology
&\sphinxstyletheadfamily 
Rate (bit/s)
&\sphinxstyletheadfamily 
Time for 1GB Upload
\\
\hline
Modem 14.4 (2400 baud)
&
14.4 kbit/s
&
154 hours
\\
\hline
ADSL Lite
&
1.5 Mbit/s
&
1.5 hours
\\
\hline
Ethernet
&
10 Mbit/s
&
13.33 minutes
\\
\hline
T3
&
44.736 Mbit/s
&
3 minutes
\\
\hline
Fast Ethernet
&
100 Mbit/s
&
1.33 minutes
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\subsubsection{Frequent issues with data uploading}
\label{\detokenize{faq:frequent-issues-with-data-uploading}}\begin{itemize}
\item {} 
Old browser version will not provide good throughput with the upload
and may fail to execute the Javascript for the uploader properly.
Update to the latest version of Firefox for optimal performance.

\item {} 
Browser-add-ons have in several occasions blocked uploads or led to
aborted uploads in the past. Disable those add-ons temporarily for
the duration of the upload.

\item {} 
In rare cases network devices have been presenting problems for the
upload. Some institutions have not anticipated the use of the http
protocol to transfer large data sets. In these cases the best option
is to find another network location for the transfer.

\end{itemize}


\subsubsection{File filters in place for uploaded files.}
\label{\detokenize{faq:file-filters-in-place-for-uploaded-files}}
Since MG-RAST has been designed to work with metagenomic and
metatranscriptomic datasets, there is a filter in place trying to
identify datasets not suitable for MG-RAST. Those datasets will be
colored red in the inbox listing and cannot be submitted. Following are
the criteria for rejection:
\begin{itemize}
\item {} 
Protein sequences \textendash{} MG-RAST is optimized to perform translation from
DNA to proteins.

\item {} 
Reads shorter than 75 basepairs \textendash{} The gene prediction stage
performance deteriorates significantly with shorter reads.

\item {} 
genomes \textendash{} Submissions with complete genomes or a small number of
contigs are rejected as well. Here our sister service RAST at
\sphinxurl{http://rast.nmpdr.org} should be used instead of MG-RAST.

\item {} 
Files that are too small (sequence data less than 1 Mbp) \textendash{} Files that
are too small for MG-RAST to properly function are rejected at the
submission stage. The minimal size requirement is 1 megabasepair.

\item {} 
Corrupted files \textendash{} FASTA and FASTQ files which do not conform to the
format standard, e.g. if the number of unique identifiers does not
match the number of sequence records in a file, the file is
considered corrupt.

\item {} 
Alignments \textendash{} We cannot identify proteins from sequences containing
alignment information.

\item {} 
Colorspace \textendash{} The tool chain does not function for ABIsolid sequences
in colorspace. Please translate to standard FASTA.

\item {} 
rar compressed files and Zip files over 4 GB \textendash{} We cannot decompress
these files.

\end{itemize}

In addition we will filter at the upload stage any Word documents, Rich
Text Format files, and all files without the extension .fna, .fasta,
.fq, .fastq, or .sff in their name.

\sphinxstylestrong{Note:} We recommend computing an MD5 checksum and verifying that the
checksum computed by MG-RAST is identical to the locally computed
checksum. This is the best way to ensure data integrity.

\sphinxstylestrong{Please note:} After the actual upload is complete, the system will
compute the statistics shown in Figure
{\hyperref[\detokenize{faq:fig:upload_inbox}]{\emph{{[}fig:upload\_inbox{]}}}}. Computing this information
takes some time, so the statistics for your sequence files will not be
visible immediately after you uploaded it. If the statistics are not
displayed in a reasonable time refresh your browser page to trigger the
statistics computation.


\subsubsection{Submit data for processing}
\label{\detokenize{faq:submit-data-for-processing}}
In the second step, data needs to be submitted for processing. At
submission time you either add data to an existing study (or project) or
create a new study. Upon successful submission, data is removed from the
inbox. You will be notified via email once your submission has completed
processing. In addition you can monitor the progress of your submission
at the job status.
\begin{itemize}
\item {} 
All submitted data will stay private until the owner makes it public
or shares it with another user.

\item {} 
Providing metadata is required to make your data public and will
increase your priority in the queue.

\item {} 
The sooner you choose to make your data public, the higher your
priority in the queue will be.

\end{itemize}

The submission step provides a visual aid to identify completed tasks
(the bars on the page are turning from blue (open) to green (done), see
Figures {\hyperref[\detokenize{faq:fig:submission_open}]{\emph{{[}fig:submission\_open{]}}}} and
{\hyperref[\detokenize{faq:fig:submission_done}]{\emph{{[}fig:submission\_done{]}}}}).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=4in]{{submission_open}.png}
\caption{The submit page with none of the fields filled out.}\label{\detokenize{faq:id7}}\end{figure}

{[}fig:submission\_open{]}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=4in]{{submission_done}.png}
\caption{The submit page with all bars in green indicating that the respective
sections have been filled out.}\label{\detokenize{faq:id8}}\end{figure}

{[}fig:submission\_done{]}


\subsubsection{Progress monitoring}
\label{\detokenize{faq:progress-monitoring}}
Once data is submitted, you can monitor its progress.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=4in]{{submission_pipeline_view}.png}
\caption{The jobs you have submitted are listed with their current status. A
green dot indicates the stage has completed successfully, blue
indicates that the current stage is in progress. Queued stages will
produce an orange dot, green indicates a completed stage and red
indicates error state. Gray dots will show for all stages waiting for
other stages to complete.}\label{\detokenize{faq:id9}}\end{figure}

{[}fig:submission\_pipeline\_view{]}

Depending on your priority (assigned based on available metadata and how
public your data is) your jobs will progress through the system. Jobs
that fail due to technical reasons (component failure etc.) will be
restarted by MG-RAST staff.

You will receive an email once a given data set has finished processing.


\subsection{Cmd-line uploader}
\label{\detokenize{faq:cmd-line-uploader}}
The following upload instructions are for all file types supported by
MG-RAST.

The mg-inbox command line tool allows upload of sequence and metadata
files and management of the user’s upload area, the inbox. In order to
operate on the inbox the user has to authenticate with an MG-RAST token.
The token can be retrieved from the “Account Management” \textendash{}\(>\)
“Manage personal preferences” \textendash{}\(>\) “Web Services” \textendash{}\(>\)
“authentication key” page via MG-RAST Web site.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Make sure you have python installed on your system.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{pip}\PYG{o}{.}\PYG{n}{pypa}\PYG{o}{.}\PYG{n}{io}\PYG{o}{/}\PYG{n}{en}\PYG{o}{/}\PYG{n}{latest}\PYG{o}{/}\PYG{n}{installing}\PYG{o}{.}\PYG{n}{html}
\end{sphinxVerbatim}

\item {} 
Go to the directory where you have your files to upload.

\item {} 
Download the upload script

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ftp}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{ftp}\PYG{o}{.}\PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{rast}\PYG{o}{.}\PYG{n}{org}\PYG{o}{/}\PYG{n}{tools}\PYG{o}{/}\PYG{n}{upload}\PYG{o}{/}\PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{inbox}\PYG{o}{.}\PYG{n}{py}
\end{sphinxVerbatim}

\item {} 
Checkout the help options for “mg-inbox.py”. If you received an error
message that you are missing certain python libraries, you will need
to install them before you can run the script. To install python
libraries use pip install \(<\)lib-name\(>\) to install
the missing libraries. Note: The error message from running “python
mg-inbox.py \textendash{}help” will provide the “lib-name” you are missing. You
may have a few libraries to install.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{python} \PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{inbox}\PYG{o}{.}\PYG{n}{py} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{help}
\end{sphinxVerbatim}

\item {} 
First you need to login. The login option takes a user token and
writes a login file after successful login. For example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{python} \PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{inbox}\PYG{o}{.}\PYG{n}{py} \PYG{n}{login} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{token} \PYG{o}{\PYGZlt{}}\PYG{n}{myToken}\PYG{o}{\PYGZgt{}}
\PYG{n}{python} \PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{inbox}\PYG{o}{.}\PYG{n}{py} \PYG{n}{view} \PYG{n+nb}{all}
\end{sphinxVerbatim}

\item {} 
You can upload a file into your inbox with

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{python} \PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{inbox}\PYG{o}{.}\PYG{n}{py} \PYG{n}{upload} \PYG{o}{\PYGZlt{}}\PYG{n}{path\PYGZus{}to\PYGZus{}file}\PYG{o}{\PYGZgt{}}\PYG{o}{/}\PYG{o}{\PYGZlt{}}\PYG{n}{file\PYGZus{}name}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

\item {} 
If you have a compressed file to upload, supports gzip or bzip2

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{python} \PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{inbox}\PYG{o}{.}\PYG{n}{py} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{gzip} \PYG{n}{upload} \PYG{o}{\PYGZlt{}}\PYG{n}{path\PYGZus{}to\PYGZus{}file}\PYG{o}{\PYGZgt{}}\PYG{o}{/}\PYG{o}{\PYGZlt{}}\PYG{n}{gzip\PYGZus{}file}\PYG{o}{\PYGZgt{}}
\PYG{n}{python} \PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{inbox}\PYG{o}{.}\PYG{n}{py} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{bzip2} \PYG{n}{upload} \PYG{o}{\PYGZlt{}}\PYG{n}{path\PYGZus{}to\PYGZus{}file}\PYG{o}{\PYGZgt{}}\PYG{o}{/}\PYG{o}{\PYGZlt{}}\PYG{n}{bzip2\PYGZus{}file}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

\item {} 
If you have an archive file containing multiple files to upload,
supports: .zip, .tar, .tar.gz, .tar.bz2

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{python} \PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{inbox}\PYG{o}{.}\PYG{n}{py} \PYG{n}{upload}\PYG{o}{\PYGZhy{}}\PYG{n}{archive} \PYG{o}{\PYGZlt{}}\PYG{n}{path\PYGZus{}to\PYGZus{}file}\PYG{o}{\PYGZgt{}}\PYG{o}{/}\PYG{o}{\PYGZlt{}}\PYG{n}{archive\PYGZus{}file}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

\item {} 
You can examine the content of your inbox with

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{python} \PYG{n}{mg}\PYG{o}{\PYGZhy{}}\PYG{n}{inbox}\PYG{o}{.}\PYG{n}{py} \PYG{n}{view} \PYG{n+nb}{all}
\end{sphinxVerbatim}

\item {} 
You can submit your sequence files from the Upload page on the
MG-RAST web site (cmd-line option coming soon).

\end{enumerate}


\subsection{REST API uploader}
\label{\detokenize{faq:rest-api-uploader}}
The following upload instructions are for using the MG-RAST REST API
with the curl program. In order to operate the API the user has to
authenticate with an MG-RAST token. The token can be retrieved from the
“Account Management” \textendash{}\(>\) “Manage personal preferences” \textendash{}\(>\)
“Web Services” \textendash{}\(>\) “authentication key” page via MG-RAST Web
site.

We strongly suggest that you use the scripts we provide, instead of the
native REST API.
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
\item {} 
You can upload a file into your inbox with

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{curl} \PYG{o}{\PYGZhy{}}\PYG{n}{X} \PYG{n}{POST} \PYG{o}{\PYGZhy{}}\PYG{n}{H} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{auth: \PYGZlt{}myToken\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{n}{F} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{upload=@\PYGZlt{}path\PYGZus{}to\PYGZus{}file\PYGZgt{}/\PYGZlt{}file\PYGZus{}name\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://api.mg\PYGZhy{}rast.org/inbox}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

\item {} 
If you have a compressed file to upload, supports gzip or bzip2

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{curl} \PYG{o}{\PYGZhy{}}\PYG{n}{X} \PYG{n}{POST} \PYG{o}{\PYGZhy{}}\PYG{n}{H} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{auth: \PYGZlt{}myToken\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{n}{F} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{upload=@\PYGZlt{}path\PYGZus{}to\PYGZus{}file\PYGZgt{}/\PYGZlt{}gzip\PYGZus{}file\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{n}{F} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{compression=gzip}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://api.mg\PYGZhy{}rast.org/inbox}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{curl} \PYG{o}{\PYGZhy{}}\PYG{n}{X} \PYG{n}{POST} \PYG{o}{\PYGZhy{}}\PYG{n}{H} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{auth: \PYGZlt{}myToken\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{n}{F} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{upload=@\PYGZlt{}path\PYGZus{}to\PYGZus{}file\PYGZgt{}/\PYGZlt{}gzip\PYGZus{}file\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{n}{F} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{compression=bzip2}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://api.mg\PYGZhy{}rast.org/inbox}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

\item {} 
If you have an archive file containing multiple files to upload do
the following two steps, supports: .zip, .tar, .tar.gz, .tar.bz2

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+m+mf}{1.} \PYG{n}{curl} \PYG{o}{\PYGZhy{}}\PYG{n}{X} \PYG{n}{POST} \PYG{o}{\PYGZhy{}}\PYG{n}{H} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{auth: \PYGZlt{}myToken\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{n}{F} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{upload=@\PYGZlt{}path\PYGZus{}to\PYGZus{}file\PYGZgt{}/\PYGZlt{}archive\PYGZus{}file\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://api.mg\PYGZhy{}rast.org/inbox}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{l+m+mf}{2.} \PYG{n}{curl} \PYG{o}{\PYGZhy{}}\PYG{n}{X} \PYG{n}{POST} \PYG{o}{\PYGZhy{}}\PYG{n}{H} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{auth: \PYGZlt{}myToken\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZhy{}}\PYG{n}{F} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{format=\PYGZlt{}one of: zip, tar, tar.gz, tar.bz2\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://api.mg\PYGZhy{}rast.org/inbox/unpack/\PYGZlt{}uploaded\PYGZus{}file\PYGZus{}id\PYGZgt{}}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

\end{enumerate}



\renewcommand{\indexname}{Index}
\printindex
\end{document}